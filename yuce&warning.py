import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import warnings
import os
import re
import calendar
import math
from io import BytesIO
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.font_manager as fm
from matplotlib.ticker import MaxNLocator
from matplotlib.gridspec import GridSpec

warnings.filterwarnings('ignore')

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="é”€å”®é¢„æµ‹ä¸åº“å­˜é£é™©ç®¡ç†ä¸€ä½“åŒ–ä»ªè¡¨ç›˜",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2rem;
        color: #1f3867;
        text-align: center;
        margin-bottom: 1rem;
    }
    .card-header {
        font-size: 1.2rem;
        font-weight: bold;
        color: #444444;
    }
    .card-value {
        font-size: 1.8rem;
        font-weight: bold;
        color: #1f3867;
    }
    .metric-card {
        background-color: white;
        border-radius: 0.5rem;
        padding: 1rem;
        box-shadow: 0 0.15rem 1.75rem 0 rgba(58, 59, 69, 0.15);
        margin-bottom: 1rem;
    }
    .card-text {
        font-size: 0.9rem;
        color: #6c757d;
    }
    .alert-box {
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
    }
    .alert-success {
        background-color: rgba(76, 175, 80, 0.1);
        border-left: 0.5rem solid #4CAF50;
    }
    .alert-warning {
        background-color: rgba(255, 152, 0, 0.1);
        border-left: 0.5rem solid #FF9800;
    }
    .alert-danger {
        background-color: rgba(244, 67, 54, 0.1);
        border-left: 0.5rem solid #F44336;
    }
    .sub-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #1f3867;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .chart-explanation {
        background-color: rgba(76, 175, 80, 0.1);
        padding: 0.9rem;
        border-radius: 0.5rem;
        margin: 0.8rem 0;
        border-left: 0.5rem solid #4CAF50;
    }
    .low-accuracy {
        border: 2px solid #F44336;
        box-shadow: 0 0 8px #F44336;
    }
    .logo-container {
        position: absolute;
        top: 0.5rem;
        right: 1rem;
        z-index: 1000;
    }
    .logo-img {
        height: 40px;
    }
    .pagination-btn {
        background-color: #1f3867;
        color: white;
        border: none;
        padding: 5px 10px;
        border-radius: 3px;
        margin: 5px;
        cursor: pointer;
    }
    .pagination-btn:hover {
        background-color: #2c4f8f;
    }
    .pagination-info {
        display: inline-block;
        padding: 5px;
        margin: 5px;
    }
    .hover-info {
        background-color: rgba(0,0,0,0.7);
        color: white;
        padding: 8px;
        border-radius: 4px;
        font-size: 0.9rem;
    }
    .slider-container {
        padding: 10px 0;
    }
    .highlight-product {
        font-weight: bold;
        background-color: #ffeb3b;
        padding: 2px 5px;
        border-radius: 3px;
    }
    .recommendation-tag {
        display: inline-block;
        padding: 2px 6px;
        border-radius: 3px;
        font-size: 0.85rem;
        font-weight: bold;
        margin-left: 5px;
    }
    .recommendation-increase {
        background-color: #4CAF50;
        color: white;
    }
    .recommendation-maintain {
        background-color: #FFC107;
        color: black;
    }
    .recommendation-decrease {
        background-color: #F44336;
        color: white;
    }
    .risk-extreme-high {
        color: #8B0000;
        font-weight: bold;
    }
    .risk-high {
        color: #FF0000;
        font-weight: bold;
    }
    .risk-medium {
        color: #FFA500;
    }
    .risk-low {
        color: #008000;
    }
    .risk-extreme-low {
        color: #0000FF;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'authenticated' not in st.session_state:
    st.session_state['authenticated'] = False

# ç™»å½•ç•Œé¢
if not st.session_state.authenticated:
    st.markdown(
        '<div style="font-size: 1.5rem; color: #1f3867; text-align: center; margin-bottom: 1rem;">é”€å”®é¢„æµ‹ä¸åº“å­˜é£é™©ç®¡ç†ä¸€ä½“åŒ–ä»ªè¡¨ç›˜ | ç™»å½•</div>',
        unsafe_allow_html=True)

    # åˆ›å»ºå±…ä¸­çš„ç™»å½•æ¡†
    col1, col2, col3 = st.columns([1, 2, 1])

    with col2:
        st.markdown("""
        <div style="padding: 20px; border-radius: 10px; border: 1px solid #ddd; box-shadow: 0 0.15rem 1.75rem 0 rgba(58, 59, 69, 0.15);">
            <h2 style="text-align: center; color: #1f3867; margin-bottom: 20px;">è¯·è¾“å…¥å¯†ç </h2>
        </div>
        """, unsafe_allow_html=True)

        # å¯†ç è¾“å…¥æ¡†
        password = st.text_input("å¯†ç ", type="password", key="password_input")

        # ç™»å½•æŒ‰é’®
        login_button = st.button("ç™»å½•")

        # éªŒè¯å¯†ç 
        if login_button:
            if password == 'SAL':  # ç®€æ˜“å¯†ç ï¼Œå®é™…åº”ç”¨ä¸­åº”æ›´å®‰å…¨
                st.session_state['authenticated'] = True
                st.success("ç™»å½•æˆåŠŸï¼")
                try:
                    st.rerun()  # ä½¿ç”¨æ–°ç‰ˆæœ¬æ–¹æ³•
                except AttributeError:
                    try:
                        st.experimental_rerun()  # å°è¯•ä½¿ç”¨æ—§ç‰ˆæœ¬æ–¹æ³•
                    except:
                        st.error("è¯·åˆ·æ–°é¡µé¢ä»¥æŸ¥çœ‹æ›´æ”¹")
            else:
                st.error("å¯†ç é”™è¯¯ï¼Œè¯·é‡è¯•ï¼")

    # å¦‚æœæœªè®¤è¯ï¼Œä¸æ˜¾ç¤ºåç»­å†…å®¹
    st.stop()


# å‡½æ•°ï¼šåŠ è½½Logo
def add_logo():
    st.markdown(
        """
        <div class="logo-container">
            <img src="https://www.example.com/logo.png" class="logo-img">
        </div>
        """,
        unsafe_allow_html=True
    )


# å‡½æ•°ï¼šæ ¼å¼åŒ–æ•°å€¼
def format_number(value):
    """æ ¼å¼åŒ–æ•°é‡æ˜¾ç¤ºä¸ºé€—å·åˆ†éš”çš„å®Œæ•´æ•°å­—"""
    return f"{int(value):,} ç®±"


# å‡½æ•°ï¼šæ·»åŠ å›¾è¡¨è§£é‡Š
def add_chart_explanation(explanation_text):
    """æ·»åŠ å›¾è¡¨è§£é‡Š"""
    st.markdown(f'<div class="chart-explanation">{explanation_text}</div>', unsafe_allow_html=True)


# å‡½æ•°ï¼šç®€åŒ–äº§å“åç§°
def simplify_product_name(code, full_name):
    """å°†äº§å“å®Œæ•´åç§°ç®€åŒ–ä¸ºæ›´ç®€çŸ­çš„æ ¼å¼"""
    # æ£€æŸ¥è¾“å…¥æœ‰æ•ˆæ€§
    if not full_name or not isinstance(full_name, str):
        return full_name

    # å¦‚æœç¬¦åˆ"å£åŠ›X-ä¸­å›½"æ ¼å¼ï¼Œåˆ™ç®€åŒ–
    if "å£åŠ›" in full_name and "-ä¸­å›½" in full_name:
        # å»é™¤"å£åŠ›"å‰ç¼€å’Œ"-ä¸­å›½"åç¼€
        return full_name.replace("å£åŠ›", "").replace("-ä¸­å›½", "").strip()

    # å¦åˆ™è¿”å›åŸå§‹åç§°
    return full_name


# å‡½æ•°ï¼šå®‰å…¨è®¡ç®—å‡å€¼
def safe_mean(series, default=0):
    """å®‰å…¨åœ°è®¡ç®—Seriesçš„å‡å€¼ï¼Œå¤„ç†ç©ºå€¼å’Œå¼‚å¸¸"""
    if series is None or len(series) == 0 or (hasattr(series, 'empty') and series.empty) or (
            hasattr(series, 'isna') and series.isna().all()):
        return default

    try:
        # å°è¯•ä½¿ç”¨pandaså†…ç½®meanæ–¹æ³•
        if hasattr(series, 'mean'):
            return series.mean()

        # å¦‚æœä¸æ˜¯pandas Seriesï¼Œå°è¯•ä½¿ç”¨numpy
        import numpy as np
        return np.nanmean(series)
    except (OverflowError, ValueError, TypeError, ZeroDivisionError):
        # å¤„ç†ä»»ä½•è®¡ç®—é”™è¯¯
        return default


# å‡½æ•°ï¼šè®¡ç®—å‡†ç¡®ç‡
def calculate_unified_accuracy(actual, forecast):
    """ç»Ÿä¸€è®¡ç®—å‡†ç¡®ç‡çš„å‡½æ•°ï¼Œé€‚ç”¨äºå…¨å›½å’ŒåŒºåŸŸ"""
    if actual == 0 and forecast == 0:
        return 1.0  # å¦‚æœå®é™…å’Œé¢„æµ‹éƒ½ä¸º0ï¼Œå‡†ç¡®ç‡ä¸º100%

    if actual == 0:
        return 0.0  # å¦‚æœå®é™…ä¸º0ä½†é¢„æµ‹ä¸ä¸º0ï¼Œå‡†ç¡®ç‡ä¸º0%

    # è®¡ç®—å·®å¼‚ç‡
    diff_rate = (actual - forecast) / actual

    # è®¡ç®—å‡†ç¡®ç‡ (åŸºç¡€å…¬å¼: 1 - |å·®å¼‚ç‡|)
    return max(0, 1 - abs(diff_rate))


# å‡½æ•°ï¼šç”Ÿæˆå¤‡è´§å»ºè®®
def generate_recommendation(growth_rate):
    """ä¼˜åŒ–çš„å¤‡è´§å»ºè®®ç”Ÿæˆå‡½æ•°"""
    # åŸºäºå¢é•¿ç‡ç”Ÿæˆå»ºè®®
    if growth_rate > 15:
        return {
            "å»ºè®®": "å¢åŠ å¤‡è´§",
            "è°ƒæ•´æ¯”ä¾‹": round(growth_rate),
            "é¢œè‰²": "#4CAF50",
            "æ ·å¼ç±»": "recommendation-increase",
            "å›¾æ ‡": "â†‘"
        }
    elif growth_rate > 0:
        return {
            "å»ºè®®": "å°å¹…å¢åŠ ",
            "è°ƒæ•´æ¯”ä¾‹": round(growth_rate / 2),
            "é¢œè‰²": "#8BC34A",
            "æ ·å¼ç±»": "recommendation-increase",
            "å›¾æ ‡": "â†—"
        }
    elif growth_rate > -10:
        return {
            "å»ºè®®": "ç»´æŒç°çŠ¶",
            "è°ƒæ•´æ¯”ä¾‹": 0,
            "é¢œè‰²": "#FFC107",
            "æ ·å¼ç±»": "recommendation-maintain",
            "å›¾æ ‡": "â†’"
        }
    else:
        adjust = abs(round(growth_rate / 2))
        return {
            "å»ºè®®": "å‡å°‘å¤‡è´§",
            "è°ƒæ•´æ¯”ä¾‹": adjust,
            "é¢œè‰²": "#F44336",
            "æ ·å¼ç±»": "recommendation-decrease",
            "å›¾æ ‡": "â†“"
        }


# å‡½æ•°ï¼šè®¡ç®—é£é™©ç™¾åˆ†æ¯”
def calculate_risk_percentage(days_to_clear, batch_age, target_days):
    """
    è®¡ç®—é£é™©ç™¾åˆ†æ¯”ï¼ŒåŸºäºæ¸…åº“å¤©æ•°å’Œåº“é¾„

    å‚æ•°:
    days_to_clear (float): é¢„è®¡æ¸…åº“å¤©æ•°
    batch_age (int): æ‰¹æ¬¡åº“é¾„ï¼ˆå¤©æ•°ï¼‰
    target_days (int): ç›®æ ‡æ¸…åº“å¤©æ•°ï¼ˆ30/60/90å¤©ï¼‰

    è¿”å›:
    float: é£é™©ç™¾åˆ†æ¯”ï¼ŒèŒƒå›´0-100
    """
    # æ ¸å¿ƒè§„åˆ™1: åº“é¾„å·²ç»è¶…è¿‡ç›®æ ‡å¤©æ•°ï¼Œé£é™©ç›´æ¥ä¸º100%
    if batch_age >= target_days:
        return 100.0

    # æ ¸å¿ƒè§„åˆ™2: æ— æ³•æ¸…åº“æƒ…å†µ
    if days_to_clear == float('inf'):
        return 100.0

    # æ ¸å¿ƒè§„åˆ™3: æ¸…åº“å¤©æ•°è¶…è¿‡ç›®æ ‡çš„3å€ï¼Œé£é™©ä¸º100%
    if days_to_clear >= 3 * target_days:
        return 100.0

    # è®¡ç®—åŸºäºæ¸…åº“å¤©æ•°çš„é£é™©ï¼ˆä½¿ç”¨sigmoidå‡½æ•°æä¾›æ›´å¥½çš„åŒºåˆ†åº¦ï¼‰
    clearance_ratio = days_to_clear / target_days
    clearance_risk = 100 / (1 + math.exp(-4 * (clearance_ratio - 1)))

    # è®¡ç®—åŸºäºåº“é¾„çš„é£é™©ï¼ˆçº¿æ€§æ¯”ä¾‹ï¼‰
    age_risk = 100 * batch_age / target_days

    # ç»„åˆé£é™© - åŠ æƒå¹³å‡ï¼Œæ›´å¼ºè°ƒé«˜é£é™©å› ç´ 
    combined_risk = 0.8 * max(clearance_risk, age_risk) + 0.2 * min(clearance_risk, age_risk)

    # é˜ˆå€¼è§„åˆ™1: æ¸…åº“å¤©æ•°è¶…è¿‡ç›®æ ‡ï¼Œé£é™©è‡³å°‘ä¸º80%
    if days_to_clear > target_days:
        combined_risk = max(combined_risk, 80)

    # é˜ˆå€¼è§„åˆ™2: æ¸…åº“å¤©æ•°è¶…è¿‡ç›®æ ‡çš„2å€ï¼Œé£é™©è‡³å°‘ä¸º90%
    if days_to_clear >= 2 * target_days:
        combined_risk = max(combined_risk, 90)

    # é˜ˆå€¼è§„åˆ™3: åº“é¾„è¶…è¿‡ç›®æ ‡çš„75%ï¼Œé£é™©è‡³å°‘ä¸º75%
    if batch_age >= 0.75 * target_days:
        combined_risk = max(combined_risk, 75)

    return min(100, round(combined_risk, 1))


# å‡½æ•°ï¼šåŠ è½½å•ä»·æ•°æ®
@st.cache_data
def load_price_data(file_path=None):
    """åŠ è½½äº§å“å•ä»·æ•°æ®"""
    price_data = {}

    # æŒ‡å®šçš„äº§å“å•ä»·ä¿¡æ¯ï¼ˆé»˜è®¤å€¼ï¼Œé˜²æ­¢æ–‡ä»¶ä¸å­˜åœ¨æˆ–è¯»å–å¤±è´¥ï¼‰
    specified_prices = {
        'F01E4B': 137.04,
        'F3411A': 137.04,
        'F0104L': 126.72,
        'F3406B': 129.36,
        'F01C5D': 153.6,
        'F01L3A': 182.4,
        'F01L6A': 307.2,
        'F01A3C': 175.5,
        'F01H2B': 307.2,
        'F01L4A': 182.4,
        'F0104J': 216.96
    }

    try:
        if file_path and os.path.exists(file_path):
            price_df = pd.read_excel(file_path)
            # æŸ¥æ‰¾åŒ…å«"å•ä»·"çš„åˆ—
            unit_price_col = [col for col in price_df.columns if 'å•ä»·' in col]
            product_code_col = [col for col in price_df.columns if 'äº§å“ä»£ç ' in col or 'ç¼–å·' in col]

            if unit_price_col and product_code_col:
                # ä½¿ç”¨æ‰¾åˆ°çš„åˆ—å
                code_col = product_code_col[0]
                price_col = unit_price_col[0]

                # å¤„ç†å¯èƒ½çš„å‰ç¼€å¦‚"å‹å·"æˆ–"ç¼–å·ï¼š"
                for _, row in price_df.iterrows():
                    code = str(row[code_col])
                    # æå–äº§å“ä»£ç  - æŸ¥æ‰¾å½¢å¦‚Få¼€å¤´åè·Ÿå­—æ¯å’Œæ•°å­—çš„æ¨¡å¼
                    code_match = re.search(r'(F[0-9A-Z]+)', code)
                    if code_match:
                        code = code_match.group(1)
                        price_data[code] = row[price_col]
            else:
                # å°è¯•æŸ¥æ‰¾äº§å“ä»£ç å’Œå•ä»·åˆ—ï¼Œä¸ç®¡åˆ—åæ˜¯ä»€ä¹ˆ
                if len(price_df.columns) >= 2:  # è‡³å°‘æœ‰ä¸¤åˆ—ï¼šä»£ç å’Œå•ä»·
                    code_col = price_df.columns[0]  # å‡è®¾ç¬¬ä¸€åˆ—æ˜¯ä»£ç 
                    price_col = price_df.columns[1]  # å‡è®¾ç¬¬äºŒåˆ—æ˜¯å•ä»·

                    for _, row in price_df.iterrows():
                        code = str(row[code_col])
                        # æå–äº§å“ä»£ç  - æŸ¥æ‰¾å½¢å¦‚Få¼€å¤´åè·Ÿå­—æ¯å’Œæ•°å­—çš„æ¨¡å¼
                        code_match = re.search(r'(F[0-9A-Z]+)', code)
                        if code_match:
                            code = code_match.group(1)
                            price_data[code] = row[price_col]

            # å¦‚æœæˆåŠŸè¯»å–äº†æ•°æ®ï¼Œè¿”å›
            if price_data:
                return price_data

        # å¦‚æœå•ä»·æ–‡ä»¶åŠ è½½å¤±è´¥æˆ–æœªæä¾›è·¯å¾„ï¼Œä½¿ç”¨æŒ‡å®šçš„ä»·æ ¼
        return specified_prices

    except Exception as e:
        # å‡ºé”™æ—¶ä½¿ç”¨æŒ‡å®šçš„ä»·æ ¼
        return specified_prices


# å‡½æ•°ï¼šåŠ è½½äº§å“ä¿¡æ¯æ•°æ®
@st.cache_data
def load_product_info(file_path=None):
    """åŠ è½½äº§å“ä¿¡æ¯æ•°æ®"""
    try:
        # é»˜è®¤è·¯å¾„æˆ–ç¤ºä¾‹æ•°æ®
        if file_path is None or not os.path.exists(file_path):
            # åˆ›å»ºç¤ºä¾‹æ•°æ®
            return create_sample_product_info()

        # åŠ è½½æ•°æ®
        df = pd.read_excel(file_path)

        # ç¡®ä¿åˆ—åæ ¼å¼ä¸€è‡´
        required_columns = ['äº§å“ä»£ç ', 'äº§å“åç§°']
        missing_columns = [col for col in required_columns if col not in df.columns]

        if missing_columns:
            st.error(f"äº§å“ä¿¡æ¯æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åˆ—: {', '.join(missing_columns)}ã€‚ä½¿ç”¨ç¤ºä¾‹æ•°æ®è¿›è¡Œæ¼”ç¤ºã€‚")
            return create_sample_product_info()

        # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
        df['äº§å“ä»£ç '] = df['äº§å“ä»£ç '].astype(str)
        df['äº§å“åç§°'] = df['äº§å“åç§°'].astype(str)

        # æ·»åŠ ç®€åŒ–äº§å“åç§°åˆ—
        df['ç®€åŒ–äº§å“åç§°'] = df.apply(lambda row: simplify_product_name(row['äº§å“ä»£ç '], row['äº§å“åç§°']), axis=1)

        return df

    except Exception as e:
        st.error(f"åŠ è½½äº§å“ä¿¡æ¯æ•°æ®æ—¶å‡ºé”™: {str(e)}ã€‚ä½¿ç”¨ç¤ºä¾‹æ•°æ®è¿›è¡Œæ¼”ç¤ºã€‚")
        return create_sample_product_info()


# å‡½æ•°ï¼šåˆ›å»ºç¤ºä¾‹äº§å“ä¿¡æ¯æ•°æ®
def create_sample_product_info():
    """åˆ›å»ºç¤ºä¾‹äº§å“ä¿¡æ¯æ•°æ®"""
    # äº§å“ä»£ç åˆ—è¡¨
    product_codes = [
        'F0104L', 'F01E4P', 'F01E6C', 'F3406B', 'F3409N', 'F3411A',
        'F01E4B', 'F0183F', 'F0110C', 'F0104J', 'F0104M', 'F0104P',
        'F0110A', 'F0110B', 'F0115C', 'F0101P'
    ]

    # äº§å“åç§°åˆ—è¡¨
    product_names = [
        'å£åŠ›æ¯”è¨68å…‹è¢‹è£…-ä¸­å›½', 'å£åŠ›æ±‰å ¡å¤§è¢‹120g-ä¸­å›½', 'å£åŠ›æ±‰å ¡ä¸­è¢‹108g-ä¸­å›½',
        'å£åŠ›æµ·æ´‹åŠ¨ç‰©100g-ä¸­å›½', 'å£åŠ›å¹»å½©èœ¥èœ´105g-ä¸­å›½', 'å£åŠ›åˆé¤è¢‹77g-ä¸­å›½',
        'å£åŠ›æ±‰å ¡137g-ä¸­å›½', 'å£åŠ›çƒ­ç‹—120g-ä¸­å›½', 'å£åŠ›å¥¶é…ª90g-ä¸­å›½',
        'å£åŠ›æ¯”è¨å°åŒ…60g-ä¸­å›½', 'å£åŠ›æ¯”è¨ä¸­åŒ…80g-ä¸­å›½', 'å£åŠ›æ¯”è¨å¤§åŒ…100g-ä¸­å›½',
        'å£åŠ›è–¯æ¡65g-ä¸­å›½', 'å£åŠ›é¸¡å—75g-ä¸­å›½', 'å£åŠ›æ±‰å ¡åœˆ85g-ä¸­å›½',
        'å£åŠ›å¾·æœæ±‰å ¡108g-ä¸­å›½'
    ]

    # äº§å“è§„æ ¼
    product_specs = [
        '68g*24', '120g*24', '108g*24', '100g*24', '105g*24', '77g*24',
        '137g*24', '120g*24', '90g*24', '60g*24', '80g*24', '100g*24',
        '65g*24', '75g*24', '85g*24', '108g*24'
    ]

    # åˆ›å»ºDataFrame
    data = {'äº§å“ä»£ç ': product_codes,
            'äº§å“åç§°': product_names,
            'äº§å“è§„æ ¼': product_specs}

    df = pd.DataFrame(data)

    # æ·»åŠ ç®€åŒ–äº§å“åç§°åˆ—
    df['ç®€åŒ–äº§å“åç§°'] = df.apply(lambda row: simplify_product_name(row['äº§å“ä»£ç '], row['äº§å“åç§°']), axis=1)

    return df


# å‡½æ•°ï¼šæ ¼å¼åŒ–äº§å“ä»£ç 
def format_product_code(code, product_info_df, include_name=True):
    """å°†äº§å“ä»£ç æ ¼å¼åŒ–ä¸ºåªæ˜¾ç¤ºç®€åŒ–åç§°ï¼Œä¸æ˜¾ç¤ºä»£ç """
    if product_info_df is None or code not in product_info_df['äº§å“ä»£ç '].values:
        return code

    if include_name:
        # ä»…ä½¿ç”¨ç®€åŒ–åç§°ï¼Œä¸åŒ…å«ä»£ç 
        filtered_df = product_info_df[product_info_df['äº§å“ä»£ç '] == code]
        if not filtered_df.empty and 'ç®€åŒ–äº§å“åç§°' in filtered_df.columns:
            simplified_name = filtered_df['ç®€åŒ–äº§å“åç§°'].iloc[0]
            if not pd.isna(simplified_name) and simplified_name:
                # ç§»é™¤ä»£ç éƒ¨åˆ†ï¼Œåªä¿ç•™ç®€åŒ–äº§å“åç§°éƒ¨åˆ†
                return simplified_name.replace(code, "").strip()

        # å›é€€åˆ°åªæ˜¾ç¤ºäº§å“åç§°ï¼Œä¸æ˜¾ç¤ºä»£ç 
        product_name = filtered_df['äº§å“åç§°'].iloc[0]
        return product_name
    else:
        return code


# å‡½æ•°ï¼šåŠ è½½å®é™…é”€å”®æ•°æ®
@st.cache_data
def load_actual_data(file_path=None):
    """åŠ è½½å®é™…é”€å”®æ•°æ®"""
    try:
        # é»˜è®¤è·¯å¾„æˆ–ç¤ºä¾‹æ•°æ®
        if file_path is None or not os.path.exists(file_path):
            # åˆ›å»ºç¤ºä¾‹æ•°æ®
            return load_sample_actual_data()

        # åŠ è½½æ•°æ®
        df = pd.read_excel(file_path)

        # ç¡®ä¿åˆ—åæ ¼å¼ä¸€è‡´
        required_columns = ['è®¢å•æ—¥æœŸ', 'æ‰€å±åŒºåŸŸ', 'ç”³è¯·äºº', 'äº§å“ä»£ç ', 'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰']

        # å°è¯•åŒ¹é…åˆ—å
        renamed_columns = {}
        for req_col in required_columns:
            matched_cols = [col for col in df.columns if req_col in col]
            if matched_cols:
                renamed_columns[matched_cols[0]] = req_col

        # å¦‚æœæ‰¾åˆ°åŒ¹é…åˆ—ï¼Œé‡å‘½å
        if renamed_columns:
            df = df.rename(columns=renamed_columns)

        # æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±åˆ—
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            st.error(f"å®é™…é”€å”®æ•°æ®æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åˆ—: {', '.join(missing_columns)}ã€‚ä½¿ç”¨ç¤ºä¾‹æ•°æ®è¿›è¡Œæ¼”ç¤ºã€‚")
            return load_sample_actual_data()

        # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
        df['è®¢å•æ—¥æœŸ'] = pd.to_datetime(df['è®¢å•æ—¥æœŸ'])
        df['æ‰€å±åŒºåŸŸ'] = df['æ‰€å±åŒºåŸŸ'].astype(str)
        df['ç”³è¯·äºº'] = df['ç”³è¯·äºº'].astype(str)
        df['äº§å“ä»£ç '] = df['äº§å“ä»£ç '].astype(str)
        df['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] = pd.to_numeric(df['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'], errors='coerce')

        # åˆ›å»ºå¹´æœˆå­—æ®µï¼Œç”¨äºä¸é¢„æµ‹æ•°æ®å¯¹é½
        df['æ‰€å±å¹´æœˆ'] = df['è®¢å•æ—¥æœŸ'].dt.strftime('%Y-%m')

        return df

    except Exception as e:
        st.error(f"åŠ è½½å®é™…é”€å”®æ•°æ®æ—¶å‡ºé”™: {str(e)}ã€‚ä½¿ç”¨ç¤ºä¾‹æ•°æ®è¿›è¡Œæ¼”ç¤ºã€‚")
        return load_sample_actual_data()


# å‡½æ•°ï¼šåŠ è½½é¢„æµ‹æ•°æ®
@st.cache_data
def load_forecast_data(file_path=None):
    """åŠ è½½é¢„æµ‹æ•°æ®"""
    try:
        # é»˜è®¤è·¯å¾„æˆ–ç¤ºä¾‹æ•°æ®
        if file_path is None or not os.path.exists(file_path):
            # åˆ›å»ºç¤ºä¾‹æ•°æ®
            return load_sample_forecast_data()

        # åŠ è½½æ•°æ®
        df = pd.read_excel(file_path)

        # ç¡®ä¿åˆ—åæ ¼å¼ä¸€è‡´
        required_columns = ['æ‰€å±å¤§åŒº', 'é”€å”®å‘˜', 'æ‰€å±å¹´æœˆ', 'äº§å“ä»£ç ', 'é¢„è®¡é”€å”®é‡']

        # å°è¯•åŒ¹é…åˆ—å
        renamed_columns = {}
        for req_col in required_columns:
            matched_cols = [col for col in df.columns if req_col in col]
            if matched_cols:
                renamed_columns[matched_cols[0]] = req_col

        # å¦‚æœæ‰¾åˆ°åŒ¹é…åˆ—ï¼Œé‡å‘½å
        if renamed_columns:
            df = df.rename(columns=renamed_columns)

        # æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±åˆ—
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            st.error(f"é¢„æµ‹æ•°æ®æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åˆ—: {', '.join(missing_columns)}ã€‚ä½¿ç”¨ç¤ºä¾‹æ•°æ®è¿›è¡Œæ¼”ç¤ºã€‚")
            return load_sample_forecast_data()

        # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
        df['æ‰€å±å¤§åŒº'] = df['æ‰€å±å¤§åŒº'].astype(str)
        df['é”€å”®å‘˜'] = df['é”€å”®å‘˜'].astype(str)
        df['æ‰€å±å¹´æœˆ'] = pd.to_datetime(df['æ‰€å±å¹´æœˆ']).dt.strftime('%Y-%m')
        df['äº§å“ä»£ç '] = df['äº§å“ä»£ç '].astype(str)
        df['é¢„è®¡é”€å”®é‡'] = pd.to_numeric(df['é¢„è®¡é”€å”®é‡'], errors='coerce')

        # ä¸ºäº†ä¿æŒä¸€è‡´ï¼Œå°†'æ‰€å±å¤§åŒº'åˆ—é‡å‘½åä¸º'æ‰€å±åŒºåŸŸ'
        df = df.rename(columns={'æ‰€å±å¤§åŒº': 'æ‰€å±åŒºåŸŸ'})

        return df

    except Exception as e:
        st.error(f"åŠ è½½é¢„æµ‹æ•°æ®æ—¶å‡ºé”™: {str(e)}ã€‚ä½¿ç”¨ç¤ºä¾‹æ•°æ®è¿›è¡Œæ¼”ç¤ºã€‚")
        return load_sample_forecast_data()


# å‡½æ•°ï¼šåˆ›å»ºç¤ºä¾‹é”€å”®æ•°æ®
def load_sample_actual_data():
    """åˆ›å»ºç¤ºä¾‹å®é™…é”€å”®æ•°æ®"""
    # äº§å“ä»£ç åˆ—è¡¨
    product_codes = [
        'F0104L', 'F01E4P', 'F01E6C', 'F3406B', 'F3409N', 'F3411A',
        'F01E4B', 'F0183F', 'F0110C', 'F0104J', 'F0104M', 'F0104P',
        'F0110A', 'F0110B', 'F0115C', 'F0101P'
    ]

    # åŒºåŸŸåˆ—è¡¨
    regions = ['åŒ—', 'å—', 'ä¸œ', 'è¥¿']

    # ç”³è¯·äººåˆ—è¡¨
    applicants = ['å­™æ¨', 'ææ ¹', 'å¼ ä¼Ÿ', 'ç‹èŠ³', 'åˆ˜æ¶›', 'é™ˆæ˜']

    # ç”Ÿæˆæ—¥æœŸèŒƒå›´
    start_date = datetime(2023, 9, 1)
    end_date = datetime(2025, 2, 24)
    date_range = pd.date_range(start=start_date, end=end_date, freq='D')

    # åˆ›å»ºæ•°æ®
    data = []
    for date in date_range:
        # ä¸ºæ¯å¤©ç”Ÿæˆéšæœºæ•°é‡çš„è®°å½•
        num_records = np.random.randint(3, 10)

        for _ in range(num_records):
            region = np.random.choice(regions)
            applicant = np.random.choice(applicants)
            product_code = np.random.choice(product_codes)
            quantity = np.random.randint(5, 300)

            data.append({
                'è®¢å•æ—¥æœŸ': date,
                'æ‰€å±åŒºåŸŸ': region,
                'ç”³è¯·äºº': applicant,
                'äº§å“ä»£ç ': product_code,
                'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': quantity
            })

    # åˆ›å»ºDataFrame
    df = pd.DataFrame(data)

    # æ·»åŠ å¹´æœˆå­—æ®µ
    df['æ‰€å±å¹´æœˆ'] = df['è®¢å•æ—¥æœŸ'].dt.strftime('%Y-%m')

    return df


# å‡½æ•°ï¼šåˆ›å»ºç¤ºä¾‹é¢„æµ‹æ•°æ®
def load_sample_forecast_data():
    """åˆ›å»ºç¤ºä¾‹é¢„æµ‹æ•°æ®"""
    # äº§å“ä»£ç åˆ—è¡¨
    product_codes = [
        'F0104L', 'F01E4P', 'F01E6C', 'F3406B', 'F3409N', 'F3411A',
        'F01E4B', 'F0183F', 'F0110C', 'F0104J', 'F0104M', 'F0104P',
        'F0110A', 'F0110B', 'F0115C', 'F0101P'
    ]

    # åŒºåŸŸåˆ—è¡¨
    regions = ['åŒ—', 'å—', 'ä¸œ', 'è¥¿']

    # é”€å”®å‘˜åˆ—è¡¨
    sales_people = ['ææ ¹', 'å¼ ä¼Ÿ', 'ç‹èŠ³', 'åˆ˜æ¶›', 'é™ˆæ˜', 'å­™æ¨']

    # ç”Ÿæˆæœˆä»½èŒƒå›´
    start_date = datetime(2023, 9, 1)
    end_date = datetime(2025, 2, 1)
    month_range = pd.date_range(start=start_date, end=end_date, freq='MS')

    # åˆ›å»ºæ•°æ®
    data = []
    for month in month_range:
        month_str = month.strftime('%Y-%m')

        for region in regions:
            for sales_person in sales_people:
                for product_code in product_codes:
                    # ä½¿ç”¨æ­£æ€åˆ†å¸ƒç”Ÿæˆé¢„æµ‹å€¼ï¼Œä½¿å…¶å˜åŒ–æ›´è‡ªç„¶
                    forecast = max(0, np.random.normal(150, 50))

                    # æœ‰äº›äº§å“å¯èƒ½æ²¡æœ‰é¢„æµ‹
                    if np.random.random() > 0.1:  # 90%çš„æ¦‚ç‡æœ‰é¢„æµ‹
                        data.append({
                            'æ‰€å±åŒºåŸŸ': region,
                            'é”€å”®å‘˜': sales_person,
                            'æ‰€å±å¹´æœˆ': month_str,
                            'äº§å“ä»£ç ': product_code,
                            'é¢„è®¡é”€å”®é‡': round(forecast)
                        })

    # åˆ›å»ºDataFrame
    df = pd.DataFrame(data)
    return df


# å‡½æ•°ï¼šåŠ è½½åº“å­˜æ•°æ®
@st.cache_data
def load_inventory_data(file_path=None):
    """åŠ è½½åº“å­˜æ•°æ®å’Œæ‰¹æ¬¡ä¿¡æ¯"""
    try:
        # é»˜è®¤è·¯å¾„æˆ–ç¤ºä¾‹æ•°æ®
        if file_path is None or not os.path.exists(file_path):
            # åˆ›å»ºç¤ºä¾‹æ•°æ®
            return load_sample_inventory_data()

        # åŠ è½½æ•°æ®
        inventory_raw = pd.read_excel(file_path, header=0)

        # ç¡®å®šåˆ—åå½¢å¼
        expected_columns = ['ç‰©æ–™', 'æè¿°', 'ç°æœ‰åº“å­˜', 'å·²åˆ†é…é‡', 'ç°æœ‰åº“å­˜å¯è®¢é‡', 'å¾…å…¥åº“é‡', 'æœ¬æœˆå‰©ä½™å¯è®¢é‡',
                            'åº“ä½', 'ç”Ÿäº§æ—¥æœŸ', 'ç”Ÿäº§æ‰¹å·', 'æ•°é‡']

        # æ£€æŸ¥åˆ—åæ˜¯å¦å­˜åœ¨
        missing_main_columns = [col for col in expected_columns[:7] if
                                not any(col in str(c) for c in inventory_raw.columns)]
        if missing_main_columns:
            st.error(f"åº“å­˜æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„ä¸»è¦åˆ—: {', '.join(missing_main_columns)}ã€‚ä½¿ç”¨ç¤ºä¾‹æ•°æ®è¿›è¡Œæ¼”ç¤ºã€‚")
            return load_sample_inventory_data()

        # å¤„ç†ç¬¬ä¸€å±‚æ•°æ®ï¼ˆäº§å“ä¿¡æ¯ï¼‰
        product_rows = inventory_raw[inventory_raw.iloc[:, 0].notna()]
        inventory_data = product_rows.iloc[:, :7].copy()
        inventory_data.columns = ['äº§å“ä»£ç ', 'æè¿°', 'ç°æœ‰åº“å­˜', 'å·²åˆ†é…é‡',
                                  'ç°æœ‰åº“å­˜å¯è®¢é‡', 'å¾…å…¥åº“é‡', 'æœ¬æœˆå‰©ä½™å¯è®¢é‡']

        # åˆ›å»ºæ‰¹æ¬¡ä¿¡æ¯
        batch_with_product = []
        product_code = None
        product_description = None

        for i, row in inventory_raw.iterrows():
            if pd.notna(row.iloc[0]):
                # è¿™æ˜¯äº§å“è¡Œ
                product_code = row.iloc[0]
                product_description = row.iloc[1]
            elif i < len(inventory_raw) - 1 and pd.notna(row.iloc[7]):
                # è¿™æ˜¯æ‰¹æ¬¡è¡Œ
                batch_row = row.iloc[7:].copy()
                batch_row_with_product = pd.Series([product_code, product_description] + batch_row.tolist())
                batch_with_product.append(batch_row_with_product)

        # åˆ›å»ºæ‰¹æ¬¡æ•°æ®DataFrame
        if batch_with_product:
            batch_data = pd.DataFrame(batch_with_product)
            batch_data.columns = ['äº§å“ä»£ç ', 'æè¿°', 'åº“ä½', 'ç”Ÿäº§æ—¥æœŸ', 'ç”Ÿäº§æ‰¹å·', 'æ•°é‡']

            # è½¬æ¢æ—¥æœŸåˆ—
            batch_data['ç”Ÿäº§æ—¥æœŸ'] = pd.to_datetime(batch_data['ç”Ÿäº§æ—¥æœŸ'], errors='coerce')

            # è½¬æ¢æ•°é‡åˆ—ä¸ºæ•°å­—
            batch_data['æ•°é‡'] = pd.to_numeric(batch_data['æ•°é‡'], errors='coerce')

            # è®¡ç®—æ‰¹æ¬¡ä»·å€¼å’Œåº“é¾„
            today = datetime.now().date()
            batch_data['åº“é¾„'] = batch_data['ç”Ÿäº§æ—¥æœŸ'].apply(
                lambda x: (today - x.date()).days if pd.notna(x) else 0
            )

            return inventory_data, batch_data

        return inventory_data, pd.DataFrame(
            columns=['äº§å“ä»£ç ', 'æè¿°', 'åº“ä½', 'ç”Ÿäº§æ—¥æœŸ', 'ç”Ÿäº§æ‰¹å·', 'æ•°é‡', 'åº“é¾„'])

    except Exception as e:
        st.error(f"åŠ è½½åº“å­˜æ•°æ®æ—¶å‡ºé”™: {str(e)}ã€‚ä½¿ç”¨ç¤ºä¾‹æ•°æ®è¿›è¡Œæ¼”ç¤ºã€‚")
        return load_sample_inventory_data()


# å‡½æ•°ï¼šåˆ›å»ºç¤ºä¾‹åº“å­˜æ•°æ®
def load_sample_inventory_data():
    """åˆ›å»ºç¤ºä¾‹åº“å­˜æ•°æ®å’Œæ‰¹æ¬¡ä¿¡æ¯"""
    # äº§å“ä»£ç åˆ—è¡¨
    product_codes = [
        'F0101P', 'F0104J', 'F0104L', 'F0104M', 'F0104P',
        'F0110A', 'F0110C', 'F01C5D', 'F01E4B', 'F01A3C'
    ]

    # æè¿°åˆ—è¡¨
    descriptions = [
        'å£åŠ›æ±‰å ¡90Gç›´ç«‹è¢‹è£…-ä¸­å›½', 'å£åŠ›æ¯”è¨XXL45Gç›’è£…-ä¸­å›½', 'å£åŠ›æ¯”è¨68Gè¢‹è£…-ä¸­å›½',
        'å£åŠ›æ¯”è¨1KGæ•£è£…-ä¸­å›½', 'å£åŠ›æ¯”è¨24ç‰‡ç›’è£…-ä¸­å›½', 'å£åŠ›è–¯æ¡65g-ä¸­å›½',
        'å£åŠ›å¥¶é…ª90g-ä¸­å›½', 'å£åŠ›æ¬¢ä¹æ´¾å¯¹100Gè¢‹è£…ï¼ˆæ°¸æ—ºä¸“ä¾›ï¼‰-ä¸­å›½',
        'å£åŠ›æ±‰å ¡137g-ä¸­å›½', 'å£åŠ›èŠå£«è›‹ç³•24ç‰‡ç›’è£…-ä¸­å›½'
    ]

    # åˆ›å»ºåº“å­˜æ•°æ®
    inventory_data = []
    for code, desc in zip(product_codes, descriptions):
        current_stock = np.random.randint(200, 3000)
        allocated = np.random.randint(0, 300)
        available = current_stock - allocated
        pending = np.random.randint(0, 500)
        remaining = available + pending

        inventory_data.append({
            'äº§å“ä»£ç ': code,
            'æè¿°': desc,
            'ç°æœ‰åº“å­˜': current_stock,
            'å·²åˆ†é…é‡': allocated,
            'ç°æœ‰åº“å­˜å¯è®¢é‡': available,
            'å¾…å…¥åº“é‡': pending,
            'æœ¬æœˆå‰©ä½™å¯è®¢é‡': remaining
        })

    # åˆ›å»ºæ‰¹æ¬¡æ•°æ®
    batch_data = []
    today = datetime.now().date()

    for i, (code, desc) in enumerate(zip(product_codes, descriptions)):
        # ä¸ºæ¯ä¸ªäº§å“ç”Ÿæˆ2-5ä¸ªæ‰¹æ¬¡
        num_batches = np.random.randint(2, 6)

        for j in range(num_batches):
            # ç”Ÿæˆéšæœºçš„ç”Ÿäº§æ—¥æœŸ
            days_ago = np.random.randint(10, 300)  # 10-300å¤©å‰çš„æ‰¹æ¬¡
            production_date = today - timedelta(days=days_ago)

            # ç”Ÿæˆæ‰¹å·
            batch_number = f"{production_date.strftime('%Y%m%d')}L:0{75000 + i * 100 + j}"

            # ç”Ÿæˆéšæœºæ•°é‡
            quantity = np.random.randint(20, 1000)

            batch_data.append({
                'äº§å“ä»£ç ': code,
                'æè¿°': desc,
                'åº“ä½': f"DC-{np.random.randint(0, 10):03d}",
                'ç”Ÿäº§æ—¥æœŸ': production_date,
                'ç”Ÿäº§æ‰¹å·': batch_number,
                'æ•°é‡': quantity,
                'åº“é¾„': days_ago
            })

    # åˆ›å»ºDataFrames
    inventory_df = pd.DataFrame(inventory_data)
    batch_df = pd.DataFrame(batch_data)

    # ç‰¹åˆ«å¤„ç†F0101Pçš„æ•°æ®ï¼Œè®©å®ƒç¬¦åˆé™„ä»¶ä¸‰ä¸­çš„ä¾‹å­
    if 'F0101P' in inventory_df['äº§å“ä»£ç '].values:
        # æ‰¾åˆ°F0101Pçš„ç´¢å¼•
        idx = inventory_df[inventory_df['äº§å“ä»£ç '] == 'F0101P'].index[0]
        inventory_df.loc[idx, 'ç°æœ‰åº“å­˜'] = 2581
        inventory_df.loc[idx, 'å·²åˆ†é…é‡'] = 20
        inventory_df.loc[idx, 'ç°æœ‰åº“å­˜å¯è®¢é‡'] = 2561
        inventory_df.loc[idx, 'æœ¬æœˆå‰©ä½™å¯è®¢é‡'] = 2561

        # ä¸ºF0101Påˆ›å»ºç‰¹å®šæ‰¹æ¬¡
        f0101p_batches = [
            {
                'äº§å“ä»£ç ': 'F0101P',
                'æè¿°': 'å£åŠ›æ±‰å ¡90Gç›´ç«‹è¢‹è£…-ä¸­å›½',
                'åº“ä½': 'DC-000',
                'ç”Ÿäº§æ—¥æœŸ': datetime(2025, 3, 5),
                'ç”Ÿäº§æ‰¹å·': '20250305L:075064',
                'æ•°é‡': 654,
                'åº“é¾„': 68
            }
        ]

        # æ‰¾åˆ°å¹¶æ›¿æ¢F0101Pæ‰¹æ¬¡
        batch_df = batch_df[batch_df['äº§å“ä»£ç '] != 'F0101P']
        for batch in f0101p_batches:
            batch_df = pd.concat([batch_df, pd.DataFrame([batch])], ignore_index=True)

    # ç‰¹åˆ«å¤„ç†F01C5Dçš„æ•°æ®ï¼Œè®©å®ƒç¬¦åˆé™„ä»¶ä¸‰ä¸­çš„ä¾‹å­
    if 'F01C5D' in inventory_df['äº§å“ä»£ç '].values:
        # ä¸ºF01C5Dåˆ›å»ºç‰¹å®šæ‰¹æ¬¡
        f01c5d_batches = [
            {
                'äº§å“ä»£ç ': 'F01C5D',
                'æè¿°': 'å£åŠ›æ¬¢ä¹æ´¾å¯¹100Gè¢‹è£…ï¼ˆæ°¸æ—ºä¸“ä¾›ï¼‰-ä¸­å›½',
                'åº“ä½': 'DC-000',
                'ç”Ÿäº§æ—¥æœŸ': datetime(2024, 9, 10),
                'ç”Ÿäº§æ‰¹å·': '20240910L:074123',
                'æ•°é‡': 252,
                'åº“é¾„': 244
            }
        ]

        # æ‰¾åˆ°å¹¶æ›¿æ¢F01C5Dæ‰¹æ¬¡
        batch_df = batch_df[batch_df['äº§å“ä»£ç '] != 'F01C5D']
        for batch in f01c5d_batches:
            batch_df = pd.concat([batch_df, pd.DataFrame([batch])], ignore_index=True)

    # ç‰¹åˆ«å¤„ç†F01A3Cçš„æ•°æ®ï¼Œè®©å®ƒç¬¦åˆé™„ä»¶ä¸‰ä¸­çš„ä¾‹å­
    if 'F01A3C' in inventory_df['äº§å“ä»£ç '].values:
        # ä¸ºF01A3Cåˆ›å»ºç‰¹å®šæ‰¹æ¬¡
        f01a3c_batches = [
            {
                'äº§å“ä»£ç ': 'F01A3C',
                'æè¿°': 'å£åŠ›èŠå£«è›‹ç³•24ç‰‡ç›’è£…-ä¸­å›½',
                'åº“ä½': 'DC-000',
                'ç”Ÿäº§æ—¥æœŸ': datetime(2024, 10, 7),
                'ç”Ÿäº§æ‰¹å·': '20241007L:074234',
                'æ•°é‡': 16,
                'åº“é¾„': 217
            }
        ]

        # æ‰¾åˆ°å¹¶æ›¿æ¢F01A3Cæ‰¹æ¬¡
        batch_df = batch_df[batch_df['äº§å“ä»£ç '] != 'F01A3C']
        for batch in f01a3c_batches:
            batch_df = pd.concat([batch_df, pd.DataFrame([batch])], ignore_index=True)

    return inventory_df, batch_df


# å‡½æ•°ï¼šè·å–å…±åŒæœˆä»½
def get_common_months(actual_df, forecast_df):
    """è·å–ä¸¤ä¸ªæ•°æ®é›†å…±æœ‰çš„æœˆä»½"""
    actual_months = set(actual_df['æ‰€å±å¹´æœˆ'].unique())
    forecast_months = set(forecast_df['æ‰€å±å¹´æœˆ'].unique())
    common_months = sorted(list(actual_months.intersection(forecast_months)))
    return common_months


# å‡½æ•°ï¼šè·å–æœ€è¿‘3ä¸ªæœˆ
def get_last_three_months():
    today = datetime.now()
    current_month = today.replace(day=1)

    last_month = current_month - timedelta(days=1)
    last_month = last_month.replace(day=1)

    two_months_ago = last_month - timedelta(days=1)
    two_months_ago = two_months_ago.replace(day=1)

    months = []
    for dt in [two_months_ago, last_month, current_month]:
        months.append(dt.strftime('%Y-%m'))

    return months


# å‡½æ•°ï¼šç­›é€‰æ•°æ®
def filter_data(data, months=None, regions=None):
    """ç»Ÿä¸€çš„æ•°æ®ç­›é€‰å‡½æ•°"""
    filtered_data = data.copy()

    if months and len(months) > 0:
        filtered_data = filtered_data[filtered_data['æ‰€å±å¹´æœˆ'].isin(months)]

    if regions and len(regions) > 0:
        filtered_data = filtered_data[filtered_data['æ‰€å±åŒºåŸŸ'].isin(regions)]

    return filtered_data


# å‡½æ•°ï¼šå¤„ç†å’Œåˆ†ææ•°æ®
def process_data(actual_df, forecast_df, product_info_df):
    """å¤„ç†æ•°æ®å¹¶è®¡ç®—å…³é”®æŒ‡æ ‡"""
    # æŒ‰æœˆä»½ã€åŒºåŸŸã€äº§å“ç æ±‡æ€»æ•°æ®
    actual_monthly = actual_df.groupby(['æ‰€å±å¹´æœˆ', 'æ‰€å±åŒºåŸŸ', 'äº§å“ä»£ç ']).agg({
        'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum'
    }).reset_index()

    forecast_monthly = forecast_df.groupby(['æ‰€å±å¹´æœˆ', 'æ‰€å±åŒºåŸŸ', 'äº§å“ä»£ç ']).agg({
        'é¢„è®¡é”€å”®é‡': 'sum'
    }).reset_index()

    # æŒ‰é”€å”®å‘˜ç»†åˆ†çš„é¢„æµ‹æ•°æ®
    forecast_by_salesperson = forecast_df.groupby(['æ‰€å±å¹´æœˆ', 'æ‰€å±åŒºåŸŸ', 'é”€å”®å‘˜', 'äº§å“ä»£ç ']).agg({
        'é¢„è®¡é”€å”®é‡': 'sum'
    }).reset_index()

    # å®é™…æŒ‰é”€å”®å‘˜ç»†åˆ†çš„æ•°æ®
    actual_by_salesperson = actual_df.groupby(['æ‰€å±å¹´æœˆ', 'æ‰€å±åŒºåŸŸ', 'ç”³è¯·äºº', 'äº§å“ä»£ç ']).agg({
        'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum'
    }).reset_index()

    # é‡å‘½ååˆ—ï¼Œä½¿åˆå¹¶æ›´å®¹æ˜“
    actual_by_salesperson = actual_by_salesperson.rename(columns={'ç”³è¯·äºº': 'é”€å”®å‘˜'})

    # åˆå¹¶é¢„æµ‹å’Œå®é™…æ•°æ®
    # æŒ‰åŒºåŸŸå’Œäº§å“çº§åˆ«
    merged_monthly = pd.merge(
        actual_monthly,
        forecast_monthly,
        on=['æ‰€å±å¹´æœˆ', 'æ‰€å±åŒºåŸŸ', 'äº§å“ä»£ç '],
        how='outer'
    )

    # æŒ‰é”€å”®å‘˜çº§åˆ«
    merged_by_salesperson = pd.merge(
        actual_by_salesperson,
        forecast_by_salesperson,
        on=['æ‰€å±å¹´æœˆ', 'æ‰€å±åŒºåŸŸ', 'é”€å”®å‘˜', 'äº§å“ä»£ç '],
        how='outer'
    )

    # å¡«å……ç¼ºå¤±å€¼ä¸º0
    for df in [merged_monthly, merged_by_salesperson]:
        df['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] = df['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].fillna(0)
        df['é¢„è®¡é”€å”®é‡'] = df['é¢„è®¡é”€å”®é‡'].fillna(0)

    # è®¡ç®—å·®å¼‚å’Œå‡†ç¡®ç‡
    for df in [merged_monthly, merged_by_salesperson]:
        # å·®å¼‚
        df['æ•°é‡å·®å¼‚'] = df['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] - df['é¢„è®¡é”€å”®é‡']

        # å·®å¼‚ç‡ (é¿å…é™¤ä»¥é›¶)
        df['æ•°é‡å·®å¼‚ç‡'] = np.where(
            df['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] > 0,
            df['æ•°é‡å·®å¼‚'] / df['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] * 100,
            np.where(
                df['é¢„è®¡é”€å”®é‡'] > 0,
                -100,  # é¢„æµ‹æœ‰å€¼ä½†å®é™…ä¸º0
                0  # é¢„æµ‹å’Œå®é™…éƒ½æ˜¯0
            )
        )

        # å‡†ç¡®ç‡
        df['æ•°é‡å‡†ç¡®ç‡'] = np.where(
            (df['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] > 0) | (df['é¢„è®¡é”€å”®é‡'] > 0),
            np.maximum(0, 100 - np.abs(df['æ•°é‡å·®å¼‚ç‡'])) / 100,
            1  # é¢„æµ‹å’Œå®é™…éƒ½æ˜¯0æ—¶å‡†ç¡®ç‡ä¸º100%
        )

    # è®¡ç®—æ€»ä½“å‡†ç¡®ç‡
    national_accuracy = calculate_national_accuracy(merged_monthly)
    regional_accuracy = calculate_regional_accuracy(merged_monthly)

    # è®¡ç®—å æ¯”80%çš„SKU
    national_top_skus = calculate_top_skus(merged_monthly, by_region=False)
    regional_top_skus = calculate_top_skus(merged_monthly, by_region=True)

    return {
        'actual_monthly': actual_monthly,
        'forecast_monthly': forecast_monthly,
        'merged_monthly': merged_monthly,
        'merged_by_salesperson': merged_by_salesperson,
        'national_accuracy': national_accuracy,
        'regional_accuracy': regional_accuracy,
        'national_top_skus': national_top_skus,
        'regional_top_skus': regional_top_skus
    }


# å‡½æ•°ï¼šè®¡ç®—å…¨å›½å‡†ç¡®ç‡
def calculate_national_accuracy(merged_df):
    """è®¡ç®—å…¨å›½çš„é¢„æµ‹å‡†ç¡®ç‡"""
    # æŒ‰æœˆä»½æ±‡æ€»
    monthly_summary = merged_df.groupby('æ‰€å±å¹´æœˆ').agg({
        'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum',
        'é¢„è®¡é”€å”®é‡': 'sum'
    }).reset_index()

    # è®¡ç®—å·®å¼‚
    monthly_summary['æ•°é‡å·®å¼‚'] = monthly_summary['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] - monthly_summary['é¢„è®¡é”€å”®é‡']

    # ä½¿ç”¨ç»Ÿä¸€å‡½æ•°è®¡ç®—å‡†ç¡®ç‡
    monthly_summary['æ•°é‡å‡†ç¡®ç‡'] = monthly_summary.apply(
        lambda row: calculate_unified_accuracy(row['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'], row['é¢„è®¡é”€å”®é‡']),
        axis=1
    )

    # è®¡ç®—æ•´ä½“å¹³å‡å‡†ç¡®ç‡ (ä½¿ç”¨å®‰å…¨å‡å€¼è®¡ç®—)
    overall = {
        'æ•°é‡å‡†ç¡®ç‡': safe_mean(monthly_summary['æ•°é‡å‡†ç¡®ç‡'], 0)
    }

    return {
        'monthly': monthly_summary,
        'overall': overall
    }


# å‡½æ•°ï¼šè®¡ç®—åŒºåŸŸå‡†ç¡®ç‡
def calculate_regional_accuracy(merged_df):
    """è®¡ç®—å„åŒºåŸŸçš„é¢„æµ‹å‡†ç¡®ç‡"""
    # æŒ‰æœˆä»½å’ŒåŒºåŸŸæ±‡æ€»
    region_monthly_summary = merged_df.groupby(['æ‰€å±å¹´æœˆ', 'æ‰€å±åŒºåŸŸ']).agg({
        'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum',
        'é¢„è®¡é”€å”®é‡': 'sum'
    }).reset_index()

    # è®¡ç®—å·®å¼‚
    region_monthly_summary['æ•°é‡å·®å¼‚'] = region_monthly_summary['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] - region_monthly_summary[
        'é¢„è®¡é”€å”®é‡']

    # ä½¿ç”¨ç»Ÿä¸€å‡½æ•°è®¡ç®—å‡†ç¡®ç‡
    region_monthly_summary['æ•°é‡å‡†ç¡®ç‡'] = region_monthly_summary.apply(
        lambda row: calculate_unified_accuracy(row['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'], row['é¢„è®¡é”€å”®é‡']),
        axis=1
    )

    # æŒ‰åŒºåŸŸè®¡ç®—å¹³å‡å‡†ç¡®ç‡ (ä½¿ç”¨å®‰å…¨å‡å€¼è®¡ç®—)
    region_overall = region_monthly_summary.groupby('æ‰€å±åŒºåŸŸ').agg({
        'æ•°é‡å‡†ç¡®ç‡': lambda x: safe_mean(x, 0)
    }).reset_index()

    return {
        'region_monthly': region_monthly_summary,
        'region_overall': region_overall
    }


# å‡½æ•°ï¼šè®¡ç®—äº§å“å¢é•¿ç‡
@st.cache_data
def calculate_product_growth(actual_monthly, regions=None, months=None, growth_min=-100, growth_max=500):
    """
    è®¡ç®—äº§å“é”€é‡å¢é•¿ç‡ï¼Œç”¨äºç”Ÿæˆå¤‡è´§å»ºè®®

    è®¡ç®—é€»è¾‘ï¼š
    1. ä¼˜å…ˆè®¡ç®—åŒæ¯”å¢é•¿ç‡ï¼šå½“å‰æœˆä¸å»å¹´åŒæœˆæ¯”è¾ƒ
    2. è‹¥æ— åŒæ¯”æ•°æ®ï¼Œåˆ™è®¡ç®—ç¯æ¯”å¢é•¿ç‡ï¼šå½“å‰æœˆä¸ä¸Šæœˆæ¯”è¾ƒ
    3. æ ¹æ®å¢é•¿ç‡ç»™å‡ºå¤‡è´§å»ºè®®

    å‚æ•°:
    - actual_monthly: å®é™…é”€å”®æ•°æ®
    - regions: åŒºåŸŸç­›é€‰
    - months: æœˆä»½ç­›é€‰
    - growth_min/max: å¢é•¿ç‡å¼‚å¸¸å€¼æˆªæ–­èŒƒå›´

    è¿”å›:
    - all_growth: æ‰€æœ‰äº§å“å¢é•¿ç‡æ•°æ®
    - latest_growth: æœ€æ–°æœˆä»½çš„å¢é•¿ç‡æ•°æ®ï¼ŒåŒ…å«è¶‹åŠ¿ä¸å¤‡è´§å»ºè®®
    """
    # ç¡®ä¿æ•°æ®æŒ‰æ—¶é—´æ’åº
    actual_monthly['æ‰€å±å¹´æœˆ'] = pd.to_datetime(actual_monthly['æ‰€å±å¹´æœˆ'])
    actual_monthly = actual_monthly.sort_values('æ‰€å±å¹´æœˆ')

    # åº”ç”¨åŒºåŸŸç­›é€‰
    if regions and len(regions) > 0:
        filtered_data = actual_monthly[actual_monthly['æ‰€å±åŒºåŸŸ'].isin(regions)]
    else:
        filtered_data = actual_monthly  # å¦‚æœæ²¡æœ‰åŒºåŸŸç­›é€‰ï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®

    # åº”ç”¨æœˆä»½ç­›é€‰
    if months and len(months) > 0:
        months_datetime = pd.to_datetime(months)
        filtered_data = filtered_data[filtered_data['æ‰€å±å¹´æœˆ'].isin(months_datetime)]

    # æŒ‰äº§å“å’Œæœˆä»½æ±‡æ€»ç­›é€‰åçš„åŒºåŸŸé”€é‡
    filtered_monthly_sales = filtered_data.groupby(['æ‰€å±å¹´æœˆ', 'äº§å“ä»£ç ']).agg({
        'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum'
    }).reset_index()

    # åˆ›å»ºå¹´å’Œæœˆå­—æ®µ
    filtered_monthly_sales['å¹´'] = filtered_monthly_sales['æ‰€å±å¹´æœˆ'].dt.year
    filtered_monthly_sales['æœˆ'] = filtered_monthly_sales['æ‰€å±å¹´æœˆ'].dt.month

    # å‡†å¤‡ç”¨äºè®¡ç®—å¢é•¿ç‡çš„æ•°æ®ç»“æ„
    growth_data = []

    # è·å–æ‰€æœ‰äº§å“çš„å”¯ä¸€åˆ—è¡¨
    products = filtered_monthly_sales['äº§å“ä»£ç '].unique()

    # è·å–æ‰€æœ‰å¹´ä»½å’Œæœˆä»½
    years = filtered_monthly_sales['å¹´'].unique()
    years.sort()

    # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œå¢é•¿ç‡è®¡ç®—
    if len(filtered_monthly_sales) > 0:
        # ä¸ºæ¯ä¸ªäº§å“è®¡ç®—æœˆåº¦å¢é•¿ç‡
        for product in products:
            product_data = filtered_monthly_sales[filtered_monthly_sales['äº§å“ä»£ç '] == product]

            # æŒ‰å¹´æœˆå¯¹äº§å“é”€é‡è¿›è¡Œæ’åº
            product_data = product_data.sort_values(['å¹´', 'æœˆ'])

            # å¦‚æœäº§å“æœ‰å¤šä¸ªæœˆçš„æ•°æ®ï¼Œè®¡ç®—ç¯æ¯”å¢é•¿ç‡ï¼ˆä¸ä¸Šæœˆç›¸æ¯”ï¼‰
            if len(product_data) > 1:
                for i in range(1, len(product_data)):
                    current_row = product_data.iloc[i]
                    prev_row = product_data.iloc[i - 1]

                    # è®¡ç®—å½“å‰æœˆç¯æ¯”å¢é•¿ç‡
                    current_sales = current_row['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰']
                    prev_sales = prev_row['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰']

                    if prev_sales > 0:
                        growth_rate = (current_sales - prev_sales) / prev_sales * 100
                        # é™åˆ¶å¼‚å¸¸å€¼
                        growth_rate = max(min(growth_rate, growth_max), growth_min)
                    else:
                        growth_rate = 0 if current_sales == 0 else 100

                    # è®°å½•ç¯æ¯”å¢é•¿ç‡æ•°æ®
                    growth_data.append({
                        'äº§å“ä»£ç ': product,
                        'å¹´': current_row['å¹´'],
                        'æœˆ': current_row['æœˆ'],
                        'å½“æœˆé”€é‡': current_sales,
                        'ä¸Šæœˆé”€é‡': prev_sales,
                        'é”€é‡å¢é•¿ç‡': growth_rate,
                        'è®¡ç®—æ–¹å¼': 'ç¯æ¯”'  # æ ‡è®°ä¸ºç¯æ¯”è®¡ç®—
                    })

            # å°è¯•è®¡ç®—åŒæœŸåŒæ¯”å¢é•¿ç‡ï¼ˆå¦‚æœæœ‰å‰ä¸€å¹´çš„æ•°æ®ï¼‰- ä¼˜å…ˆä½¿ç”¨åŒæ¯”æ•°æ®
            if len(years) > 1:
                for year in years[1:]:  # ä»ç¬¬äºŒå¹´å¼€å§‹
                    prev_year = year - 1

                    # è·å–å½“å‰å¹´å’Œå‰ä¸€å¹´çš„æ•°æ®
                    current_year_data = product_data[product_data['å¹´'] == year]
                    prev_year_data = product_data[product_data['å¹´'] == prev_year]

                    # ä¸ºæ¯ä¸ªæœˆè®¡ç®—åŒæ¯”å¢é•¿ç‡
                    for _, curr_row in current_year_data.iterrows():
                        curr_month = curr_row['æœˆ']
                        curr_sales = curr_row['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰']

                        # å¯»æ‰¾å‰ä¸€å¹´åŒæœˆæ•°æ®
                        prev_month_data = prev_year_data[prev_year_data['æœˆ'] == curr_month]

                        if not prev_month_data.empty:
                            prev_sales = prev_month_data.iloc[0]['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰']

                            if prev_sales > 0:
                                yoy_growth_rate = (curr_sales - prev_sales) / prev_sales * 100
                                # é™åˆ¶å¼‚å¸¸å€¼
                                yoy_growth_rate = max(min(yoy_growth_rate, growth_max), growth_min)
                            else:
                                yoy_growth_rate = 0 if curr_sales == 0 else 100

                            # è®°å½•åŒæ¯”å¢é•¿ç‡
                            # ä¼˜å…ˆä½¿ç”¨åŒæ¯”æ•°æ®ï¼ˆæ›¿æ¢ä¹‹å‰çš„ç¯æ¯”æ•°æ®ï¼Œå¦‚æœå­˜åœ¨ï¼‰
                            existing_entry = next((item for item in growth_data if
                                                   item['äº§å“ä»£ç '] == product and
                                                   item['å¹´'] == year and
                                                   item['æœˆ'] == curr_month), None)

                            if existing_entry:
                                existing_entry['é”€é‡å¢é•¿ç‡'] = yoy_growth_rate
                                existing_entry['åŒæ¯”ä¸Šå¹´é”€é‡'] = prev_sales
                                existing_entry['è®¡ç®—æ–¹å¼'] = 'åŒæ¯”'  # æ›´æ–°ä¸ºåŒæ¯”è®¡ç®—
                            else:
                                growth_data.append({
                                    'äº§å“ä»£ç ': product,
                                    'å¹´': year,
                                    'æœˆ': curr_month,
                                    'å½“æœˆé”€é‡': curr_sales,
                                    'åŒæ¯”ä¸Šå¹´é”€é‡': prev_sales,
                                    'é”€é‡å¢é•¿ç‡': yoy_growth_rate,
                                    'è®¡ç®—æ–¹å¼': 'åŒæ¯”'  # æ ‡è®°ä¸ºåŒæ¯”è®¡ç®—
                                })

    # åˆ›å»ºå¢é•¿ç‡DataFrame
    growth_df = pd.DataFrame(growth_data)

    # å¦‚æœæœ‰å¢é•¿æ•°æ®ï¼Œæ·»åŠ è¶‹åŠ¿åˆ¤æ–­å’Œå¤‡è´§å»ºè®®
    if not growth_df.empty:
        try:
            # å–æœ€è¿‘ä¸€ä¸ªæœˆçš„å¢é•¿ç‡
            latest_growth = growth_df.sort_values(['å¹´', 'æœˆ'], ascending=False).groupby(
                'äº§å“ä»£ç ').first().reset_index()

            # è¿‡æ»¤æ— æ•ˆå¢é•¿ç‡å€¼
            latest_growth = latest_growth[latest_growth['é”€é‡å¢é•¿ç‡'].notna()]
            latest_growth = latest_growth[np.isfinite(latest_growth['é”€é‡å¢é•¿ç‡'])]

            if not latest_growth.empty:
                # æ·»åŠ è¶‹åŠ¿åˆ¤æ–­
                latest_growth['è¶‹åŠ¿'] = np.where(
                    latest_growth['é”€é‡å¢é•¿ç‡'] > 15, 'å¼ºåŠ²å¢é•¿',
                    np.where(
                        latest_growth['é”€é‡å¢é•¿ç‡'] > 0, 'å¢é•¿',
                        np.where(
                            latest_growth['é”€é‡å¢é•¿ç‡'] > -10, 'è½»å¾®ä¸‹é™',
                            'æ˜¾è‘—ä¸‹é™'
                        )
                    )
                )

                # æ·»åŠ å¤‡è´§å»ºè®®
                latest_growth['å¤‡è´§å»ºè®®å¯¹è±¡'] = latest_growth['é”€é‡å¢é•¿ç‡'].apply(generate_recommendation)
                latest_growth['å¤‡è´§å»ºè®®'] = latest_growth['å¤‡è´§å»ºè®®å¯¹è±¡'].apply(lambda x: x['å»ºè®®'])
                latest_growth['è°ƒæ•´æ¯”ä¾‹'] = latest_growth['å¤‡è´§å»ºè®®å¯¹è±¡'].apply(lambda x: x['è°ƒæ•´æ¯”ä¾‹'])
                latest_growth['å»ºè®®é¢œè‰²'] = latest_growth['å¤‡è´§å»ºè®®å¯¹è±¡'].apply(lambda x: x['é¢œè‰²'])
                latest_growth['å»ºè®®æ ·å¼ç±»'] = latest_growth['å¤‡è´§å»ºè®®å¯¹è±¡'].apply(lambda x: x['æ ·å¼ç±»'])
                latest_growth['å»ºè®®å›¾æ ‡'] = latest_growth['å¤‡è´§å»ºè®®å¯¹è±¡'].apply(lambda x: x['å›¾æ ‡'])
            else:
                # åˆ›å»ºç©ºçš„ç»“æœæ¡†æ¶
                latest_growth = pd.DataFrame(columns=growth_df.columns)
        except Exception as e:
            # è®°å½•é”™è¯¯ä½†ç»§ç»­æ‰§è¡Œ
            print(f"å¤„ç†å¢é•¿ç‡æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            latest_growth = pd.DataFrame(columns=growth_df.columns)

        return {
            'all_growth': growth_df,
            'latest_growth': latest_growth
        }
    else:
        return {
            'all_growth': pd.DataFrame(),
            'latest_growth': pd.DataFrame()
        }


# å‡½æ•°ï¼šè®¡ç®—é‡ç‚¹SKU
def calculate_top_skus(merged_df, by_region=False):
    """è®¡ç®—å é”€å”®é‡80%çš„SKUåŠå…¶å‡†ç¡®ç‡ - ä¿®å¤ç©ºåŒºåŸŸé—®é¢˜"""
    if merged_df.empty:
        return {} if by_region else pd.DataFrame()

    if by_region:
        # æŒ‰åŒºåŸŸã€äº§å“æ±‡æ€»
        grouped = merged_df.groupby(['æ‰€å±åŒºåŸŸ', 'äº§å“ä»£ç ']).agg({
            'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum',
            'é¢„è®¡é”€å”®é‡': 'sum'
        }).reset_index()

        # è®¡ç®—å‡†ç¡®ç‡
        grouped['æ•°é‡å‡†ç¡®ç‡'] = grouped.apply(
            lambda row: calculate_unified_accuracy(row['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'], row['é¢„è®¡é”€å”®é‡']),
            axis=1
        )

        # è®¡ç®—å„åŒºåŸŸçš„å æ¯”80%SKU
        results = {}
        for region in grouped['æ‰€å±åŒºåŸŸ'].unique():
            if pd.isna(region) or region is None or region == 'None':
                continue  # è·³è¿‡ç©ºåŒºåŸŸ

            region_data = grouped[grouped['æ‰€å±åŒºåŸŸ'] == region].copy()
            if region_data.empty:
                continue  # è·³è¿‡æ²¡æœ‰æ•°æ®çš„åŒºåŸŸ

            total_sales = region_data['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].sum()
            if total_sales <= 0:
                continue  # è·³è¿‡é”€å”®é‡ä¸º0çš„åŒºåŸŸ

            # æŒ‰é”€å”®é‡é™åºæ’åº
            region_data = region_data.sort_values('æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰', ascending=False)

            # è®¡ç®—ç´¯è®¡é”€å”®é‡å’Œå æ¯”
            region_data['ç´¯è®¡é”€å”®é‡'] = region_data['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].cumsum()
            region_data['ç´¯è®¡å æ¯”'] = region_data['ç´¯è®¡é”€å”®é‡'] / total_sales * 100

            # ç­›é€‰å æ¯”80%çš„SKU
            top_skus = region_data[region_data['ç´¯è®¡å æ¯”'] <= 80].copy()

            # å¦‚æœæ²¡æœ‰SKUè¾¾åˆ°80%é˜ˆå€¼ï¼Œè‡³å°‘å–å‰3ä¸ªSKU
            if top_skus.empty:
                top_skus = region_data.head(min(3, len(region_data)))

            results[region] = top_skus

        return results
    else:
        # å…¨å›½æ±‡æ€»
        grouped = merged_df.groupby('äº§å“ä»£ç ').agg({
            'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum',
            'é¢„è®¡é”€å”®é‡': 'sum'
        }).reset_index()

        # è®¡ç®—å‡†ç¡®ç‡
        grouped['æ•°é‡å‡†ç¡®ç‡'] = grouped.apply(
            lambda row: calculate_unified_accuracy(row['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'], row['é¢„è®¡é”€å”®é‡']),
            axis=1
        )

        total_sales = grouped['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].sum()
        if total_sales <= 0:
            return pd.DataFrame(columns=grouped.columns)  # è¿”å›ç©ºDataFrameä½†ä¿æŒåˆ—ç»“æ„

        # æŒ‰é”€å”®é‡é™åºæ’åº
        grouped = grouped.sort_values('æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰', ascending=False)

        # è®¡ç®—ç´¯è®¡é”€å”®é‡å’Œå æ¯” - è¿™é‡Œä¿®å¤äº†åˆ—åä¸åŒ¹é…çš„é”™è¯¯
        grouped['ç´¯è®¡é”€å”®é‡'] = grouped['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].cumsum()
        grouped['ç´¯è®¡å æ¯”'] = grouped['ç´¯è®¡é”€å”®é‡'] / total_sales * 100  # ä¿®æ”¹è¿™é‡Œï¼Œä½¿ç”¨"ç´¯è®¡é”€å”®é‡"è€Œä¸æ˜¯"ç´¯è®¡é”€é‡"

        # ç­›é€‰å æ¯”80%çš„SKU
        top_skus = grouped[grouped['ç´¯è®¡å æ¯”'] <= 80].copy()

        # å¦‚æœæ²¡æœ‰SKUè¾¾åˆ°80%é˜ˆå€¼ï¼Œè‡³å°‘å–å‰5ä¸ªSKU
        if top_skus.empty:
            top_skus = grouped.head(min(5, len(grouped)))

        return top_skus


# å‡½æ•°ï¼šåˆ†ææ‰¹æ¬¡é£é™©
def analyze_batch_risk(batch_data, actual_data, forecast_data, prices, min_daily_sales=0.5, min_seasonal_index=0.3):
    """
    åˆ†ææ‰¹æ¬¡é£é™©ï¼Œè®¡ç®—æ‰¹æ¬¡çš„é£é™©ç­‰çº§ã€æ¸…åº“å¤©æ•°å’Œç§¯å‹é£é™©ç­‰

    å‚æ•°:
    batch_data (DataFrame): æ‰¹æ¬¡æ•°æ®
    actual_data (DataFrame): å®é™…é”€å”®æ•°æ®
    forecast_data (DataFrame): é¢„æµ‹æ•°æ®
    prices (dict): äº§å“å•ä»·å­—å…¸
    min_daily_sales (float): æœ€å°æ—¥å‡é”€é‡é˜ˆå€¼ï¼Œé˜²æ­¢æ¸…åº“å¤©æ•°è®¡ç®—ä¸ºæ— ç©·å¤§
    min_seasonal_index (float): å­£èŠ‚æ€§æŒ‡æ•°ä¸‹é™ï¼Œé˜²æ­¢å­£èŠ‚æ€§å¤ªä½å¯¼è‡´è°ƒæ•´åé”€é‡æ¥è¿‘é›¶

    è¿”å›:
    DataFrame: æ‰¹æ¬¡é£é™©åˆ†æç»“æœ
    """
    if batch_data.empty:
        return pd.DataFrame()

    batch_analysis = []
    today = datetime.now().date()

    # è®¡ç®—æ¯ä¸ªäº§å“çš„é”€å”®æŒ‡æ ‡
    product_sales_metrics = {}
    for product_code in batch_data['äº§å“ä»£ç '].unique():
        # è·å–è¯¥äº§å“çš„é”€å”®è®°å½•
        product_sales = actual_data[actual_data['äº§å“ä»£ç '] == product_code]

        if len(product_sales) == 0:
            # æ— é”€å”®è®°å½•
            product_sales_metrics[product_code] = {
                'daily_avg_sales': 0,
                'sales_std': 0,
                'coefficient_of_variation': float('inf'),
                'total_sales': 0,
                'last_90_days_sales': 0,
                'region_sales': {},
                'person_sales': {}
            }
        else:
            # è®¡ç®—æ—¥å‡é”€é‡
            total_sales = product_sales['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].sum()

            # è®¡ç®—è¿‡å»90å¤©çš„é”€é‡
            ninety_days_ago = today - timedelta(days=90)
            recent_sales = product_sales[product_sales['è®¢å•æ—¥æœŸ'].dt.date >= ninety_days_ago]
            recent_sales_total = recent_sales['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].sum() if len(recent_sales) > 0 else 0

            # è®¡ç®—æ—¥å‡é”€é‡
            # ä½¿ç”¨ä»æœ€æ—©è®¢å•åˆ°ä»Šå¤©çš„å¤©æ•°ä½œä¸ºåˆ†æ¯
            days_range = (today - product_sales['è®¢å•æ—¥æœŸ'].min().date()).days + 1
            daily_avg_sales = total_sales / days_range if days_range > 0 else 0

            # è®¡ç®—æ—¥é”€é‡æ ‡å‡†å·®
            # é¦–å…ˆæ„å»ºæ¯æ—¥é”€é‡æ—¶é—´åºåˆ—
            daily_sales = product_sales.groupby(product_sales['è®¢å•æ—¥æœŸ'].dt.date)['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].sum()

            # è®¡ç®—æ ‡å‡†å·®
            sales_std = daily_sales.std() if len(daily_sales) > 1 else 0

            # è®¡ç®—å˜å¼‚ç³»æ•°ï¼ˆæ³¢åŠ¨ç³»æ•°ï¼‰
            coefficient_of_variation = sales_std / daily_avg_sales if daily_avg_sales > 0 else float('inf')

            # æŒ‰åŒºåŸŸå’Œé”€å”®äººå‘˜åˆ†ç»„ç»Ÿè®¡
            region_sales = product_sales.groupby('æ‰€å±åŒºåŸŸ')['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].sum().to_dict()
            person_sales = product_sales.groupby('ç”³è¯·äºº')['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].sum().to_dict()

            # å­˜å‚¨ç»“æœ
            product_sales_metrics[product_code] = {
                'daily_avg_sales': daily_avg_sales,
                'sales_std': sales_std,
                'coefficient_of_variation': coefficient_of_variation,
                'total_sales': total_sales,
                'last_90_days_sales': recent_sales_total,
                'region_sales': region_sales,
                'person_sales': person_sales
            }

    # è®¡ç®—æ¯ä¸ªäº§å“çš„å­£èŠ‚æ€§æŒ‡æ•°
    seasonal_indices = {}
    for product_code in batch_data['äº§å“ä»£ç '].unique():
        product_sales = actual_data[actual_data['äº§å“ä»£ç '] == product_code]

        if len(product_sales) > 0:
            # æŒ‰æœˆåˆ†ç»„é”€é‡
            product_sales['æœˆä»½'] = product_sales['è®¢å•æ—¥æœŸ'].dt.month
            monthly_sales = product_sales.groupby('æœˆä»½')['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].sum()

            if len(monthly_sales) > 1:
                # è®¡ç®—å¹³å‡æœˆé”€é‡
                avg_monthly_sales = monthly_sales.mean()

                # å½“å‰æœˆä»½çš„å­£èŠ‚æ€§æŒ‡æ•°
                current_month = today.month
                if current_month in monthly_sales.index:
                    seasonal_index = monthly_sales[current_month] / avg_monthly_sales
                else:
                    seasonal_index = 1.0  # æ— æ•°æ®æ—¶é»˜è®¤ä¸º1
            else:
                seasonal_index = 1.0  # åªæœ‰ä¸€ä¸ªæœˆçš„æ•°æ®ï¼Œæ— æ³•è®¡ç®—å­£èŠ‚æ€§
        else:
            seasonal_index = 1.0  # æ— é”€å”®æ•°æ®é»˜è®¤ä¸º1

        # åº”ç”¨å­£èŠ‚æ€§æŒ‡æ•°ä¸‹é™ï¼Œé¿å…å› å­£èŠ‚æ€§æä½å¯¼è‡´çš„é—®é¢˜
        seasonal_index = max(seasonal_index, min_seasonal_index)
        seasonal_indices[product_code] = seasonal_index

    # ä¸ºæ¯ä¸ªæ‰¹æ¬¡è®¡ç®—é£é™©æŒ‡æ ‡
    for _, batch in batch_data.iterrows():
        product_code = batch['äº§å“ä»£ç ']
        batch_date = batch['ç”Ÿäº§æ—¥æœŸ']
        batch_qty = batch['æ•°é‡']
        batch_age = batch['åº“é¾„'] if 'åº“é¾„' in batch.index else (today - batch_date.date()).days

        # è·å–é”€å”®æŒ‡æ ‡
        sales_metrics = product_sales_metrics.get(product_code, {
            'daily_avg_sales': 0,
            'sales_std': 0,
            'coefficient_of_variation': float('inf'),
            'total_sales': 0,
            'last_90_days_sales': 0,
            'region_sales': {},
            'person_sales': {}
        })

        # è·å–å­£èŠ‚æ€§æŒ‡æ•°
        seasonal_index = seasonal_indices.get(product_code, 1.0)

        # è·å–äº§å“å•ä»·å¹¶è®¡ç®—æ‰¹æ¬¡ä»·å€¼
        unit_price = prices.get(product_code, 50.0)
        batch_value = batch_qty * unit_price

        # è®¡ç®—é¢„è®¡æ¸…åº“å¤©æ•°
        daily_avg_sales = sales_metrics['daily_avg_sales']

        # è€ƒè™‘å­£èŠ‚æ€§è°ƒæ•´ï¼Œå¹¶åº”ç”¨æœ€å°é”€é‡é˜ˆå€¼
        daily_avg_sales_adjusted = max(daily_avg_sales * seasonal_index, min_daily_sales)

        # è®¡ç®—æ¸…åº“å¤©æ•°å’Œç§¯å‹é£é™©
        if daily_avg_sales_adjusted > 0:
            days_to_clear = batch_qty / daily_avg_sales_adjusted

            # è®¡ç®—é£é™©ç™¾åˆ†æ¯”
            one_month_risk = calculate_risk_percentage(days_to_clear, batch_age, 30)
            two_month_risk = calculate_risk_percentage(days_to_clear, batch_age, 60)
            three_month_risk = calculate_risk_percentage(days_to_clear, batch_age, 90)
        else:
            days_to_clear = float('inf')
            one_month_risk = 100
            two_month_risk = 100
            three_month_risk = 100

        # æ ¹æ®å¤æ‚çš„é£é™©è¯„ä¼°é€»è¾‘ç¡®å®šé£é™©ç­‰çº§å’Œé£é™©å¾—åˆ†
        # æ”¹è¿›é£é™©ç­‰çº§è¯„ä¼°é€»è¾‘ - ä½¿ç”¨ç»¼åˆè¯„åˆ†æ–¹æ³•
        risk_score = 0

        # åº“é¾„å› ç´  (0-40åˆ†)
        if batch_age > 90:
            risk_score += 40
        elif batch_age > 60:
            risk_score += 30
        elif batch_age > 30:
            risk_score += 20
        else:
            risk_score += 10

        # æ¸…åº“å¤©æ•°å› ç´  (0-40åˆ†)
        if days_to_clear == float('inf'):
            risk_score += 40
        elif days_to_clear > 180:  # åŠå¹´ä»¥ä¸Š
            risk_score += 35
        elif days_to_clear > 90:
            risk_score += 30
        elif days_to_clear > 60:
            risk_score += 20
        elif days_to_clear > 30:
            risk_score += 10

        # é”€é‡æ³¢åŠ¨ç³»æ•° (0-10åˆ†)
        if sales_metrics['coefficient_of_variation'] > 2.0:
            risk_score += 10
        elif sales_metrics['coefficient_of_variation'] > 1.0:
            risk_score += 5

        # æ ¹æ®æ€»åˆ†ç¡®å®šé£é™©ç­‰çº§
        if risk_score >= 80:
            risk_level = "æé«˜é£é™©"
        elif risk_score >= 60:
            risk_level = "é«˜é£é™©"
        elif risk_score >= 40:
            risk_level = "ä¸­é£é™©"
        elif risk_score >= 20:
            risk_level = "ä½é£é™©"
        else:
            risk_level = "æä½é£é™©"

        # ç”Ÿæˆå»ºè®®æªæ–½
        if risk_level == "æé«˜é£é™©":
            recommendation = "ç´§æ€¥æ¸…ç†ï¼šè€ƒè™‘æŠ˜ä»·ä¿ƒé”€"
        elif risk_level == "é«˜é£é™©":
            recommendation = "ä¼˜å…ˆå¤„ç†ï¼šé™ä»·ä¿ƒé”€æˆ–è½¬ä»“è°ƒé…"
        elif risk_level == "ä¸­é£é™©":
            recommendation = "å¯†åˆ‡ç›‘æ§ï¼šè°ƒæ•´é‡‡è´­è®¡åˆ’"
        elif risk_level == "ä½é£é™©":
            recommendation = "å¸¸è§„ç®¡ç†ï¼šå®šæœŸå®¡æŸ¥åº“å­˜å‘¨è½¬"
        else:
            recommendation = "ç»´æŒç°çŠ¶ï¼šæ­£å¸¸åº“å­˜æ°´å¹³"

        # ç¡®å®šç§¯å‹åŸå› 
        stocking_reasons = []
        if batch_age > 60:
            stocking_reasons.append("åº“é¾„è¿‡é•¿")
        if sales_metrics['coefficient_of_variation'] > 1.0:
            stocking_reasons.append("é”€é‡æ³¢åŠ¨å¤§")
        if seasonal_index < 0.8:
            stocking_reasons.append("å­£èŠ‚æ€§å½±å“")
        if not stocking_reasons:
            stocking_reasons.append("æ­£å¸¸åº“å­˜")

        # è·å–è´£ä»»åŒºåŸŸå’Œè´£ä»»äºº
        responsible_region, responsible_person, responsibility_summary = analyze_responsibility(
            product_code, batch_date, sales_metrics, forecast_data, actual_data, batch_qty
        )

        # æ·»åŠ æ‰¹æ¬¡åˆ†æç»“æœ
        batch_analysis.append({
            'äº§å“ä»£ç ': product_code,
            'æè¿°': batch['æè¿°'],
            'æ‰¹æ¬¡æ—¥æœŸ': batch_date.date(),
            'æ‰¹æ¬¡åº“å­˜': batch_qty,
            'åº“é¾„': batch_age,
            'æ‰¹æ¬¡ä»·å€¼': batch_value,
            'æ—¥å‡å‡ºè´§': round(daily_avg_sales, 2),
            'å‡ºè´§æ³¢åŠ¨ç³»æ•°': round(sales_metrics['coefficient_of_variation'], 2),
            'é¢„è®¡æ¸…åº“å¤©æ•°': days_to_clear if days_to_clear != float('inf') else float('inf'),
            'ä¸€ä¸ªæœˆç§¯å‹é£é™©': f"{round(one_month_risk, 1)}%",
            'ä¸¤ä¸ªæœˆç§¯å‹é£é™©': f"{round(two_month_risk, 1)}%",
            'ä¸‰ä¸ªæœˆç§¯å‹é£é™©': f"{round(three_month_risk, 1)}%",
            'ç§¯å‹åŸå› ': 'ï¼Œ'.join(stocking_reasons),
            'å­£èŠ‚æ€§æŒ‡æ•°': round(seasonal_index, 2),
            'è´£ä»»åŒºåŸŸ': responsible_region,
            'è´£ä»»äºº': responsible_person,
            'è´£ä»»åˆ†ææ‘˜è¦': responsibility_summary,
            'é£é™©ç¨‹åº¦': risk_level,
            'é£é™©å¾—åˆ†': risk_score,
            'å»ºè®®æªæ–½': recommendation
        })

    # åˆ›å»ºDataFrameå¹¶æ’åº
    batch_df = pd.DataFrame(batch_analysis)

    # æŒ‰ç…§é£é™©ç¨‹åº¦å’Œåº“é¾„æ’åº
    risk_order = {
        "æé«˜é£é™©": 0,
        "é«˜é£é™©": 1,
        "ä¸­é£é™©": 2,
        "ä½é£é™©": 3,
        "æä½é£é™©": 4
    }

    if not batch_df.empty:
        batch_df['é£é™©æ’åº'] = batch_df['é£é™©ç¨‹åº¦'].map(risk_order)
        batch_df = batch_df.sort_values(by=['é£é™©æ’åº', 'åº“é¾„'], ascending=[True, False])
        batch_df = batch_df.drop(columns=['é£é™©æ’åº'])

    return batch_df


# å‡½æ•°ï¼šåˆ†æè´£ä»»å½’å±
def analyze_responsibility(product_code, batch_date, sales_metrics, forecast_df, actual_df, batch_qty):
    """
    åˆ†ææ‰¹æ¬¡åº“å­˜çš„è´£ä»»å½’å±

    å‚æ•°:
    product_code (str): äº§å“ä»£ç 
    batch_date (datetime): æ‰¹æ¬¡ç”Ÿäº§æ—¥æœŸ
    sales_metrics (dict): äº§å“é”€å”®æŒ‡æ ‡
    forecast_df (DataFrame): é¢„æµ‹æ•°æ®
    actual_df (DataFrame): å®é™…é”€å”®æ•°æ®
    batch_qty (float): æ‰¹æ¬¡åº“å­˜æ•°é‡

    è¿”å›:
    tuple: (è´£ä»»åŒºåŸŸ, è´£ä»»äºº, è´£ä»»åˆ†ææ‘˜è¦)
    """
    today = datetime.now().date()
    batch_date = batch_date.date()
    default_region = "æœªçŸ¥"
    default_person = "ç³»ç»Ÿç®¡ç†å‘˜"

    # å»ºç«‹é”€å”®äººå‘˜-åŒºåŸŸæ˜ å°„
    sales_person_region_mapping = {}
    person_region_data = actual_df[['ç”³è¯·äºº', 'æ‰€å±åŒºåŸŸ']].drop_duplicates()
    for _, row in person_region_data.iterrows():
        person = row['ç”³è¯·äºº']
        region = row['æ‰€å±åŒºåŸŸ']
        sales_person_region_mapping[person] = region

    # è·å–äº§å“è´£ä»»åˆ†é…çš„é»˜è®¤æ˜ å°„
    product_responsibility = {}
    product_region_counts = actual_df[actual_df['äº§å“ä»£ç '] == product_code].groupby('æ‰€å±åŒºåŸŸ')[
        'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].sum()
    product_person_counts = actual_df[actual_df['äº§å“ä»£ç '] == product_code].groupby('ç”³è¯·äºº')['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].sum()

    if not product_region_counts.empty:
        default_region = product_region_counts.idxmax()
    if not product_person_counts.empty:
        default_person = product_person_counts.idxmax()

    # å®šä¹‰æ—¶é—´çª—å£
    forecast_start_date = batch_date - timedelta(days=90)
    forecast_end_date = batch_date + timedelta(days=30)
    sales_start_date = batch_date
    sales_end_date = min(today, batch_date + timedelta(days=90))

    # è·å–ç›¸å…³é¢„æµ‹è®°å½•
    forecast_df['æ‰€å±å¹´æœˆ'] = pd.to_datetime(forecast_df['æ‰€å±å¹´æœˆ'])
    product_forecasts = forecast_df[
        (forecast_df['äº§å“ä»£ç '] == product_code) &
        (forecast_df['æ‰€å±å¹´æœˆ'].dt.date >= forecast_start_date) &
        (forecast_df['æ‰€å±å¹´æœˆ'].dt.date <= forecast_end_date)
        ]

    # è·å–ç›¸å…³å®é™…é”€å”®è®°å½•
    product_sales = actual_df[
        (actual_df['äº§å“ä»£ç '] == product_code) &
        (actual_df['è®¢å•æ—¥æœŸ'].dt.date >= sales_start_date) &
        (actual_df['è®¢å•æ—¥æœŸ'].dt.date <= sales_end_date)
        ]

    # åˆå§‹åŒ–è´£ä»»è¯„åˆ†
    person_scores = {}
    region_scores = {}

    # è®¡ç®—é¢„æµ‹æœªå…‘ç°é‡
    person_allocations = {}
    forecast_responsibility = {}

    if not product_forecasts.empty:
        # æŒ‰é”€å”®äººå‘˜åˆ†ç»„ç»Ÿè®¡é¢„æµ‹æ€»é‡
        person_forecast_totals = product_forecasts.groupby('é”€å”®å‘˜')['é¢„è®¡é”€å”®é‡'].sum()

        # æŒ‰é”€å”®äººå‘˜ç»Ÿè®¡å®é™…é”€å”®æ€»é‡
        person_sales_data = {}
        for person in person_forecast_totals.index:
            person_actual_sales = product_sales[product_sales['ç”³è¯·äºº'] == person]['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].sum() \
                if not product_sales.empty else 0
            person_sales_data[person] = person_actual_sales

            # è®¡ç®—æœªå…‘ç°é¢„æµ‹é‡
            forecast_qty = person_forecast_totals[person]
            if forecast_qty > 0:
                unfulfilled = max(0, forecast_qty - person_actual_sales)
                if unfulfilled > 0:
                    forecast_responsibility[person] = {
                        "forecast_quantity": forecast_qty,
                        "actual_sales": person_actual_sales,
                        "unfulfilled": unfulfilled,
                        "fulfillment_rate": person_actual_sales / forecast_qty
                    }

        # å¦‚æœæœ‰æœªå…‘ç°é¢„æµ‹ï¼ŒæŒ‰æœªå…‘ç°é‡åˆ†é…åº“å­˜è´£ä»»
        if forecast_responsibility:
            total_unfulfilled = sum(detail["unfulfilled"] for person, detail in forecast_responsibility.items())

            if total_unfulfilled > 0:
                # æŒ‰æœªå…‘ç°é¢„æµ‹é‡æ¯”ä¾‹åˆ†é…åº“å­˜
                for person, detail in forecast_responsibility.items():
                    allocation = int(batch_qty * (detail["unfulfilled"] / total_unfulfilled))
                    person_allocations[person] = max(1, allocation)

                    # è®¡ç®—è´£ä»»å¾—åˆ†
                    # é¢„æµ‹å·®å¼‚å¾—åˆ† (60%)
                    forecast_score = 0.6 * (1 - detail["fulfillment_rate"])
                    # åˆ†é…æ€»å¾—åˆ†
                    person_scores[person] = forecast_score

                    # è®¾ç½®åŒºåŸŸå¾—åˆ†
                    person_region = sales_person_region_mapping.get(person, default_region)
                    region_scores[person_region] = region_scores.get(person_region, 0) + forecast_score

                # ç¡®ä¿æ‰€æœ‰åº“å­˜éƒ½è¢«åˆ†é…
                allocated_total = sum(person_allocations.values())
                if allocated_total < batch_qty and person_allocations:
                    # å°†å‰©ä½™åº“å­˜åˆ†é…ç»™æœªå…‘ç°é¢„æµ‹é‡æœ€å¤§çš„äºº
                    top_unfulfilled_person = max(forecast_responsibility.items(),
                                                 key=lambda x: x[1]["unfulfilled"])[0]
                    person_allocations[top_unfulfilled_person] += (batch_qty - allocated_total)

    # å¦‚æœæ²¡æœ‰äººæœ‰é¢„æµ‹æœªå…‘ç°ï¼Œä½¿ç”¨é»˜è®¤è´£ä»»äºº
    if not person_scores:
        person_scores[default_person] = 1.0
        region_scores[default_region] = 1.0
        person_allocations[default_person] = batch_qty

    # ç¡®å®šæœ€ç»ˆè´£ä»»äºº
    if person_allocations:
        responsible_person = max(person_allocations.items(), key=lambda x: x[1])[0]

        # è·å–è´£ä»»åŒºåŸŸ
        if responsible_person in sales_person_region_mapping:
            responsible_region = sales_person_region_mapping[responsible_person]
        else:
            responsible_region = default_region
    else:
        responsible_person = default_person
        responsible_region = default_region

    # æ„å»ºè´£ä»»åˆ†ææ‘˜è¦
    responsibility_summary = generate_responsibility_summary(
        responsible_person, forecast_responsibility, person_allocations, batch_qty
    )

    return responsible_region, responsible_person, responsibility_summary


# å‡½æ•°ï¼šç”Ÿæˆè´£ä»»åˆ†ææ‘˜è¦
def generate_responsibility_summary(responsible_person, forecast_responsibility, person_allocations, batch_qty):
    """
    ç”Ÿæˆè´£ä»»åˆ†ææ‘˜è¦

    å‚æ•°:
    responsible_person (str): ä¸»è¦è´£ä»»äºº
    forecast_responsibility (dict): é¢„æµ‹è´£ä»»è¯¦æƒ…
    person_allocations (dict): äººå‘˜åº“å­˜åˆ†é…æƒ…å†µ
    batch_qty (float): æ‰¹æ¬¡åº“å­˜æ•°é‡

    è¿”å›:
    str: è´£ä»»åˆ†ææ‘˜è¦
    """
    if not person_allocations:
        return "æ— æ³•ç¡®å®šè´£ä»»"

    # ç¡®å®šä¸»è¦è´£ä»»äººçš„è´£ä»»åŸå› 
    main_reasons = []

    if responsible_person in forecast_responsibility:
        detail = forecast_responsibility[responsible_person]
        forecast_qty = detail["forecast_quantity"]
        actual_sales = detail["actual_sales"]
        fulfillment_rate = detail["fulfillment_rate"] * 100
        unfulfilled = detail["unfulfilled"]

        main_reasons.append(f"é¢„æµ‹{forecast_qty:.0f}ä»¶ä½†ä»…é”€å”®{actual_sales:.0f}ä»¶(å±¥è¡Œç‡{fulfillment_rate:.0f}%)")
        main_reasons.append(f"æœªå…‘ç°é¢„æµ‹{unfulfilled:.0f}ä»¶")
    else:
        main_reasons.append("ç»¼åˆé¢„æµ‹ä¸é”€å”®å› ç´ ")

    # è·å–ä¸»è¦è´£ä»»äººåº”æ‰¿æ‹…çš„åº“å­˜æ•°é‡
    main_allocation = person_allocations.get(responsible_person, 0)

    # æ„å»ºä¸»è¦è´£ä»»äººéƒ¨åˆ†
    main_reason = "ã€".join(main_reasons)
    main_part = f"{responsible_person}ä¸»è¦è´£ä»»({main_reason}ï¼Œæ‰¿æ‹…{main_allocation}ä»¶)"

    # æ„å»ºå…±åŒè´£ä»»éƒ¨åˆ†
    other_persons = []
    for person, allocation in person_allocations.items():
        if person != responsible_person and allocation > 0:
            if person in forecast_responsibility:
                unfulfilled = forecast_responsibility[person]["unfulfilled"]
                other_persons.append(f"{person}(æœªå…‘ç°é¢„æµ‹{unfulfilled:.0f}ä»¶ï¼Œæ‰¿æ‹…{allocation}ä»¶)")
            else:
                other_persons.append(f"{person}(è´£ä»»å…±æ‹…ï¼Œæ‰¿æ‹…{allocation}ä»¶)")

    # ç»„åˆæœ€ç»ˆæ‘˜è¦
    if other_persons:
        return f"{main_part}ï¼Œå…±åŒè´£ä»»ï¼š{', '.join(other_persons)}"
    else:
        return main_part


# å‡½æ•°ï¼šåˆ›å»ºå›¾è¡¨åˆ†é¡µå™¨
def display_chart_paginator(df, chart_function, page_size, title, key_prefix):
    """åˆ›å»ºå›¾è¡¨åˆ†é¡µå™¨"""
    total_items = len(df)
    total_pages = (total_items + page_size - 1) // page_size

    if f"{key_prefix}_current_page" not in st.session_state:
        st.session_state[f"{key_prefix}_current_page"] = 0

    # åˆ›å»ºåˆ†é¡µæ§åˆ¶
    col1, col2, col3 = st.columns([1, 3, 1])

    with col1:
        if st.button("ä¸Šä¸€é¡µ", key=f"{key_prefix}_prev", disabled=st.session_state[f"{key_prefix}_current_page"] <= 0):
            st.session_state[f"{key_prefix}_current_page"] -= 1
            st.rerun()

    with col2:
        st.markdown(
            f"<div style='text-align:center' class='pagination-info'>ç¬¬ {st.session_state[f'{key_prefix}_current_page'] + 1} é¡µï¼Œå…± {total_pages} é¡µ</div>",
            unsafe_allow_html=True)

    with col3:
        if st.button("ä¸‹ä¸€é¡µ", key=f"{key_prefix}_next",
                     disabled=st.session_state[f"{key_prefix}_current_page"] >= total_pages - 1):
            st.session_state[f"{key_prefix}_current_page"] += 1
            st.rerun()

    # ç¡®ä¿å½“å‰é¡µåœ¨æœ‰æ•ˆèŒƒå›´å†…
    if st.session_state[f"{key_prefix}_current_page"] >= total_pages:
        st.session_state[f"{key_prefix}_current_page"] = total_pages - 1
    if st.session_state[f"{key_prefix}_current_page"] < 0:
        st.session_state[f"{key_prefix}_current_page"] = 0

    # è·å–å½“å‰é¡µçš„æ•°æ®
    start_idx = st.session_state[f"{key_prefix}_current_page"] * page_size
    end_idx = min(start_idx + page_size, total_items)
    page_data = df.iloc[start_idx:end_idx]

    # æ˜¾ç¤ºå›¾è¡¨
    chart_function(page_data, title)


# å‡½æ•°ï¼šåˆ›å»ºé€šç”¨å›¾è¡¨
def create_chart(chart_type, data, x, y, title, color=None, orientation='v', text=None, **kwargs):
    """é€šç”¨å›¾è¡¨åˆ›å»ºå‡½æ•°"""
    if chart_type == 'bar':
        fig = px.bar(data, x=x, y=y, color=color, orientation=orientation, text=text, title=title, **kwargs)
    elif chart_type == 'line':
        fig = px.line(data, x=x, y=y, color=color, title=title, **kwargs)
    elif chart_type == 'scatter':
        fig = px.scatter(data, x=x, y=y, color=color, title=title, **kwargs)
    else:
        fig = go.Figure()
        st.warning(f"æœªæ”¯æŒçš„å›¾è¡¨ç±»å‹: {chart_type}")

    # é€šç”¨æ ·å¼è®¾ç½®
    fig.update_layout(
        title_font=dict(size=16),
        xaxis_title_font=dict(size=14),
        yaxis_title_font=dict(size=14),
        legend_title_font=dict(size=14),
        plot_bgcolor='white'  # è®¾ç½®ç™½è‰²èƒŒæ™¯
    )

    # æ·»åŠ æ•°å­—æ ¼å¼è®¾ç½®
    if orientation == 'v' and x is not None:
        fig.update_layout(
            xaxis=dict(
                tickformat=",",  # ä½¿ç”¨é€—å·åˆ†éš”
                showexponent="none"  # ä¸ä½¿ç”¨ç§‘å­¦è®¡æ•°æ³•
            )
        )
    elif orientation == 'h' and y is not None:
        fig.update_layout(
            yaxis=dict(
                tickformat=",",  # ä½¿ç”¨é€—å·åˆ†éš”
                showexponent="none"  # ä¸ä½¿ç”¨ç§‘å­¦è®¡æ•°æ³•
            )
        )

    return fig


# å‡½æ•°ï¼šåˆ›å»ºå¸¦å¤‡è´§å»ºè®®çš„å¢é•¿ç‡å›¾è¡¨
def plot_growth_with_recommendations(data, title):
    """åˆ›å»ºå¸¦æœ‰å†…ç½®å¤‡è´§å»ºè®®çš„å¢é•¿ç‡å›¾è¡¨ - ä¼˜åŒ–è§†è§‰æ•ˆæœ"""
    if data.empty:
        st.warning("æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®æ¥ç”Ÿæˆå¢é•¿ç‡å›¾è¡¨ã€‚")
        return None

    # ç¡®ä¿æ•°æ®ä¸­æœ‰å¤‡è´§å»ºè®®
    if 'å¤‡è´§å»ºè®®å¯¹è±¡' not in data.columns:
        data['å¤‡è´§å»ºè®®å¯¹è±¡'] = data['é”€é‡å¢é•¿ç‡'].apply(generate_recommendation)
        data['å¤‡è´§å»ºè®®'] = data['å¤‡è´§å»ºè®®å¯¹è±¡'].apply(lambda x: x['å»ºè®®'])
        data['è°ƒæ•´æ¯”ä¾‹'] = data['å¤‡è´§å»ºè®®å¯¹è±¡'].apply(lambda x: x['è°ƒæ•´æ¯”ä¾‹'])
        data['å»ºè®®é¢œè‰²'] = data['å¤‡è´§å»ºè®®å¯¹è±¡'].apply(lambda x: x['é¢œè‰²'])
        data['å»ºè®®å›¾æ ‡'] = data['å¤‡è´§å»ºè®®å¯¹è±¡'].apply(lambda x: x['å›¾æ ‡'])

    # å‡†å¤‡æ˜¾ç¤ºæ–‡æœ¬
    data['æ˜¾ç¤ºæ–‡æœ¬'] = data.apply(
        lambda row: f"{row['é”€é‡å¢é•¿ç‡']:.1f}% {row['å»ºè®®å›¾æ ‡']}",
        axis=1
    )

    # åˆ›å»ºå›¾è¡¨ - ä¼˜åŒ–é¢œè‰²æ–¹æ¡ˆ
    fig = px.bar(
        data,
        y='äº§å“æ˜¾ç¤º',
        x='é”€é‡å¢é•¿ç‡',
        color='è¶‹åŠ¿',
        title=title,
        text='æ˜¾ç¤ºæ–‡æœ¬',
        orientation='h',
        color_discrete_map={
            'å¼ºåŠ²å¢é•¿': '#1E88E5',  # æ·±è“è‰²
            'å¢é•¿': '#43A047',  # ç»¿è‰²
            'è½»å¾®ä¸‹é™': '#FB8C00',  # æ©™è‰²
            'æ˜¾è‘—ä¸‹é™': '#E53935'  # çº¢è‰²
        }
    )

    # æ›´æ–°å¸ƒå±€ - æ”¹è¿›è§†è§‰æ•ˆæœ
    fig.update_layout(
        yaxis_title="äº§å“",
        xaxis_title="å¢é•¿ç‡ (%)",
        xaxis=dict(tickformat=",", showexponent="none"),
        plot_bgcolor='white',
        margin=dict(l=10, r=10, t=50, b=10)
    )

    # æ·»åŠ å‚è€ƒçº¿
    fig.add_shape(
        type="line",
        y0=-0.5,
        y1=len(data) - 0.5,
        x0=0,
        x1=0,
        line=dict(color="black", width=1, dash="dash")
    )

    # ä¼˜åŒ–æ‚¬åœæç¤º
    fig.update_traces(
        hovertemplate='<b>%{y}</b><br>å¢é•¿ç‡: %{x:.2f}%<br>å»ºè®®: %{customdata[0]}<br>è°ƒæ•´æ¯”ä¾‹: %{customdata[1]}%<extra></extra>',
        customdata=data[['å¤‡è´§å»ºè®®', 'è°ƒæ•´æ¯”ä¾‹']].values
    )

    # æ”¹è¿›æ¡å½¢å›¾æ ·å¼
    fig.update_traces(
        marker_line_width=0.5,
        marker_line_color="white",
        opacity=0.9
    )

    return fig


# å‡½æ•°ï¼šåˆ›å»ºæ‰¹æ¬¡é£é™©åˆ†å¸ƒé¥¼å›¾
def create_risk_distribution_chart(batch_analysis):
    """åˆ›å»ºæ‰¹æ¬¡é£é™©åˆ†å¸ƒé¥¼å›¾"""
    if batch_analysis.empty:
        st.warning("æ²¡æœ‰æ‰¹æ¬¡æ•°æ®å¯ä¾›åˆ†æ")
        return None

    # è®¡ç®—å„é£é™©ç­‰çº§çš„æ‰¹æ¬¡æ•°é‡
    risk_counts = batch_analysis['é£é™©ç¨‹åº¦'].value_counts()

    # ä¸ºé¥¼å›¾å‡†å¤‡æ•°æ®
    labels = risk_counts.index
    values = risk_counts.values

    # è®¾ç½®é¢œè‰²æ˜ å°„
    color_map = {
        'æé«˜é£é™©': '#8B0000',  # æ·±çº¢è‰²
        'é«˜é£é™©': '#FF0000',  # çº¢è‰²
        'ä¸­é£é™©': '#FFA500',  # æ©™è‰²
        'ä½é£é™©': '#4CAF50',  # ç»¿è‰²
        'æä½é£é™©': '#2196F3'  # è“è‰²
    }
    colors = [color_map.get(level, '#CCCCCC') for level in labels]

    # è®¾ç½®åˆ†ç¦»å€¼
    explode = [0.1 if level == 'æé«˜é£é™©' else 0.05 if level == 'é«˜é£é™©' else 0 for level in labels]

    # åˆ›å»ºé¥¼å›¾
    fig = go.Figure()

    # æ·»åŠ é¥¼å›¾
    fig.add_trace(go.Pie(
        labels=labels,
        values=values,
        hole=0.4,
        marker=dict(colors=colors),
        textinfo='percent',
        hoverinfo='label+value+percent',
        textfont=dict(size=14),
        pull=explode
    ))

    # æ›´æ–°å¸ƒå±€
    fig.update_layout(
        title='åº“å­˜æ‰¹æ¬¡é£é™©åˆ†å¸ƒ',
        title_font=dict(size=18, family='Arial', color='#1f3867'),
        legend=dict(
            orientation='h',
            yanchor='bottom',
            y=-0.2,
            xanchor='center',
            x=0.5,
            font=dict(size=12)
        ),
        margin=dict(t=60, b=100, l=20, r=20),
        height=500,
        width=700,
        plot_bgcolor='white',
        paper_bgcolor='white'
    )

    # æ·»åŠ æ³¨é‡Š - æ˜¾ç¤ºæ‰¹æ¬¡æ€»æ•°
    total_batches = sum(values)
    high_risk_batches = risk_counts.get('æé«˜é£é™©', 0) + risk_counts.get('é«˜é£é™©', 0)

    fig.add_annotation(
        x=0.5,
        y=0.5,
        text=f"æ€»æ‰¹æ¬¡: {total_batches}<br>é«˜é£é™©æ‰¹æ¬¡: {high_risk_batches}",
        font=dict(size=14, color='#1f3867'),
        showarrow=False
    )

    return fig


# å‡½æ•°ï¼šåˆ›å»ºé«˜é£é™©æ‰¹æ¬¡åº“é¾„åˆ†å¸ƒå›¾
def create_high_risk_batches_chart(batch_analysis):
    """åˆ›å»ºé«˜é£é™©æ‰¹æ¬¡åº“é¾„åˆ†å¸ƒå›¾"""
    if batch_analysis.empty:
        st.warning("æ²¡æœ‰æ‰¹æ¬¡æ•°æ®å¯ä¾›åˆ†æ")
        return None

    # ç­›é€‰é«˜é£é™©æ‰¹æ¬¡
    high_risk_batches = batch_analysis[batch_analysis['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])]

    if high_risk_batches.empty:
        st.info("æ²¡æœ‰é«˜é£é™©æ‰¹æ¬¡æ•°æ®")
        return None

    # æ’åºæ‰¹æ¬¡æ•°æ®ï¼ŒæŒ‰åº“é¾„é™åº
    high_risk_batches = high_risk_batches.sort_values('åº“é¾„', ascending=False)

    # åªæ˜¾ç¤ºå‰10ä¸ªæ‰¹æ¬¡ï¼Œé¿å…å›¾è¡¨è¿‡äºæ‹¥æŒ¤
    top_batches = high_risk_batches.head(10)

    # åˆ›å»ºæ‰¹æ¬¡æ ‡ç­¾ - æ›´åŠ æ¸…æ™°çš„æ ¼å¼
    batch_labels = [f"{code} ({date})" for code, date in
                    zip(top_batches['äº§å“ä»£ç '], top_batches['æ‰¹æ¬¡æ—¥æœŸ'].astype(str))]

    # è®¾ç½®é¢œè‰² - ä½¿ç”¨é£é™©ç¨‹åº¦åŒºåˆ†
    bar_colors = ['#8B0000' if x == 'æé«˜é£é™©' else '#FF5252' for x in top_batches['é£é™©ç¨‹åº¦']]

    # åˆ›å»ºæ°´å¹³æ¡å½¢å›¾
    fig = go.Figure()

    # æ·»åŠ åº“é¾„æ¡å½¢å›¾
    fig.add_trace(go.Bar(
        y=batch_labels,
        x=top_batches['åº“é¾„'],
        orientation='h',
        marker=dict(color=bar_colors),
        text=top_batches['åº“é¾„'].apply(lambda x: f"{int(x)}å¤©"),
        textposition='outside',
        name='åº“é¾„(å¤©)'
    ))

    # æ·»åŠ é£é™©é˜ˆå€¼å‚è€ƒçº¿
    fig.add_shape(
        type="line",
        x0=90, x1=90,
        y0=-0.5, y1=len(batch_labels) - 0.5,
        line=dict(color="red", width=1, dash="dash"),
        name="é«˜é£é™©é˜ˆå€¼(90å¤©)"
    )

    fig.add_shape(
        type="line",
        x0=60, x1=60,
        y0=-0.5, y1=len(batch_labels) - 0.5,
        line=dict(color="orange", width=1, dash="dash"),
        name="ä¸­é£é™©é˜ˆå€¼(60å¤©)"
    )

    fig.add_shape(
        type="line",
        x0=30, x1=30,
        y0=-0.5, y1=len(batch_labels) - 0.5,
        line=dict(color="green", width=1, dash="dash"),
        name="ä½é£é™©é˜ˆå€¼(30å¤©)"
    )

    # æ·»åŠ å›¾ä¾‹æ³¨é‡Š
    fig.add_annotation(x=90, y=len(batch_labels), text="é«˜é£é™©(90å¤©)",
                       showarrow=False, xanchor="left", yanchor="bottom",
                       font=dict(color="red"))

    fig.add_annotation(x=60, y=len(batch_labels), text="ä¸­é£é™©(60å¤©)",
                       showarrow=False, xanchor="left", yanchor="bottom",
                       font=dict(color="orange"))

    fig.add_annotation(x=30, y=len(batch_labels), text="ä½é£é™©(30å¤©)",
                       showarrow=False, xanchor="left", yanchor="bottom",
                       font=dict(color="green"))

    # æ›´æ–°å¸ƒå±€
    fig.update_layout(
        title='é«˜é£é™©æ‰¹æ¬¡åº“é¾„åˆ†å¸ƒåˆ†æ',
        title_font=dict(size=18, family='Arial', color='#1f3867'),
        xaxis=dict(
            title='åº“é¾„(å¤©)',
            tickformat=",",
            showexponent="none"
        ),
        yaxis=dict(title='æ‰¹æ¬¡'),
        margin=dict(t=60, b=50, l=20, r=20),
        height=max(500, len(batch_labels) * 40),
        width=800,
        plot_bgcolor='white',
        paper_bgcolor='white'
    )

    # æ·»åŠ æ‚¬åœä¿¡æ¯
    hover_texts = []
    for _, batch in top_batches.iterrows():
        hover_text = (
            f"äº§å“ä»£ç : {batch['äº§å“ä»£ç ']}<br>"
            f"æ‰¹æ¬¡æ—¥æœŸ: {batch['æ‰¹æ¬¡æ—¥æœŸ']}<br>"
            f"åº“é¾„: {batch['åº“é¾„']}å¤©<br>"
            f"æ‰¹æ¬¡åº“å­˜: {batch['æ‰¹æ¬¡åº“å­˜']}ä»¶<br>"
            f"æ‰¹æ¬¡ä»·å€¼: Â¥{batch['æ‰¹æ¬¡ä»·å€¼']:,.2f}<br>"
            f"é£é™©ç­‰çº§: {batch['é£é™©ç¨‹åº¦']}<br>"
            f"è´£ä»»äºº: {batch['è´£ä»»äºº']}"
        )
        hover_texts.append(hover_text)

    fig.update_traces(
        hovertemplate='%{text}',
        text=hover_texts
    )

    return fig


# å‡½æ•°ï¼šåˆ›å»ºé¢„æµ‹åå·®åˆ†æå›¾
def create_forecast_bias_chart(batch_analysis, actual_data, forecast_data):
    """åˆ›å»ºé¢„æµ‹åå·®åˆ†æå›¾"""
    if batch_analysis.empty:
        st.warning("æ²¡æœ‰æ‰¹æ¬¡æ•°æ®å¯ä¾›åˆ†æ")
        return None

    # ç­›é€‰é«˜é£é™©æ‰¹æ¬¡
    high_risk_batches = batch_analysis[batch_analysis['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])]

    if high_risk_batches.empty:
        st.info("æ²¡æœ‰é«˜é£é™©æ‰¹æ¬¡æ•°æ®")
        return None

    # è®¡ç®—äº§å“é¢„æµ‹åå·®
    forecast_bias_data = []

    for _, batch in high_risk_batches.iterrows():
        product_code = batch['äº§å“ä»£ç ']
        batch_date = batch['æ‰¹æ¬¡æ—¥æœŸ']

        # è·å–ç›¸å…³é¢„æµ‹å’Œå®é™…é”€å”®æ•°æ®
        three_months_before = pd.to_datetime(batch_date) - pd.DateOffset(months=3)
        product_forecast = forecast_data[
            (forecast_data['äº§å“ä»£ç '] == product_code) &
            (pd.to_datetime(forecast_data['æ‰€å±å¹´æœˆ']).dt.date >= three_months_before)
            ]

        product_sales = actual_data[
            (actual_data['äº§å“ä»£ç '] == product_code) &
            (actual_data['è®¢å•æ—¥æœŸ'].dt.date >= three_months_before)
            ]

        if not product_forecast.empty and not product_sales.empty:
            forecast_qty = product_forecast['é¢„è®¡é”€å”®é‡'].sum()
            actual_qty = product_sales['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].sum()

            if actual_qty > 0:
                bias_pct = (forecast_qty - actual_qty) / actual_qty * 100
            elif forecast_qty > 0:
                bias_pct = 100  # é¢„æµ‹æœ‰å€¼ä½†å®é™…ä¸º0
            else:
                bias_pct = 0  # é¢„æµ‹å’Œå®é™…éƒ½æ˜¯0

            # é™åˆ¶åå·®åœ¨åˆç†èŒƒå›´å†…ï¼Œä¾¿äºå¯è§†åŒ–
            bias_pct = max(min(bias_pct, 200), -100)

            forecast_bias_data.append({
                'äº§å“ä»£ç ': product_code,
                'æè¿°': batch['æè¿°'],
                'æ‰¹æ¬¡æ—¥æœŸ': batch_date,
                'é¢„æµ‹é‡': forecast_qty,
                'å®é™…é”€é‡': actual_qty,
                'é¢„æµ‹åå·®': bias_pct,
                'é£é™©ç¨‹åº¦': batch['é£é™©ç¨‹åº¦']
            })

    if not forecast_bias_data:
        st.info("æ— æ³•è®¡ç®—é¢„æµ‹åå·®æ•°æ®")
        return None

    # åˆ›å»ºé¢„æµ‹åå·®DataFrame
    bias_df = pd.DataFrame(forecast_bias_data)

    # æŒ‰åå·®ç»å¯¹å€¼æ’åº
    bias_df = bias_df.reindex(bias_df['é¢„æµ‹åå·®'].abs().sort_values(ascending=False).index)

    # é™åˆ¶æ˜¾ç¤ºå‰8ä¸ªåå·®æœ€å¤§çš„äº§å“
    bias_df = bias_df.head(8)

    # åˆ›å»ºæ°´å¹³æ¡å½¢å›¾
    fig = go.Figure()

    # åˆ›å»ºäº§å“æ ‡ç­¾
    products = []
    for code, desc in zip(bias_df['äº§å“ä»£ç '], bias_df['æè¿°']):
        short_desc = desc[:20] + '...' if len(desc) > 20 else desc
        products.append(f"{code}: {short_desc}")

    # è®¾ç½®é¢œè‰² - æ­£åå·®(é¢„æµ‹è¿‡é«˜)ä¸ºçº¢è‰²ï¼Œè´Ÿåå·®(é¢„æµ‹è¿‡ä½)ä¸ºè“è‰²
    bar_colors = ['#FF5252' if x > 0 else '#4682B4' for x in bias_df['é¢„æµ‹åå·®']]

    # æ·»åŠ é¢„æµ‹åå·®æ¡å½¢å›¾
    fig.add_trace(go.Bar(
        y=products,
        x=bias_df['é¢„æµ‹åå·®'].abs(),
        orientation='h',
        marker=dict(color=bar_colors),
        text=bias_df['é¢„æµ‹åå·®'].apply(
            lambda x: f"{abs(x):.1f}% ({'é¢„æµ‹è¿‡é«˜' if x > 0 else 'é¢„æµ‹è¿‡ä½'})"
        ),
        textposition='outside',
        name='é¢„æµ‹åå·®(%)'
    ))

    # æ›´æ–°å¸ƒå±€
    fig.update_layout(
        title='æ‰¹æ¬¡é¢„æµ‹åå·®åˆ†æ',
        title_font=dict(size=18, family='Arial', color='#1f3867'),
        xaxis=dict(
            title='é¢„æµ‹åå·®ç™¾åˆ†æ¯”(ç»å¯¹å€¼)',
            tickformat=",",
            showexponent="none"
        ),
        yaxis=dict(title='äº§å“'),
        margin=dict(t=60, b=50, l=20, r=20),
        height=max(500, len(products) * 40),
        width=800,
        plot_bgcolor='white',
        paper_bgcolor='white'
    )

    # æ·»åŠ å›¾ä¾‹
    fig.add_shape(
        type="rect",
        xref="paper", yref="paper",
        x0=0.8, y0=0.9, x1=0.82, y1=0.92,
        fillcolor="#FF5252",
        line_width=0,
        layer="below"
    )

    fig.add_annotation(
        xref="paper", yref="paper",
        x=0.83, y=0.91,
        text="é¢„æµ‹è¿‡é«˜ - å¯¼è‡´åº“å­˜ç§¯å‹",
        showarrow=False,
        font=dict(size=12),
        align="left"
    )

    fig.add_shape(
        type="rect",
        xref="paper", yref="paper",
        x0=0.8, y0=0.85, x1=0.82, y1=0.87,
        fillcolor="#4682B4",
        line_width=0,
        layer="below"
    )

    fig.add_annotation(
        xref="paper", yref="paper",
        x=0.83, y=0.86,
        text="é¢„æµ‹è¿‡ä½ - å¯èƒ½å¯¼è‡´ç¼ºè´§",
        showarrow=False,
        font=dict(size=12),
        align="left"
    )

    # æ·»åŠ æ‚¬åœä¿¡æ¯
    hover_texts = []
    for _, row in bias_df.iterrows():
        hover_text = (
            f"äº§å“ä»£ç : {row['äº§å“ä»£ç ']}<br>"
            f"é¢„æµ‹é‡: {row['é¢„æµ‹é‡']:.0f}ä»¶<br>"
            f"å®é™…é”€é‡: {row['å®é™…é”€é‡']:.0f}ä»¶<br>"
            f"é¢„æµ‹åå·®: {row['é¢„æµ‹åå·®']:.1f}%<br>"
            f"é£é™©ç¨‹åº¦: {row['é£é™©ç¨‹åº¦']}"
        )
        hover_texts.append(hover_text)

    fig.update_traces(
        hovertemplate='%{text}',
        text=hover_texts
    )

    return fig


# å‡½æ•°ï¼šåˆ›å»ºæ¸…åº“é¢„æµ‹å›¾
def create_clearance_forecast_chart(batch_analysis):
    """åˆ›å»ºæ¸…åº“é¢„æµ‹å›¾"""
    if batch_analysis.empty:
        st.warning("æ²¡æœ‰æ‰¹æ¬¡æ•°æ®å¯ä¾›åˆ†æ")
        return None

    # ç­›é€‰é«˜é£é™©æ‰¹æ¬¡
    high_risk_batches = batch_analysis[batch_analysis['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])]

    if high_risk_batches.empty:
        st.info("æ²¡æœ‰é«˜é£é™©æ‰¹æ¬¡æ•°æ®")
        return None

    # å¤„ç†æ¸…åº“å¤©æ•°æ•°å€¼
    high_risk_batches['æ¸…åº“å¤©æ•°å€¼'] = high_risk_batches['é¢„è®¡æ¸…åº“å¤©æ•°'].apply(
        lambda x: 365 if x == float('inf') else float(x)
    )

    # æŒ‰æ¸…åº“å¤©æ•°æ’åº
    sorted_batches = high_risk_batches.sort_values('æ¸…åº“å¤©æ•°å€¼', ascending=False).head(8)

    # åˆ›å»ºæ‰¹æ¬¡æ ‡ç­¾
    batch_labels = []
    for code, desc in zip(sorted_batches['äº§å“ä»£ç '], sorted_batches['æè¿°']):
        short_desc = desc[:20] + '...' if len(desc) > 20 else desc
        batch_labels.append(f"{code}: {short_desc}")

    # åˆ›å»ºæŸ±çŠ¶å›¾
    fig = go.Figure()

    # æ·»åŠ æ¸…åº“å¤©æ•°æŸ±
    fig.add_trace(go.Bar(
        y=batch_labels,
        x=sorted_batches['æ¸…åº“å¤©æ•°å€¼'],
        orientation='h',
        marker=dict(color='#FF5252'),
        text=sorted_batches['æ¸…åº“å¤©æ•°å€¼'].apply(
            lambda x: f"{int(x)}å¤©" if x < 365 else "âˆ"
        ),
        textposition='outside',
        name='é¢„è®¡æ¸…åº“å¤©æ•°'
    ))

    # æ·»åŠ åº“é¾„æŸ±
    fig.add_trace(go.Bar(
        y=batch_labels,
        x=sorted_batches['åº“é¾„'],
        orientation='h',
        marker=dict(color='#4682B4'),
        text=sorted_batches['åº“é¾„'].apply(lambda x: f"{int(x)}å¤©"),
        textposition='outside',
        name='å½“å‰åº“é¾„'
    ))

    # æ·»åŠ é£é™©é˜ˆå€¼å‚è€ƒçº¿
    fig.add_shape(
        type="line",
        x0=90, x1=90,
        y0=-0.5, y1=len(batch_labels) - 0.5,
        line=dict(color="red", width=1, dash="dash"),
        name="é«˜é£é™©é˜ˆå€¼(90å¤©)"
    )

    fig.add_shape(
        type="line",
        x0=60, x1=60,
        y0=-0.5, y1=len(batch_labels) - 0.5,
        line=dict(color="orange", width=1, dash="dash"),
        name="ä¸­é£é™©é˜ˆå€¼(60å¤©)"
    )

    fig.add_shape(
        type="line",
        x0=30, x1=30,
        y0=-0.5, y1=len(batch_labels) - 0.5,
        line=dict(color="green", width=1, dash="dash"),
        name="ä½é£é™©é˜ˆå€¼(30å¤©)"
    )

    # æ›´æ–°å¸ƒå±€
    fig.update_layout(
        title='é«˜é£é™©æ‰¹æ¬¡æ¸…åº“é¢„æµ‹åˆ†æ',
        title_font=dict(size=18, family='Arial', color='#1f3867'),
        xaxis=dict(
            title='å¤©æ•°',
            tickformat=",",
            showexponent="none"
        ),
        yaxis=dict(title='äº§å“'),
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        ),
        margin=dict(t=80, b=50, l=20, r=20),
        height=max(500, len(batch_labels) * 50),
        width=800,
        plot_bgcolor='white',
        paper_bgcolor='white'
    )

    # æ·»åŠ æ‚¬åœä¿¡æ¯
    clearance_hover_texts = []
    age_hover_texts = []
    for _, batch in sorted_batches.iterrows():
        clearance_text = (
            f"äº§å“ä»£ç : {batch['äº§å“ä»£ç ']}<br>"
            f"é¢„è®¡æ¸…åº“å¤©æ•°: {batch['æ¸…åº“å¤©æ•°å€¼']:.0f if batch['æ¸…åº“å¤©æ•°å€¼'] < 365 else 'âˆ'}å¤©<br>"
            f"æ—¥å‡å‡ºè´§: {batch['æ—¥å‡å‡ºè´§']:.2f}ç®±<br>"
            f"æ‰¹æ¬¡åº“å­˜: {batch['æ‰¹æ¬¡åº“å­˜']}ä»¶<br>"
            f"é£é™©ç¨‹åº¦: {batch['é£é™©ç¨‹åº¦']}"
        )
        clearance_hover_texts.append(clearance_text)

        age_text = (
            f"äº§å“ä»£ç : {batch['äº§å“ä»£ç ']}<br>"
            f"å½“å‰åº“é¾„: {batch['åº“é¾„']}å¤©<br>"
            f"æ‰¹æ¬¡æ—¥æœŸ: {batch['æ‰¹æ¬¡æ—¥æœŸ']}<br>"
            f"æ‰¹æ¬¡ä»·å€¼: Â¥{batch['æ‰¹æ¬¡ä»·å€¼']:,.2f}"
        )
        age_hover_texts.append(age_text)

    fig.update_traces(
        hovertemplate='%{text}',
        text=clearance_hover_texts,
        selector=dict(name='é¢„è®¡æ¸…åº“å¤©æ•°')
    )

    fig.update_traces(
        hovertemplate='%{text}',
        text=age_hover_texts,
        selector=dict(name='å½“å‰åº“é¾„')
    )

    return fig


# å‡½æ•°ï¼šåˆ›å»ºè´£ä»»åŒºåŸŸåˆ†å¸ƒå›¾
def create_responsibility_region_chart(batch_analysis):
    """åˆ›å»ºè´£ä»»åŒºåŸŸåˆ†å¸ƒå›¾"""
    if batch_analysis.empty:
        st.warning("æ²¡æœ‰æ‰¹æ¬¡æ•°æ®å¯ä¾›åˆ†æ")
        return None

    # ç­›é€‰é«˜é£é™©æ‰¹æ¬¡
    high_risk_batches = batch_analysis[batch_analysis['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])]

    if high_risk_batches.empty:
        st.info("æ²¡æœ‰é«˜é£é™©æ‰¹æ¬¡æ•°æ®")
        return None

    # è®¡ç®—å„åŒºåŸŸçš„é«˜é£é™©æ‰¹æ¬¡æ•°é‡
    region_counts = high_risk_batches['è´£ä»»åŒºåŸŸ'].value_counts()

    # è®¡ç®—å„åŒºåŸŸçš„é«˜é£é™©æ‰¹æ¬¡ä»·å€¼æ€»å’Œ
    region_values = high_risk_batches.groupby('è´£ä»»åŒºåŸŸ')['æ‰¹æ¬¡ä»·å€¼'].sum()

    # åˆ›å»ºæŸ±çŠ¶å›¾
    fig = go.Figure()

    # æ·»åŠ æ‰¹æ¬¡æ•°é‡æŸ±
    fig.add_trace(go.Bar(
        x=region_counts.index,
        y=region_counts.values,
        name='æ‰¹æ¬¡æ•°é‡',
        marker=dict(color='#4682B4'),
        text=region_counts.values,
        textposition='outside'
    ))

    # æ·»åŠ æ‰¹æ¬¡ä»·å€¼çº¿
    fig.add_trace(go.Scatter(
        x=region_values.index,
        y=region_values.values,
        mode='lines+markers',
        name='æ‰¹æ¬¡ä»·å€¼(å…ƒ)',
        yaxis='y2',
        marker=dict(size=10, color='#FF5252'),
        line=dict(width=3, color='#FF5252')
    ))

    # æ›´æ–°å¸ƒå±€
    fig.update_layout(
        title='é«˜é£é™©æ‰¹æ¬¡è´£ä»»åŒºåŸŸåˆ†å¸ƒ',
        title_font=dict(size=18, family='Arial', color='#1f3867'),
        xaxis=dict(title='è´£ä»»åŒºåŸŸ'),
        yaxis=dict(
            title='æ‰¹æ¬¡æ•°é‡',
            titlefont=dict(color='#4682B4'),
            tickfont=dict(color='#4682B4')
        ),
        yaxis2=dict(
            title='æ‰¹æ¬¡ä»·å€¼(å…ƒ)',
            titlefont=dict(color='#FF5252'),
            tickfont=dict(color='#FF5252'),
            overlaying='y',
            side='right',
            tickformat=',',
            showexponent='none'
        ),
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        ),
        margin=dict(t=80, b=50, l=50, r=100),
        height=500,
        width=800,
        plot_bgcolor='white',
        paper_bgcolor='white'
    )

    # æ·»åŠ æ‚¬åœä¿¡æ¯
    region_details = {}
    for region in region_counts.index:
        region_batches = high_risk_batches[high_risk_batches['è´£ä»»åŒºåŸŸ'] == region]
        top_products = region_batches.groupby('äº§å“ä»£ç ').size().sort_values(ascending=False).head(3)

        details = f"åŒºåŸŸ: {region}<br>æ‰¹æ¬¡æ•°: {region_counts[region]}<br>æ‰¹æ¬¡ä»·å€¼: Â¥{region_values.get(region, 0):,.2f}<br><br>ä¸»è¦äº§å“:<br>"
        for product, count in top_products.items():
            details += f"- {product}: {count}ä¸ªæ‰¹æ¬¡<br>"

        region_details[region] = details

    hover_texts = []
    for region in region_counts.index:
        hover_texts.append(region_details[region])

    fig.update_traces(
        hovertemplate='%{text}',
        text=hover_texts,
        selector=dict(name='æ‰¹æ¬¡æ•°é‡')
    )

    fig.update_traces(
        hovertemplate='%{text}',
        text=hover_texts,
        selector=dict(name='æ‰¹æ¬¡ä»·å€¼(å…ƒ)')
    )

    return fig


# å‡½æ•°ï¼šåˆ›å»ºè´£ä»»äººåˆ†å¸ƒå›¾
def create_responsibility_person_chart(batch_analysis):
    """åˆ›å»ºè´£ä»»äººåˆ†å¸ƒå›¾"""
    if batch_analysis.empty:
        st.warning("æ²¡æœ‰æ‰¹æ¬¡æ•°æ®å¯ä¾›åˆ†æ")
        return None

    # ç­›é€‰é«˜é£é™©æ‰¹æ¬¡
    high_risk_batches = batch_analysis[batch_analysis['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])]

    if high_risk_batches.empty:
        st.info("æ²¡æœ‰é«˜é£é™©æ‰¹æ¬¡æ•°æ®")
        return None

    # è®¡ç®—å„è´£ä»»äººçš„é«˜é£é™©æ‰¹æ¬¡æ•°é‡
    person_counts = high_risk_batches['è´£ä»»äºº'].value_counts().head(10)  # åªæ˜¾ç¤ºå‰10ä½è´£ä»»äºº

    # è®¡ç®—å„è´£ä»»äººçš„é«˜é£é™©æ‰¹æ¬¡ä»·å€¼æ€»å’Œ
    person_values = high_risk_batches.groupby('è´£ä»»äºº')['æ‰¹æ¬¡ä»·å€¼'].sum()
    person_values = person_values[person_counts.index]  # ä¿æŒä¸countsç›¸åŒé¡ºåº

    # åˆ›å»ºæŸ±çŠ¶å›¾
    fig = go.Figure()

    # æ·»åŠ æ‰¹æ¬¡æ•°é‡æŸ±
    fig.add_trace(go.Bar(
        x=person_counts.index,
        y=person_counts.values,
        name='æ‰¹æ¬¡æ•°é‡',
        marker=dict(color='#4682B4'),
        text=person_counts.values,
        textposition='outside'
    ))

    # æ·»åŠ æ‰¹æ¬¡ä»·å€¼çº¿
    fig.add_trace(go.Scatter(
        x=person_values.index,
        y=person_values.values,
        mode='lines+markers',
        name='æ‰¹æ¬¡ä»·å€¼(å…ƒ)',
        yaxis='y2',
        marker=dict(size=10, color='#FF5252'),
        line=dict(width=3, color='#FF5252')
    ))

    # æ›´æ–°å¸ƒå±€
    fig.update_layout(
        title='é«˜é£é™©æ‰¹æ¬¡è´£ä»»äººåˆ†å¸ƒ(å‰10ä½)',
        title_font=dict(size=18, family='Arial', color='#1f3867'),
        xaxis=dict(
            title='è´£ä»»äºº',
            tickangle=45
        ),
        yaxis=dict(
            title='æ‰¹æ¬¡æ•°é‡',
            titlefont=dict(color='#4682B4'),
            tickfont=dict(color='#4682B4')
        ),
        yaxis2=dict(
            title='æ‰¹æ¬¡ä»·å€¼(å…ƒ)',
            titlefont=dict(color='#FF5252'),
            tickfont=dict(color='#FF5252'),
            overlaying='y',
            side='right',
            tickformat=',',
            showexponent='none'
        ),
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        ),
        margin=dict(t=80, b=100, l=50, r=100),
        height=600,
        width=800,
        plot_bgcolor='white',
        paper_bgcolor='white'
    )

    # æ·»åŠ æ‚¬åœä¿¡æ¯
    person_details = {}
    for person in person_counts.index:
        person_batches = high_risk_batches[high_risk_batches['è´£ä»»äºº'] == person]
        top_products = person_batches.groupby('äº§å“ä»£ç ').size().sort_values(ascending=False).head(3)
        regions = person_batches['è´£ä»»åŒºåŸŸ'].unique()

        details = f"è´£ä»»äºº: {person}<br>æ‰¹æ¬¡æ•°: {person_counts[person]}<br>æ‰¹æ¬¡ä»·å€¼: Â¥{person_values.get(person, 0):,.2f}<br>"
        details += f"æ‰€å±åŒºåŸŸ: {', '.join(regions)}<br><br>ä¸»è¦äº§å“:<br>"

        for product, count in top_products.items():
            details += f"- {product}: {count}ä¸ªæ‰¹æ¬¡<br>"

        person_details[person] = details

    hover_texts = []
    for person in person_counts.index:
        hover_texts.append(person_details[person])

    fig.update_traces(
        hovertemplate='%{text}',
        text=hover_texts,
        selector=dict(name='æ‰¹æ¬¡æ•°é‡')
    )

    fig.update_traces(
        hovertemplate='%{text}',
        text=hover_texts,
        selector=dict(name='æ‰¹æ¬¡ä»·å€¼(å…ƒ)')
    )

    return fig


# å‡½æ•°ï¼šæ˜¾ç¤ºå¤‡è´§å»ºè®®è¡¨æ ¼
def display_recommendations_table(latest_growth, product_info):
    """æ˜¾ç¤ºäº§å“å¢é•¿ç‡å’Œå¤‡è´§å»ºè®®çš„å›¾è¡¨"""
    if latest_growth.empty:
        st.warning("æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®æ¥ç”Ÿæˆå¤‡è´§å»ºè®®å›¾è¡¨ã€‚")
        return

    # ç¡®ä¿æ•°æ®ä¸­åŒ…å«å¿…è¦çš„åˆ—
    if 'äº§å“ä»£ç ' not in latest_growth.columns:
        st.error("æ•°æ®ä¸­ç¼ºå°‘äº§å“ä»£ç åˆ—ã€‚")
        return

    # åˆ›å»ºä¸€ä¸ªå‰¯æœ¬ä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
    display_data = latest_growth.copy()

    # æ·»åŠ äº§å“æ˜¾ç¤ºåç§°ï¼ˆå¦‚æœå°šæœªå­˜åœ¨ï¼‰
    if 'äº§å“æ˜¾ç¤º' not in display_data.columns:
        display_data['äº§å“æ˜¾ç¤º'] = display_data.apply(
            lambda row: format_product_code(row['äº§å“ä»£ç '], product_info, include_name=True),
            axis=1
        )

    # æŒ‰å¢é•¿ç‡é™åºæ’åº
    display_data = display_data.sort_values('é”€é‡å¢é•¿ç‡', ascending=False)

    # æ˜¾ç¤ºå›¾è¡¨æ ‡é¢˜å’Œè¯´æ˜
    st.markdown("### äº§å“å¤‡è´§å»ºè®®ä¸€è§ˆ")
    st.markdown("""
    <div style="margin-bottom: 1rem; padding: 0.9rem; background-color: rgba(76, 175, 80, 0.1); border-radius: 0.5rem; border-left: 0.5rem solid #4CAF50;">
        <p style="margin: 0; font-size: 0.9rem;">
            <b>å›¾è¡¨è¯´æ˜</b>ï¼šå±•ç¤ºäº†äº§å“é”€é‡çš„å¢é•¿è¶‹åŠ¿ä¸å¤‡è´§å»ºè®®ã€‚è®¡ç®—æ–¹æ³•ï¼šä¼˜å…ˆä½¿ç”¨åŒæ¯”å¢é•¿ç‡ï¼ˆå½“å‰æœˆä»½ä¸å»å¹´åŒæœŸç›¸æ¯”ï¼‰ï¼Œå¦‚æ— åŒæœŸæ•°æ®åˆ™ä½¿ç”¨ç¯æ¯”å¢é•¿ç‡ï¼ˆä¸å‰ä¸€æœˆç›¸æ¯”ï¼‰ã€‚
            é¢œè‰²åŒºåˆ†äº†ä¸åŒè¶‹åŠ¿ï¼šæ·±è“è‰²è¡¨ç¤ºå¼ºåŠ²å¢é•¿(>10%)ï¼Œç»¿è‰²è¡¨ç¤ºå¢é•¿(0-10%)ï¼Œæ©™è‰²è¡¨ç¤ºè½»å¾®ä¸‹é™(-10-0%)ï¼Œçº¢è‰²è¡¨ç¤ºæ˜¾è‘—ä¸‹é™(<-10%)ã€‚
            æ‚¬åœå¯æŸ¥çœ‹è¯¦ç»†çš„å¤‡è´§å»ºè®®å’Œè°ƒæ•´å¹…åº¦ã€‚
        </p>
    </div>
    """, unsafe_allow_html=True)

    # åˆ›å»ºè¶‹åŠ¿çš„é¢œè‰²æ˜ å°„
    color_map = {
        'å¼ºåŠ²å¢é•¿': '#1E88E5',  # æ·±è“è‰²
        'å¢é•¿': '#43A047',  # ç»¿è‰²
        'è½»å¾®ä¸‹é™': '#FB8C00',  # æ©™è‰²
        'æ˜¾è‘—ä¸‹é™': '#E53935'  # çº¢è‰²
    }

    # å‡†å¤‡è‡ªå®šä¹‰æ•°æ®ç”¨äºæ‚¬åœæç¤º - ä¿®å¤ä¹±ç é—®é¢˜å’Œé”®é”™è¯¯
    custom_data = []
    for _, row in display_data.iterrows():
        # å°†æ‰€æœ‰æ•°å€¼è½¬ä¸ºå­—ç¬¦ä¸²ï¼Œé¿å…æ ¼å¼é—®é¢˜
        # ä½¿ç”¨'å½“æœˆé”€é‡'æ›¿ä»£'3ä¸ªæœˆæ»šåŠ¨é”€é‡'
        sales_value = "0"
        if 'å½“æœˆé”€é‡' in row and pd.notna(row['å½“æœˆé”€é‡']):
            sales_value = str(int(row['å½“æœˆé”€é‡']))

        trend = str(row['è¶‹åŠ¿']) if pd.notna(row['è¶‹åŠ¿']) else ""
        recommendation = str(row['å¤‡è´§å»ºè®®']) if pd.notna(row['å¤‡è´§å»ºè®®']) else ""
        adjust_pct = str(int(row['è°ƒæ•´æ¯”ä¾‹'])) + "%" if pd.notna(row['è°ƒæ•´æ¯”ä¾‹']) else "0%"
        icon = str(row.get('å»ºè®®å›¾æ ‡', '')) if pd.notna(row.get('å»ºè®®å›¾æ ‡', '')) else ""

        custom_data.append([sales_value, trend, recommendation, adjust_pct, icon])

    # åˆ›å»ºæ°´å¹³æ¡å½¢å›¾
    fig = go.Figure()

    # æ·»åŠ æ¡å½¢å›¾
    fig.add_trace(go.Bar(
        y=display_data['äº§å“æ˜¾ç¤º'],
        x=display_data['é”€é‡å¢é•¿ç‡'],
        orientation='h',
        marker=dict(
            color=[color_map.get(trend, '#1f3867') for trend in display_data['è¶‹åŠ¿']],
            line=dict(width=0)
        ),
        customdata=custom_data,
        hovertemplate='<b>%{y}</b><br>' +
                      'å¢é•¿ç‡: %{x:.1f}%<br>' +
                      'å½“å‰é”€é‡: %{customdata[0]}ç®±<br>' +  # ä¿®æ”¹æ‚¬åœä¿¡æ¯
                      'è¶‹åŠ¿: %{customdata[1]}<br>' +
                      'å¤‡è´§å»ºè®®: %{customdata[2]} %{customdata[4]}<br>' +
                      'è°ƒæ•´å¹…åº¦: %{customdata[3]}<extra></extra>'
    ))

    # æ·»åŠ é›¶çº¿
    fig.add_shape(
        type="line",
        x0=0,
        x1=0,
        y0=-0.5,
        y1=len(display_data) - 0.5,
        line=dict(color="black", width=1, dash="dash")
    )

    # æ›´æ–°å¸ƒå±€ - ä¿®æ”¹å›¾ä¾‹ä½ç½®åˆ°å›¾è¡¨ä¸Šæ–¹
    fig.update_layout(
        title="äº§å“é”€é‡å¢é•¿ç‡ä¸å¤‡è´§å»ºè®®",
        xaxis=dict(
            title="å¢é•¿ç‡ (%)",
            zeroline=False
        ),
        yaxis=dict(
            title="äº§å“",
            autorange="reversed"  # å°†æœ€é«˜å¢é•¿ç‡çš„äº§å“æ”¾åœ¨é¡¶éƒ¨
        ),
        height=max(500, len(display_data) * 30),  # åŠ¨æ€è°ƒæ•´é«˜åº¦ä»¥é€‚åº”äº§å“æ•°é‡
        margin=dict(l=10, r=10, t=100, b=10),  # å¢åŠ ä¸Šè¾¹è·ä¸ºå›¾ä¾‹ç•™å‡ºç©ºé—´
        plot_bgcolor='white'
    )

    # æ·»åŠ æ ‡æ³¨ - åœ¨æ¡å½¢æ—è¾¹æ˜¾ç¤ºå¢é•¿ç‡
    for i, row in enumerate(display_data.itertuples()):
        fig.add_annotation(
            x=row.é”€é‡å¢é•¿ç‡,
            y=row.äº§å“æ˜¾ç¤º,
            text=f"{row.é”€é‡å¢é•¿ç‡:.1f}% {row.å»ºè®®å›¾æ ‡ if hasattr(row, 'å»ºè®®å›¾æ ‡') and pd.notna(row.å»ºè®®å›¾æ ‡) else ''}",
            showarrow=False,
            xshift=10 if row.é”€é‡å¢é•¿ç‡ >= 0 else -10,
            align="left" if row.é”€é‡å¢é•¿ç‡ >= 0 else "right",
            font=dict(
                color="#43A047" if row.é”€é‡å¢é•¿ç‡ >= 0 else "#E53935",
                size=10
            )
        )

    # æ·»åŠ å›¾ä¾‹è§£é‡Šä¸åŒé¢œè‰²çš„å«ä¹‰ - ä¿®æ”¹ä½ç½®åˆ°å›¾è¡¨ä¸Šæ–¹
    legend_items = [
        {"name": "å¼ºåŠ²å¢é•¿", "color": "#1E88E5", "description": "> 10%"},
        {"name": "å¢é•¿", "color": "#43A047", "description": "0% ~ 10%"},
        {"name": "è½»å¾®ä¸‹é™", "color": "#FB8C00", "description": "-10% ~ 0%"},
        {"name": "æ˜¾è‘—ä¸‹é™", "color": "#E53935", "description": "< -10%"}
    ]

    # åœ¨å›¾è¡¨ä¸Šæ–¹æ·»åŠ å›¾ä¾‹
    legend_annotations = []
    legend_spacing = 0.25  # å›¾ä¾‹é¡¹ä¹‹é—´çš„é—´è·

    for i, item in enumerate(legend_items):
        # è®¡ç®—xä½ç½®ï¼Œå¹³å‡åˆ†å¸ƒåœ¨å›¾è¡¨å®½åº¦ä¸Š
        x_pos = 0.05 + (i * 0.25)
        legend_annotations.append(
            dict(
                x=x_pos,
                y=1.08,  # æ”¾åœ¨å›¾è¡¨ä¸Šæ–¹
                xref="paper",
                yref="paper",
                text=f"<span style='color:{item['color']};'>â– </span> {item['name']} ({item['description']})",
                showarrow=False,
                font=dict(size=10),
                align="left"
            )
        )

    fig.update_layout(annotations=legend_annotations)

    # æ˜¾ç¤ºå›¾è¡¨
    st.plotly_chart(fig, use_container_width=True)


# ä¸»ç¨‹åºå¼€å§‹
add_logo()  # æ·»åŠ Logo

# æ ‡é¢˜
st.markdown('<div class="main-header">é”€å”®é¢„æµ‹ä¸åº“å­˜é£é™©ç®¡ç†ä¸€ä½“åŒ–ä»ªè¡¨ç›˜</div>', unsafe_allow_html=True)

# ä¾§è¾¹æ  - ä¸Šä¼ æ–‡ä»¶åŒºåŸŸ
st.sidebar.header("ğŸ“‚ æ•°æ®å¯¼å…¥")
use_default_files = st.sidebar.checkbox("ä½¿ç”¨é»˜è®¤æ–‡ä»¶", value=True, help="ä½¿ç”¨æŒ‡å®šçš„é»˜è®¤æ–‡ä»¶è·¯å¾„")

# å®šä¹‰é»˜è®¤æ–‡ä»¶è·¯å¾„
DEFAULT_ACTUAL_FILE = "2409~250224å‡ºè´§æ•°æ®.xlsx"
DEFAULT_FORECAST_FILE = "2409~2502äººå·¥é¢„æµ‹.xlsx"
DEFAULT_PRODUCT_FILE = "äº§å“ä¿¡æ¯.xlsx"
DEFAULT_INVENTORY_FILE = "å«æ‰¹æ¬¡åº“å­˜0221ï¼ˆ2ï¼‰.xlsx"
DEFAULT_PRICE_FILE = "å•ä»·.xlsx"

if use_default_files:
    # ä½¿ç”¨é»˜è®¤æ–‡ä»¶è·¯å¾„
    actual_data = load_actual_data(DEFAULT_ACTUAL_FILE)
    forecast_data = load_forecast_data(DEFAULT_FORECAST_FILE)
    product_info = load_product_info(DEFAULT_PRODUCT_FILE)
    inventory_data, batch_data = load_inventory_data(DEFAULT_INVENTORY_FILE)
    price_data = load_price_data(DEFAULT_PRICE_FILE)

    if os.path.exists(DEFAULT_ACTUAL_FILE):
        st.sidebar.success(f"å·²æˆåŠŸåŠ è½½é»˜è®¤å‡ºè´§æ•°æ®æ–‡ä»¶")
    else:
        st.sidebar.warning(f"é»˜è®¤å‡ºè´§æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®")

    if os.path.exists(DEFAULT_FORECAST_FILE):
        st.sidebar.success(f"å·²æˆåŠŸåŠ è½½é»˜è®¤é¢„æµ‹æ•°æ®æ–‡ä»¶")
    else:
        st.sidebar.warning(f"é»˜è®¤é¢„æµ‹æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®")

    if os.path.exists(DEFAULT_PRODUCT_FILE):
        st.sidebar.success(f"å·²æˆåŠŸåŠ è½½é»˜è®¤äº§å“ä¿¡æ¯æ–‡ä»¶")
    else:
        st.sidebar.warning(f"é»˜è®¤äº§å“ä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®")

    if os.path.exists(DEFAULT_INVENTORY_FILE):
        st.sidebar.success(f"å·²æˆåŠŸåŠ è½½é»˜è®¤åº“å­˜æ•°æ®æ–‡ä»¶")
    else:
        st.sidebar.warning(f"é»˜è®¤åº“å­˜æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®")

    if os.path.exists(DEFAULT_PRICE_FILE):
        st.sidebar.success(f"å·²æˆåŠŸåŠ è½½é»˜è®¤å•ä»·æ•°æ®æ–‡ä»¶")
    else:
        st.sidebar.warning(f"é»˜è®¤å•ä»·æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å•ä»·")
else:
    # ä¸Šä¼ æ–‡ä»¶
    uploaded_actual = st.sidebar.file_uploader("ä¸Šä¼ å‡ºè´§æ•°æ®æ–‡ä»¶", type=["xlsx", "xls"])
    uploaded_forecast = st.sidebar.file_uploader("ä¸Šä¼ äººå·¥é¢„æµ‹æ•°æ®æ–‡ä»¶", type=["xlsx", "xls"])
    uploaded_product = st.sidebar.file_uploader("ä¸Šä¼ äº§å“ä¿¡æ¯æ–‡ä»¶", type=["xlsx", "xls"])
    uploaded_inventory = st.sidebar.file_uploader("ä¸Šä¼ åº“å­˜æ•°æ®æ–‡ä»¶", type=["xlsx", "xls"])
    uploaded_price = st.sidebar.file_uploader("ä¸Šä¼ å•ä»·æ•°æ®æ–‡ä»¶", type=["xlsx", "xls"])

    # åŠ è½½æ•°æ®
    actual_data = load_actual_data(uploaded_actual if uploaded_actual else None)
    forecast_data = load_forecast_data(uploaded_forecast if uploaded_forecast else None)
    product_info = load_product_info(uploaded_product if uploaded_product else None)
    inventory_data, batch_data = load_inventory_data(uploaded_inventory if uploaded_inventory else None)
    price_data = load_price_data(uploaded_price if uploaded_price else None)

# åˆ†ææ‰¹æ¬¡é£é™©
batch_risk_analysis = analyze_batch_risk(batch_data, actual_data, forecast_data, price_data)

# åˆ›å»ºäº§å“ä»£ç åˆ°åç§°çš„æ˜ å°„
product_names_map = {}
if not product_info.empty:
    for _, row in product_info.iterrows():
        product_names_map[row['äº§å“ä»£ç ']] = row['äº§å“åç§°']

# ç­›é€‰å…±æœ‰æœˆä»½æ•°æ®
common_months = get_common_months(actual_data, forecast_data)
actual_data_filtered = actual_data[actual_data['æ‰€å±å¹´æœˆ'].isin(common_months)]
forecast_data_filtered = forecast_data[forecast_data['æ‰€å±å¹´æœˆ'].isin(common_months)]

# å¤„ç†æ•°æ®
processed_data = process_data(actual_data_filtered, forecast_data_filtered, product_info)

# è·å–æ•°æ®çš„æ‰€æœ‰æœˆä»½
all_months = sorted(processed_data['merged_monthly']['æ‰€å±å¹´æœˆ'].unique())
latest_month = all_months[-1] if all_months else None

# è·å–æœ€è¿‘3ä¸ªæœˆ
last_three_months = get_last_three_months()
valid_last_three_months = [month for month in last_three_months if month in all_months]

# åˆ›å»ºæ ‡ç­¾é¡µ - æ›´æ–°æ ‡ç­¾é¡µç»“æ„
tabs = st.tabs(["ğŸ“Š æ€»è§ˆä¸å†å²", "ğŸ” é¢„æµ‹å·®å¼‚åˆ†æ", "ğŸ“ˆ äº§å“è¶‹åŠ¿", "ğŸ” é‡ç‚¹SKUåˆ†æ", "ğŸš¨ åº“å­˜é£é™©ç®¡ç†"])

with tabs[0]:  # æ€»è§ˆä¸å†å²æ ‡ç­¾é¡µ
    # åœ¨æ ‡ç­¾é¡µå†…æ·»åŠ ç­›é€‰å™¨
    st.markdown("### ğŸ“Š åˆ†æç­›é€‰")
    with st.expander("ç­›é€‰æ¡ä»¶", expanded=True):
        col1, col2 = st.columns(2)
        with col1:
            selected_months = st.multiselect(
                "é€‰æ‹©åˆ†ææœˆä»½",
                options=all_months,
                default=valid_last_three_months if valid_last_three_months else ([all_months[-1]] if all_months else [])
            )

        with col2:
            all_regions = sorted(processed_data['merged_monthly']['æ‰€å±åŒºåŸŸ'].unique())
            selected_regions = st.multiselect(
                "é€‰æ‹©åŒºåŸŸ",
                options=all_regions,
                default=all_regions
            )

    # æ ¹æ®ç­›é€‰æ¡ä»¶è¿‡æ»¤æ•°æ®
    filtered_monthly = filter_data(processed_data['merged_monthly'], selected_months, selected_regions)
    filtered_salesperson = filter_data(processed_data['merged_by_salesperson'], selected_months, selected_regions)

    # æ£€æŸ¥é€‰å®šæœˆä»½å’ŒåŒºåŸŸæ˜¯å¦ä¸ºç©º
    if not selected_months or not selected_regions:
        st.warning("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæœˆä»½å’Œä¸€ä¸ªåŒºåŸŸè¿›è¡Œåˆ†æã€‚")
    else:
        # è®¡ç®—æ€»è§ˆKPI
        total_actual_qty = filtered_monthly['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].sum()
        total_forecast_qty = filtered_monthly['é¢„è®¡é”€å”®é‡'].sum()
        total_diff = total_actual_qty - total_forecast_qty
        total_diff_percent = (total_diff / total_actual_qty * 100) if total_actual_qty > 0 else 0

        # æ ¹æ®ç­›é€‰æ¡ä»¶è®¡ç®—å‡†ç¡®ç‡ - ä½¿ç”¨ç­›é€‰åçš„æ•°æ®
        # è®¡ç®—å…¨å›½å‡†ç¡®ç‡ - ä½¿ç”¨ç­›é€‰åçš„æ•°æ®è®¡ç®—
        filtered_national_accuracy = calculate_national_accuracy(filtered_monthly)
        national_qty_accuracy = filtered_national_accuracy['overall']['æ•°é‡å‡†ç¡®ç‡'] * 100

        # è®¡ç®—åŒºåŸŸå‡†ç¡®ç‡ - ä½¿ç”¨ç­›é€‰åçš„æ•°æ®
        filtered_regional_accuracy = calculate_regional_accuracy(filtered_monthly)
        selected_regions_accuracy = filtered_regional_accuracy['region_overall']
        selected_regions_qty_accuracy = selected_regions_accuracy['æ•°é‡å‡†ç¡®ç‡'].mean() * 100

        # è®¡ç®—åº“å­˜é£é™©åˆ†å¸ƒ
        risk_counts = {'æé«˜é£é™©': 0, 'é«˜é£é™©': 0, 'ä¸­é£é™©': 0, 'ä½é£é™©': 0, 'æä½é£é™©': 0}
        if not batch_risk_analysis.empty:
            risk_distribution = batch_risk_analysis['é£é™©ç¨‹åº¦'].value_counts().to_dict()
            for level, count in risk_distribution.items():
                if level in risk_counts:
                    risk_counts[level] = count

        # è®¡ç®—é«˜é£é™©æ‰¹æ¬¡å æ¯”
        high_risk_count = risk_counts['æé«˜é£é™©'] + risk_counts['é«˜é£é™©']
        total_batches = sum(risk_counts.values())
        high_risk_percent = (high_risk_count / total_batches * 100) if total_batches > 0 else 0

        # æŒ‡æ ‡å¡è¡Œ
        st.markdown("### ğŸ”‘ å…³é”®ç»©æ•ˆæŒ‡æ ‡")
        col1, col2, col3, col4 = st.columns(4)

        # æ€»é”€å”®é‡
        with col1:
            st.markdown(f"""
            <div class="metric-card">
                <p class="card-header">å®é™…é”€å”®é‡</p>
                <p class="card-value">{format_number(total_actual_qty)}</p>
                <p class="card-text">é€‰å®šæœŸé—´å†…</p>
            </div>
            """, unsafe_allow_html=True)

        # æ€»é¢„æµ‹é”€å”®é‡
        with col2:
            st.markdown(f"""
            <div class="metric-card">
                <p class="card-header">é¢„æµ‹é”€å”®é‡</p>
                <p class="card-value">{format_number(total_forecast_qty)}</p>
                <p class="card-text">é€‰å®šæœŸé—´å†…</p>
            </div>
            """, unsafe_allow_html=True)

        # å…¨å›½å‡†ç¡®ç‡
        with col3:
            st.markdown(f"""
            <div class="metric-card">
                <p class="card-header">å…¨å›½é”€å”®é‡å‡†ç¡®ç‡</p>
                <p class="card-value">{national_qty_accuracy:.2f}%</p>
                <p class="card-text">æ•´ä½“é¢„æµ‹ç²¾åº¦</p>
                <p class="card-text" style="font-style: italic; font-size: 0.8rem;">è®¡ç®—é€»è¾‘ï¼š1-|å®é™…é”€é‡-é¢„æµ‹é”€é‡|/å®é™…é”€é‡</p>
            </div>
            """, unsafe_allow_html=True)

        # åº“å­˜é£é™©æŒ‡æ ‡
        with col4:
            st.markdown(f"""
            <div class="metric-card">
                <p class="card-header">é«˜é£é™©åº“å­˜æ‰¹æ¬¡</p>
                <p class="card-value">{high_risk_count} <span style="font-size: 1rem;">({high_risk_percent:.1f}%)</span></p>
                <p class="card-text">éœ€ç´§æ€¥å¤„ç†çš„åº“å­˜æ‰¹æ¬¡</p>
                <p class="card-text" style="font-style: italic; font-size: 0.8rem;">åŒ…æ‹¬æé«˜é£é™©({risk_counts['æé«˜é£é™©']})å’Œé«˜é£é™©({risk_counts['é«˜é£é™©']})æ‰¹æ¬¡</p>
            </div>
            """, unsafe_allow_html=True)

        # åŒºåŸŸé”€å”®åˆ†æ
        st.markdown('<div class="sub-header">ğŸ“Š åŒºåŸŸé”€å”®åˆ†æ</div>', unsafe_allow_html=True)

        # è®¡ç®—æ¯ä¸ªåŒºåŸŸçš„é”€å”®é‡å’Œé¢„æµ‹é‡
        region_sales_comparison = filtered_monthly.groupby('æ‰€å±åŒºåŸŸ').agg({
            'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum',
            'é¢„è®¡é”€å”®é‡': 'sum'
        }).reset_index()

        # è®¡ç®—å·®å¼‚
        region_sales_comparison['å·®å¼‚'] = region_sales_comparison['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] - region_sales_comparison[
            'é¢„è®¡é”€å”®é‡']
        region_sales_comparison['å·®å¼‚ç‡'] = region_sales_comparison['å·®å¼‚'] / region_sales_comparison[
            'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] * 100

        # åˆ›å»ºæ°´å¹³å †å æŸ±çŠ¶å›¾
        fig_sales_comparison = go.Figure()

        # æ·»åŠ å®é™…é”€å”®é‡æŸ±
        fig_sales_comparison.add_trace(go.Bar(
            y=region_sales_comparison['æ‰€å±åŒºåŸŸ'],
            x=region_sales_comparison['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'],
            name='å®é™…é”€å”®é‡',
            marker_color='royalblue',
            orientation='h'
        ))

        # æ·»åŠ é¢„æµ‹é”€å”®é‡æŸ±
        fig_sales_comparison.add_trace(go.Bar(
            y=region_sales_comparison['æ‰€å±åŒºåŸŸ'],
            x=region_sales_comparison['é¢„è®¡é”€å”®é‡'],
            name='é¢„æµ‹é”€å”®é‡',
            marker_color='lightcoral',
            orientation='h'
        ))

        # æ·»åŠ å·®å¼‚ç‡ç‚¹
        fig_sales_comparison.add_trace(go.Scatter(
            y=region_sales_comparison['æ‰€å±åŒºåŸŸ'],
            x=[region_sales_comparison['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].max() * 1.05] * len(region_sales_comparison),  # æ”¾åœ¨å³ä¾§
            mode='markers+text',
            marker=dict(
                color=region_sales_comparison['å·®å¼‚ç‡'].apply(lambda x: 'green' if x > 0 else 'red'),
                size=10
            ),
            text=[f"{x:.1f}%" for x in region_sales_comparison['å·®å¼‚ç‡']],
            textposition='middle right',
            name='å·®å¼‚ç‡ (%)'
        ))

        # æ›´æ–°å¸ƒå±€
        fig_sales_comparison.update_layout(
            title="å„åŒºåŸŸé¢„æµ‹ä¸å®é™…é”€å”®å¯¹æ¯”",
            barmode='group',
            xaxis=dict(
                title="é”€å”®é‡ (ç®±)",
                tickformat=",",
                showexponent="none"
            ),
            yaxis=dict(title="åŒºåŸŸ"),
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
            plot_bgcolor='white'
        )

        # ä¸ºæ¯ä¸ªåŒºåŸŸå‡†å¤‡è¯¦ç»†ä¿¡æ¯
        region_details = []
        for _, region_row in region_sales_comparison.iterrows():
            region = region_row['æ‰€å±åŒºåŸŸ']
            # è·å–è¯¥åŒºåŸŸæ•°æ®
            region_data = filtered_monthly[filtered_monthly['æ‰€å±åŒºåŸŸ'] == region]

            if not region_data.empty:
                # æ‰¾å‡ºå·®å¼‚æœ€å¤§çš„äº§å“
                product_diff = region_data.groupby('äº§å“ä»£ç ').agg({
                    'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum',
                    'é¢„è®¡é”€å”®é‡': 'sum'
                })
                product_diff['å·®å¼‚'] = product_diff['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] - product_diff['é¢„è®¡é”€å”®é‡']
                product_diff['å·®å¼‚ç‡'] = product_diff.apply(
                    lambda row: (row['å·®å¼‚'] / row['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] * 100) if row['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] > 0 else 0,
                    axis=1
                )

                if not product_diff.empty:
                    # æ‰¾å‡ºå·®å¼‚ç‡æœ€å¤§çš„äº§å“
                    max_diff_idx = product_diff['å·®å¼‚ç‡'].abs().idxmax()
                    product_code = max_diff_idx
                    product_name = format_product_code(product_code, product_info, include_name=True)
                    actual = product_diff.loc[max_diff_idx, 'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰']
                    forecast = product_diff.loc[max_diff_idx, 'é¢„è®¡é”€å”®é‡']
                    diff_rate = product_diff.loc[max_diff_idx, 'å·®å¼‚ç‡']

                    # æ‰¾è¯¥äº§å“çš„ä¸»è¦é”€å”®å‘˜
                    product_sales = filtered_salesperson[
                        (filtered_salesperson['æ‰€å±åŒºåŸŸ'] == region) &
                        (filtered_salesperson['äº§å“ä»£ç '] == product_code)
                        ]

                    if not product_sales.empty:
                        sales_by_person = product_sales.groupby('é”€å”®å‘˜').agg({
                            'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum'
                        })
                        top_salesperson = sales_by_person[
                            'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].idxmax() if not sales_by_person.empty else "æœªçŸ¥"
                    else:
                        top_salesperson = "æœªçŸ¥"

                    detail = f"æœ€å¤§å·®å¼‚äº§å“: {product_name}<br>"
                    detail += f"å®é™…é”€é‡: {actual:.0f}ç®±<br>"
                    detail += f"é¢„æµ‹é”€é‡: {forecast:.0f}ç®±<br>"
                    detail += f"å·®å¼‚ç‡: {diff_rate:.1f}%<br>"
                    detail += f"ä¸»è¦é”€å”®å‘˜: {top_salesperson}"
                else:
                    detail = "æ— äº§å“å·®å¼‚æ•°æ®"
            else:
                detail = "æ— åŒºåŸŸæ•°æ®"

            region_details.append(detail)

        # æ›´æ–°æ‚¬åœæ¨¡æ¿
        fig_sales_comparison.update_traces(
            hovertemplate='<b>%{y}åŒºåŸŸ</b><br>%{x:,.0f}ç®±<br><br><b>å·®å¼‚è¯¦æƒ…:</b><br>%{customdata}<extra>%{name}</extra>',
            customdata=region_details,
            selector=dict(type='bar')
        )

        st.plotly_chart(fig_sales_comparison, use_container_width=True)

        # ç”ŸæˆåŠ¨æ€è§£è¯»
        diff_explanation = f"""
        <b>å›¾è¡¨è§£è¯»ï¼š</b> æ­¤å›¾å±•ç¤ºäº†å„åŒºåŸŸçš„å®é™…é”€å”®é‡(è“è‰²)ä¸é¢„æµ‹é”€å”®é‡(çº¢è‰²)å¯¹æ¯”ï¼Œç»¿è‰²ç‚¹è¡¨ç¤ºæ­£å·®å¼‚ç‡(ä½ä¼°)ï¼Œçº¢è‰²ç‚¹è¡¨ç¤ºè´Ÿå·®å¼‚ç‡(é«˜ä¼°)ã€‚
        å·®å¼‚ç‡è¶Šé«˜(ç»å¯¹å€¼è¶Šå¤§)ï¼Œè¡¨æ˜é¢„æµ‹åç¦»å®é™…çš„ç¨‹åº¦è¶Šå¤§ã€‚
        """

        # æ·»åŠ å…·ä½“åˆ†æ
        if not region_sales_comparison.empty:
            # æ‰¾å‡ºå·®å¼‚æœ€å¤§çš„é¡¹ç›®
            high_diff_regions = region_sales_comparison[abs(region_sales_comparison['å·®å¼‚ç‡']) > 15]
            if not high_diff_regions.empty:
                diff_explanation += "<br><b>éœ€å…³æ³¨åŒºåŸŸï¼š</b> "
                for _, row in high_diff_regions.iterrows():
                    if row['å·®å¼‚ç‡'] > 0:
                        diff_explanation += f"{row['æ‰€å±åŒºåŸŸ']}åŒºåŸŸä½ä¼°äº†{row['å·®å¼‚ç‡']:.1f}%ï¼Œ"
                    else:
                        diff_explanation += f"{row['æ‰€å±åŒºåŸŸ']}åŒºåŸŸé«˜ä¼°äº†{abs(row['å·®å¼‚ç‡']):.1f}%ï¼Œ"

            diff_explanation += f"<br><b>è¡ŒåŠ¨å»ºè®®ï¼š</b> "

            # æ·»åŠ å…·ä½“å»ºè®®
            if not high_diff_regions.empty:
                for _, row in high_diff_regions.iterrows():
                    if row['å·®å¼‚ç‡'] > 0:
                        adjust = abs(round(row['å·®å¼‚ç‡']))
                        diff_explanation += f"å»ºè®®{row['æ‰€å±åŒºåŸŸ']}åŒºåŸŸæé«˜é¢„æµ‹é‡{adjust}%ä»¥æ»¡è¶³å®é™…éœ€æ±‚ï¼›"
                    else:
                        adjust = abs(round(row['å·®å¼‚ç‡']))
                        diff_explanation += f"å»ºè®®{row['æ‰€å±åŒºåŸŸ']}åŒºåŸŸé™ä½é¢„æµ‹é‡{adjust}%ä»¥é¿å…åº“å­˜ç§¯å‹ï¼›"
            else:
                diff_explanation += "å„åŒºåŸŸé¢„æµ‹ä¸å®é™…é”€å”®è¾ƒä¸ºåŒ¹é…ï¼Œå»ºè®®ç»´æŒå½“å‰é¢„æµ‹æ–¹æ³•ã€‚"

        # åº“å­˜é£é™©åˆ†å¸ƒæ¦‚è§ˆ
        st.markdown('<div class="sub-header">ğŸš¨ åº“å­˜é£é™©æ¦‚è§ˆ</div>', unsafe_allow_html=True)

        col1, col2 = st.columns([1, 1])

        with col1:
            # åˆ›å»ºé£é™©åˆ†å¸ƒé¥¼å›¾
            risk_chart = create_risk_distribution_chart(batch_risk_analysis)
            if risk_chart:
                st.plotly_chart(risk_chart, use_container_width=True)
            else:
                st.info("æ²¡æœ‰è¶³å¤Ÿçš„æ‰¹æ¬¡æ•°æ®æ¥ç”Ÿæˆé£é™©åˆ†å¸ƒå›¾")

        with col2:
            # é«˜é£é™©æ‰¹æ¬¡åº“é¾„åˆ†å¸ƒå›¾
            high_risk_chart = create_high_risk_batches_chart(batch_risk_analysis)
            if high_risk_chart:
                st.plotly_chart(high_risk_chart, use_container_width=True)
            else:
                st.info("æ²¡æœ‰é«˜é£é™©æ‰¹æ¬¡æ•°æ®æ¥ç”Ÿæˆåº“é¾„åˆ†å¸ƒå›¾")

        # é£é™©è§£è¯»
        risk_explanation = f"""
        <b>é£é™©åˆ†å¸ƒè§£è¯»ï¼š</b> å·¦å›¾å±•ç¤ºäº†æ‰€æœ‰åº“å­˜æ‰¹æ¬¡æŒ‰é£é™©ç­‰çº§çš„åˆ†å¸ƒæƒ…å†µï¼Œå³å›¾æ˜¾ç¤ºäº†é«˜é£é™©æ‰¹æ¬¡çš„åº“é¾„åˆ†å¸ƒã€‚
        é£é™©è¯„ä¼°åŸºäºåº“é¾„ã€æ¸…åº“å¤©æ•°ã€é”€é‡æ³¢åŠ¨ç­‰å› ç´ ç»¼åˆè®¡ç®—ï¼Œåˆ†ä¸ºæé«˜é£é™©ã€é«˜é£é™©ã€ä¸­é£é™©ã€ä½é£é™©å’Œæä½é£é™©äº”ä¸ªç­‰çº§ã€‚
        """

        # æ·»åŠ å…·ä½“åˆ†æ
        high_risk_batches = batch_risk_analysis[batch_risk_analysis['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])]
        if not high_risk_batches.empty:
            avg_age = high_risk_batches['åº“é¾„'].mean()
            oldest_batch = high_risk_batches.iloc[high_risk_batches['åº“é¾„'].idxmax()]
            total_value = high_risk_batches['æ‰¹æ¬¡ä»·å€¼'].sum()

            risk_explanation += f"<br><b>é«˜é£é™©æ‰¹æ¬¡åˆ†æï¼š</b> "
            risk_explanation += f"å…±æœ‰{len(high_risk_batches)}ä¸ªé«˜é£é™©æ‰¹æ¬¡ï¼Œå¹³å‡åº“é¾„{avg_age:.1f}å¤©ï¼Œæœ€é•¿åº“é¾„æ‰¹æ¬¡ä¸º{oldest_batch['äº§å“ä»£ç ']}({oldest_batch['åº“é¾„']}å¤©)ã€‚"
            risk_explanation += f"è¿™äº›æ‰¹æ¬¡æ€»ä»·å€¼{total_value:,.2f}å…ƒï¼Œå ç”¨ä»“å‚¨èµ„æºå’Œèµ„é‡‘æˆæœ¬ã€‚"

            risk_explanation += f"<br><b>è¡ŒåŠ¨å»ºè®®ï¼š</b> "
            risk_explanation += f"ä¼˜å…ˆå¤„ç†æé«˜é£é™©æ‰¹æ¬¡ï¼Œè€ƒè™‘æŠ˜ä»·ä¿ƒé”€æˆ–è½¬ä»“è°ƒé…ï¼›å¯¹é«˜é£é™©æ‰¹æ¬¡åˆ¶å®šæ¸…åº“è®¡åˆ’ï¼›åŠ å¼ºé¢„æµ‹å‡†ç¡®æ€§ï¼Œå‡å°‘æœªæ¥åº“å­˜ç§¯å‹é£é™©ã€‚"
        else:
            risk_explanation += "<br><b>å½“å‰æ— é«˜é£é™©æ‰¹æ¬¡ï¼Œåº“å­˜çŠ¶å†µè‰¯å¥½ã€‚ç»§ç»­ä¿æŒå½“å‰åº“å­˜ç®¡ç†æ°´å¹³ã€‚</b>"

        add_chart_explanation(risk_explanation)
        add_chart_explanation(diff_explanation)

        # æ·»åŠ å†å²è¶‹åŠ¿åˆ†æéƒ¨åˆ†
        st.markdown('<div class="sub-header">ğŸ“Š é”€å”®ä¸é¢„æµ‹å†å²è¶‹åŠ¿</div>', unsafe_allow_html=True)

        # å‡†å¤‡å†å²è¶‹åŠ¿æ•°æ®
        monthly_trend = filtered_monthly.groupby(['æ‰€å±å¹´æœˆ', 'æ‰€å±åŒºåŸŸ']).agg({
            'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum',
            'é¢„è®¡é”€å”®é‡': 'sum'
        }).reset_index()

        # ä½¿ç”¨å…¨å›½æ•°æ®ï¼Œä¸å†æä¾›åŒºåŸŸé€‰æ‹©å™¨
        selected_region_for_trend = 'å…¨å›½'

        if selected_region_for_trend == 'å…¨å›½':
            # è®¡ç®—å…¨å›½è¶‹åŠ¿
            national_trend = monthly_trend.groupby('æ‰€å±å¹´æœˆ').agg({
                'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum',
                'é¢„è®¡é”€å”®é‡': 'sum'
            }).reset_index()

            trend_data = national_trend
        else:
            # ç­›é€‰åŒºåŸŸè¶‹åŠ¿
            region_trend = monthly_trend[monthly_trend['æ‰€å±åŒºåŸŸ'] == selected_region_for_trend]
            trend_data = region_trend

        # åˆ›å»ºé”€å”®ä¸é¢„æµ‹è¶‹åŠ¿å›¾
        fig_trend = go.Figure()

        # æ·»åŠ å®é™…é”€å”®çº¿
        fig_trend.add_trace(go.Scatter(
            x=trend_data['æ‰€å±å¹´æœˆ'],
            y=trend_data['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'],
            mode='lines+markers',
            name='å®é™…é”€å”®é‡',
            line=dict(color='royalblue', width=3),
            marker=dict(size=8)
        ))

        # æ·»åŠ é¢„æµ‹é”€å”®çº¿
        fig_trend.add_trace(go.Scatter(
            x=trend_data['æ‰€å±å¹´æœˆ'],
            y=trend_data['é¢„è®¡é”€å”®é‡'],
            mode='lines+markers',
            name='é¢„æµ‹é”€å”®é‡',
            line=dict(color='lightcoral', width=3, dash='dot'),
            marker=dict(size=8)
        ))

        # è®¡ç®—å·®å¼‚ç‡
        trend_data['å·®å¼‚ç‡'] = (trend_data['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] - trend_data['é¢„è®¡é”€å”®é‡']) / trend_data[
            'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] * 100

        # æ·»åŠ å·®å¼‚ç‡çº¿
        fig_trend.add_trace(go.Scatter(
            x=trend_data['æ‰€å±å¹´æœˆ'],
            y=trend_data['å·®å¼‚ç‡'],
            mode='lines+markers+text',
            name='å·®å¼‚ç‡ (%)',
            yaxis='y2',
            line=dict(color='green', width=2),
            marker=dict(size=8),
            text=[f"{x:.1f}%" for x in trend_data['å·®å¼‚ç‡']],
            textposition='top center'
        ))

        # æ›´æ–°å¸ƒå±€
        title = f"é”€å”®ä¸é¢„æµ‹å†å²è¶‹åŠ¿åˆ†æ"  # åˆ é™¤äº†"å…¨å›½"å‰ç¼€
        fig_trend.update_layout(
            title=title,
            xaxis_title="æœˆä»½",
            yaxis=dict(
                title="é”€å”®é‡ (ç®±)",
                tickformat=",",
                showexponent="none"
            ),
            yaxis2=dict(
                title="å·®å¼‚ç‡ (%)",
                overlaying='y',
                side='right'
            ),
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
            plot_bgcolor='white'
        )

        # æ·»åŠ æ‚¬åœæç¤º
        fig_trend.update_traces(
            hovertemplate='<b>%{x}</b><br>%{name}: %{y:,.0f}ç®±<extra></extra>',
            selector=dict(name=['å®é™…é”€å”®é‡', 'é¢„æµ‹é”€å”®é‡'])
        )

        fig_trend.update_traces(
            hovertemplate='<b>%{x}</b><br>%{name}: %{y:.2f}%<extra></extra>',
            selector=dict(name='å·®å¼‚ç‡ (%)')
        )

        # å¼ºè°ƒé€‰å®šæœˆä»½
        if selected_months:
            for month in selected_months:
                if month in trend_data['æ‰€å±å¹´æœˆ'].values:
                    fig_trend.add_shape(
                        type="rect",
                        x0=month,
                        x1=month,
                        y0=0,
                        y1=trend_data['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].max() * 1.1,
                        fillcolor="rgba(144, 238, 144, 0.2)",
                        line=dict(width=0)
                    )

        st.plotly_chart(fig_trend, use_container_width=True)

        # ç”ŸæˆåŠ¨æ€è§£è¯»
        trend_explanation = f"""
        <b>å›¾è¡¨è§£è¯»ï¼š</b> æ­¤å›¾å±•ç¤ºäº†{selected_region_for_trend}å†å²é”€å”®é‡(è“çº¿)ä¸é¢„æµ‹é”€å”®é‡(çº¢çº¿)è¶‹åŠ¿ï¼Œä»¥åŠæœˆåº¦å·®å¼‚ç‡(ç»¿çº¿)ã€‚
        é€šè¿‡è§‚å¯Ÿè¶‹åŠ¿å¯ä»¥å‘ç°é”€å”®çš„å­£èŠ‚æ€§æ³¢åŠ¨ã€é¢„æµ‹ä¸å®é™…çš„ä¸€è‡´æ€§ä»¥åŠå·®å¼‚ç‡çš„å˜åŒ–è¶‹åŠ¿ã€‚
        """

        # æ·»åŠ å…·ä½“åˆ†æ
        if not trend_data.empty and len(trend_data) > 1:
            # è®¡ç®—æ•´ä½“è¶‹åŠ¿
            sales_trend = np.polyfit(range(len(trend_data)), trend_data['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'], 1)[0]
            sales_trend_direction = "ä¸Šå‡" if sales_trend > 0 else "ä¸‹é™"

            # æ‰¾å‡ºå·®å¼‚ç‡æœ€å¤§å’Œæœ€å°çš„æœˆä»½
            max_diff_month = trend_data.loc[trend_data['å·®å¼‚ç‡'].abs().idxmax()]

            # è®¡ç®—å‡†ç¡®ç‡å‡å€¼
            accuracy_mean = (100 - abs(trend_data['å·®å¼‚ç‡'])).mean()

            trend_explanation += f"<br><b>è¶‹åŠ¿åˆ†æï¼š</b> "

            trend_explanation += f"{selected_region_for_trend}é”€å”®é‡æ•´ä½“å‘ˆ{sales_trend_direction}è¶‹åŠ¿ï¼Œ"
            trend_explanation += f"å†å²å‡†ç¡®ç‡å¹³å‡ä¸º{accuracy_mean:.1f}%ï¼Œ"
            trend_explanation += f"{max_diff_month['æ‰€å±å¹´æœˆ']}æœˆå·®å¼‚ç‡æœ€å¤§ï¼Œè¾¾{max_diff_month['å·®å¼‚ç‡']:.1f}%ã€‚"

            # ç”Ÿæˆå»ºè®®
            trend_explanation += f"<br><b>è¡ŒåŠ¨å»ºè®®ï¼š</b> "

            # æ ¹æ®è¶‹åŠ¿åˆ†æç”Ÿæˆå»ºè®®
            if abs(trend_data['å·®å¼‚ç‡']).mean() > 10:
                trend_explanation += f"é’ˆå¯¹{selected_region_for_trend}çš„é”€å”®é¢„æµ‹ä»æœ‰æå‡ç©ºé—´ï¼Œå»ºè®®åˆ†æå·®å¼‚ç‡è¾ƒå¤§æœˆä»½çš„åŸå› ï¼›"

                # æ£€æŸ¥æ˜¯å¦æœ‰å­£èŠ‚æ€§æ¨¡å¼
                month_numbers = [int(m.split('-')[1]) for m in trend_data['æ‰€å±å¹´æœˆ']]
                if len(month_numbers) >= 12:
                    spring_diff = abs(trend_data[trend_data['æ‰€å±å¹´æœˆ'].str.contains(r'-0[345])]['
                    å·®å¼‚ç‡
                    ']).mean()
                    summer_diff = abs(trend_data[trend_data['æ‰€å±å¹´æœˆ'].str.contains(r'-0[678])]['
                    å·®å¼‚ç‡
                    ']).mean()
                    autumn_diff = abs(
                        trend_data[trend_data['æ‰€å±å¹´æœˆ'].str.contains(r'-0[9]$|10|11)]['
                    å·®å¼‚ç‡
                    ']).mean()
                    winter_diff = abs(
                        trend_data[trend_data['æ‰€å±å¹´æœˆ'].str.contains(r'-12$|-0[12])]['
                    å·®å¼‚ç‡
                    ']).mean()

                    seasons = [('æ˜¥å­£', spring_diff), ('å¤å­£', summer_diff), ('ç§‹å­£', autumn_diff),
                               ('å†¬å­£', winter_diff)]
                    worst_season = max(seasons, key=lambda x: x[1])

                    trend_explanation += f"ç‰¹åˆ«æ³¨æ„{worst_season[0]}æœˆä»½çš„é¢„æµ‹ï¼Œå†å²ä¸Šè¿™äº›æœˆä»½å·®å¼‚ç‡è¾ƒå¤§({worst_season[1]:.1f}%)ï¼›"

                    trend_explanation += "è€ƒè™‘åœ¨é¢„æµ‹æ¨¡å‹ä¸­å¢åŠ å­£èŠ‚æ€§å› ç´ ï¼Œæé«˜å­£èŠ‚æ€§é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚"
                    else:
                    trend_explanation += f"{selected_region_for_trend}çš„é”€å”®é¢„æµ‹æ•´ä½“è¡¨ç°è‰¯å¥½ï¼Œå»ºè®®ä¿æŒå½“å‰é¢„æµ‹æ–¹æ³•ï¼Œ"
                    trend_explanation += "æŒç»­ç›‘æ§é”€å”®è¶‹åŠ¿å˜åŒ–ï¼ŒåŠæ—¶è°ƒæ•´é¢„æµ‹æ¨¡å‹ã€‚"

                    add_chart_explanation(trend_explanation)

                    with tabs[1]:  # é¢„æµ‹å·®å¼‚åˆ†ææ ‡ç­¾é¡µ
                    # åœ¨æ ‡ç­¾é¡µå†…æ·»åŠ ç­›é€‰å™¨
                        st.markdown("### ğŸ“Š é¢„æµ‹å·®å¼‚åˆ†æç­›é€‰")
                    with st.expander("ç­›é€‰æ¡ä»¶", expanded=True):
                        col1, col2, col3 = st.columns(3)

                    with col1:
                        diff_selected_months = st.multiselect(
                            "é€‰æ‹©åˆ†ææœˆä»½",
                            options=all_months,
                            default=valid_last_three_months if valid_last_three_months else (
                                [all_months[-1]] if all_months else []),
                            key="diff_months"
                        )

                    with col2:
                        diff_selected_regions = st.multiselect(
                            "é€‰æ‹©åŒºåŸŸ",
                            options=all_regions,
                            default=all_regions,
                            key="diff_regions"
                        )

                    with col3:
                        analysis_dimension = st.selectbox(
                            "é€‰æ‹©åˆ†æç»´åº¦",
                            options=['äº§å“', 'é”€å”®å‘˜'],
                            key="dimension_select"
                        )

                    # ç­›é€‰æ•°æ®
                    diff_filtered_monthly = filter_data(processed_data['merged_monthly'], diff_selected_months,
                                                        diff_selected_regions)
                    diff_filtered_salesperson = filter_data(processed_data['merged_by_salesperson'],
                                                            diff_selected_months,
                                                            diff_selected_regions)

                    # æ£€æŸ¥ç­›é€‰æ¡ä»¶æ˜¯å¦æœ‰æ•ˆ
                    if not diff_selected_months or not diff_selected_regions:
                        st.warning("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæœˆä»½å’Œä¸€ä¸ªåŒºåŸŸè¿›è¡Œåˆ†æã€‚")
                    else:
                        st.markdown("### é¢„æµ‹å·®å¼‚è¯¦ç»†åˆ†æ")

                    # ä½¿ç”¨å…¨å›½æ•°æ®ï¼Œä¸å†æä¾›åŒºåŸŸé€‰æ‹©
                    selected_region_for_diff = 'å…¨å›½'

                    # å‡†å¤‡æ•°æ®
                    if selected_region_for_diff == 'å…¨å›½':
                    # å…¨å›½æ•°æ®ï¼ŒæŒ‰é€‰å®šç»´åº¦æ±‡æ€»
                        if
                    analysis_dimension == 'äº§å“':
                    diff_data = diff_filtered_monthly.groupby(['äº§å“ä»£ç ', 'æ‰€å±åŒºåŸŸ']).agg({
                        'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum',
                        'é¢„è®¡é”€å”®é‡': 'sum',
                    }).reset_index()

                    # åˆå¹¶é”€å”®å‘˜ä¿¡æ¯(æŒ‰åŒºåŸŸå’Œäº§å“åˆ†ç»„)
                    sales_info = diff_filtered_salesperson.groupby(['æ‰€å±åŒºåŸŸ', 'äº§å“ä»£ç ', 'é”€å”®å‘˜']).agg({
                        'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum'
                    }).reset_index()

                    # å¯¹æ¯ä¸ªäº§å“æ‰¾å‡ºä¸»è¦é”€å”®å‘˜(é”€é‡æœ€å¤§çš„)
                    top_sales = sales_info.loc[sales_info.groupby(['æ‰€å±åŒºåŸŸ', 'äº§å“ä»£ç '])['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].idxmax()]
                    top_sales = top_sales[['æ‰€å±åŒºåŸŸ', 'äº§å“ä»£ç ', 'é”€å”®å‘˜']]

                    # å°†é”€å”®å‘˜ä¿¡æ¯åˆå¹¶åˆ°å·®å¼‚æ•°æ®ä¸­
                    diff_data = pd.merge(diff_data, top_sales, on=['æ‰€å±åŒºåŸŸ', 'äº§å“ä»£ç '], how='left')

                    # æ±‡æ€»åˆ°äº§å“çº§åˆ«
                    diff_summary = diff_data.groupby('äº§å“ä»£ç ').agg({
                        'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum',
                        'é¢„è®¡é”€å”®é‡': 'sum'
                    }).reset_index()

                    else:  # é”€å”®å‘˜ç»´åº¦
                    diff_data = diff_filtered_salesperson.groupby(['é”€å”®å‘˜', 'æ‰€å±åŒºåŸŸ', 'äº§å“ä»£ç ']).agg({
                        'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum',
                        'é¢„è®¡é”€å”®é‡': 'sum'
                    }).reset_index()

                    # å¯¹æ¯ä¸ªé”€å”®å‘˜æ‰¾å‡ºä¸»è¦äº§å“(é”€é‡æœ€å¤§çš„)
                    top_products = diff_data.loc[diff_data.groupby(['é”€å”®å‘˜', 'æ‰€å±åŒºåŸŸ'])['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].idxmax()]
                    top_products = top_products[['é”€å”®å‘˜', 'æ‰€å±åŒºåŸŸ', 'äº§å“ä»£ç ']]

                    # æ±‡æ€»åˆ°é”€å”®å‘˜çº§åˆ«
                    diff_summary = diff_data.groupby('é”€å”®å‘˜').agg({
                        'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum',
                        'é¢„è®¡é”€å”®é‡': 'sum'
                    }).reset_index()
                    else:
                    # é€‰å®šåŒºåŸŸæ•°æ®ï¼ŒæŒ‰é€‰å®šç»´åº¦æ±‡æ€»
                    region_filtered = diff_filtered_monthly[
                        diff_filtered_monthly['æ‰€å±åŒºåŸŸ'] == selected_region_for_diff]
                    region_filtered_salesperson = diff_filtered_salesperson[
                        diff_filtered_salesperson['æ‰€å±åŒºåŸŸ'] == selected_region_for_diff]

                    if analysis_dimension == 'äº§å“':
                        diff_data = region_filtered.groupby(['äº§å“ä»£ç ']).agg({
                            'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum',
                            'é¢„è®¡é”€å”®é‡': 'sum'
                        }).reset_index()

                    # åˆå¹¶é”€å”®å‘˜ä¿¡æ¯
                    sales_info = region_filtered_salesperson.groupby(['äº§å“ä»£ç ', 'é”€å”®å‘˜']).agg({
                        'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum'
                    }).reset_index()

                    # å¯¹æ¯ä¸ªäº§å“æ‰¾å‡ºä¸»è¦é”€å”®å‘˜(é”€é‡æœ€å¤§çš„)
                    top_sales = sales_info.loc[sales_info.groupby('äº§å“ä»£ç ')['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].idxmax()]
                    top_sales = top_sales[['äº§å“ä»£ç ', 'é”€å”®å‘˜']]

                    # å°†é”€å”®å‘˜ä¿¡æ¯åˆå¹¶åˆ°å·®å¼‚æ•°æ®ä¸­
                    diff_data = pd.merge(diff_data, top_sales, on='äº§å“ä»£ç ', how='left')

                    # æ±‡æ€»å’Œå·®å¼‚æ•°æ®ä¿æŒä¸€è‡´
                    diff_summary = diff_data.copy()

                    else:  # é”€å”®å‘˜ç»´åº¦
                    diff_data = region_filtered_salesperson.groupby(['é”€å”®å‘˜', 'äº§å“ä»£ç ']).agg({
                        'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum',
                        'é¢„è®¡é”€å”®é‡': 'sum'
                    }).reset_index()

                    # å¯¹æ¯ä¸ªé”€å”®å‘˜æ‰¾å‡ºä¸»è¦äº§å“(é”€é‡æœ€å¤§çš„)
                    top_products = diff_data.loc[diff_data.groupby('é”€å”®å‘˜')['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].idxmax()]
                    top_products = top_products[['é”€å”®å‘˜', 'äº§å“ä»£ç ']]

                    # æ±‡æ€»åˆ°é”€å”®å‘˜çº§åˆ«
                    diff_summary = diff_data.groupby('é”€å”®å‘˜').agg({
                        'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum',
                        'é¢„è®¡é”€å”®é‡': 'sum'
                    }).reset_index()

                    # è®¡ç®—å·®å¼‚å’Œå·®å¼‚ç‡
                    diff_summary['æ•°é‡å·®å¼‚'] = diff_summary['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] - diff_summary['é¢„è®¡é”€å”®é‡']
                    diff_summary['æ•°é‡å·®å¼‚ç‡'] = diff_summary['æ•°é‡å·®å¼‚'] / diff_summary['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] * 100

                    # å¤„ç†äº§å“åç§°æ˜¾ç¤º
                    if analysis_dimension == 'äº§å“':
                        diff_summary['äº§å“åç§°'] = diff_summary['äº§å“ä»£ç '].apply(
                            lambda x: product_names_map.get(x, ''))
                    diff_summary['äº§å“æ˜¾ç¤º'] = diff_summary.apply(
                        lambda row: format_product_code(row['äº§å“ä»£ç '], product_info, include_name=True),
                        axis=1
                    )
                    dimension_column = 'äº§å“æ˜¾ç¤º'
                    else:
                    dimension_column = 'é”€å”®å‘˜'

                    # æŒ‰å·®å¼‚ç‡ç»å¯¹å€¼é™åºæ’åºï¼ˆå·®å¼‚æœ€å¤§çš„æ’åœ¨å‰é¢ï¼‰
                    diff_summary = diff_summary.sort_values('æ•°é‡å·®å¼‚ç‡', key=abs, ascending=False)

                    # æ˜¾ç¤ºæ‰€æœ‰æ•°æ®ï¼Œä¸å†é™åˆ¶æ•°é‡
                    top_diff_items = diff_summary

                    # å‡†å¤‡è¯¦ç»†ä¿¡æ¯ç”¨äºæ‚¬åœæ˜¾ç¤º
                    hover_data = []
                    for idx, row in top_diff_items.iterrows():
                        if
                    analysis_dimension == 'äº§å“':
                    # æ‰¾åˆ°è¯¥äº§å“çš„è¯¦ç»†ä¿¡æ¯
                    if selected_region_for_diff == 'å…¨å›½':
                    # æŸ¥æ‰¾è¯¥äº§å“åœ¨æ‰€æœ‰é€‰å®šæœˆä»½çš„æ•°æ®
                        product_details = diff_filtered_monthly[diff_filtered_monthly['äº§å“ä»£ç '] == row['äº§å“ä»£ç ']]
                    product_details = product_details.sort_values('æ‰€å±å¹´æœˆ')

                    # æŒ‰æœˆä»½æ±‡æ€»
                    monthly_info = []
                    for month, month_data in product_details.groupby('æ‰€å±å¹´æœˆ'):
                        actual = month_data['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].sum()
                    forecast = month_data['é¢„è®¡é”€å”®é‡'].sum()
                    diff_rate = (actual - forecast) / actual * 100 if actual > 0 else 0
                    monthly_info.append(
                        f"{month}æœˆ: å®é™… {actual:.0f}ç®±, é¢„æµ‹ {forecast:.0f}ç®±, å·®å¼‚ {diff_rate:.1f}%"
                    )

                    # åˆ†æåŒºåŸŸå’Œé”€å”®å‘˜
                    region_info = []
                    for region, region_data in product_details.groupby('æ‰€å±åŒºåŸŸ'):
                        region_actual = region_data['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].sum()
                    region_forecast = region_data['é¢„è®¡é”€å”®é‡'].sum()
                    region_diff = (
                                          region_actual - region_forecast) / region_actual * 100 if region_actual > 0 else 0

                    # æ‰¾å‡ºè¯¥åŒºåŸŸä¸»è¦é”€å”®å‘˜
                    region_salesperson = diff_filtered_salesperson[
                        (diff_filtered_salesperson['äº§å“ä»£ç '] == row['äº§å“ä»£ç ']) &
                        (diff_filtered_salesperson['æ‰€å±åŒºåŸŸ'] == region)
                        ]

                    if not region_salesperson.empty:
                        top_salesperson = region_salesperson.groupby('é”€å”®å‘˜')['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].sum().idxmax()
                    region_info.append(
                        f"{region}åŒºåŸŸ: å·®å¼‚ {region_diff:.1f}%, ä¸»è¦é”€å”®å‘˜: {top_salesperson}"
                    )

                    # å¤‡è´§å»ºè®®
                    recent_sales = product_details.sort_values('æ‰€å±å¹´æœˆ', ascending=False)
                    recent_trend = 0
                    if len(recent_sales) >= 2:
                        recent_values = recent_sales.groupby('æ‰€å±å¹´æœˆ')['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].sum()
                    if len(recent_values) >= 2:
                        latest_values = recent_values.iloc[:2].values
                    if latest_values[1] > 0:  # é¿å…é™¤ä»¥é›¶
                        recent_trend = (latest_values[0] - latest_values[1]) / latest_values[1] * 100

                    recommendation = "<b>å¤‡è´§å»ºè®®:</b><br>"
                    if recent_trend > 15:
                        recommendation += f"é”€é‡å‘ˆä¸Šå‡è¶‹åŠ¿(+{recent_trend:.1f}%)ï¼Œå»ºè®®å¢åŠ å¤‡è´§{min(50, round(abs(recent_trend)))}%"
                    elif recent_trend < -15:
                        recommendation += f"é”€é‡å‘ˆä¸‹é™è¶‹åŠ¿({recent_trend:.1f}%)ï¼Œå»ºè®®å‡å°‘å¤‡è´§{min(30, abs(round(recent_trend)))}%"
                    else:
                        recommendation += "é”€é‡è¾ƒç¨³å®šï¼Œå»ºè®®ç»´æŒå½“å‰å¤‡è´§æ°´å¹³ï¼Œå…³æ³¨åŒºåŸŸå·®å¼‚"

                    # æ·»åŠ åº“å­˜é£é™©ä¿¡æ¯
                    if not batch_risk_analysis.empty:
                        product_batches = batch_risk_analysis[batch_risk_analysis['äº§å“ä»£ç '] == row['äº§å“ä»£ç ']]
                    if not product_batches.empty:
                        high_risk_batches = product_batches[product_batches['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])]
                    if not high_risk_batches.empty:
                        avg_age = high_risk_batches['åº“é¾„'].mean()
                    total_qty = high_risk_batches['æ‰¹æ¬¡åº“å­˜'].sum()
                    total_value = high_risk_batches['æ‰¹æ¬¡ä»·å€¼'].sum()

                    recommendation += f"<br><b>åº“å­˜é£é™©è­¦ç¤º:</b><br>"
                    recommendation += f"æœ‰{len(high_risk_batches)}ä¸ªé«˜é£é™©æ‰¹æ¬¡ï¼Œå…±{total_qty}ç®±ï¼Œä»·å€¼{total_value:,.2f}å…ƒï¼Œå¹³å‡åº“é¾„{avg_age:.1f}å¤©"
                    recommendation += f"<br>å»ºè®®é‡‡å–ç§¯ææ¸…åº“æªæ–½ï¼Œå‡å°‘åº“å­˜ç§¯å‹"

                    # åˆå¹¶æ‰€æœ‰ä¿¡æ¯
                    hover_info = "<br>".join(monthly_info) + "<br><br>" + "<br>".join(
                        region_info) + "<br><br>" + recommendation

                    else:
                    # åŒºåŸŸå†…è¯¥äº§å“çš„é”€å”®å‘˜å·®å¼‚æƒ…å†µ
                    sales_details = region_filtered_salesperson[
                        region_filtered_salesperson['äº§å“ä»£ç '] == row['äº§å“ä»£ç ']]

                    if not sales_details.empty:
                    # è®¡ç®—é”€å”®å‘˜å·®å¼‚
                        sales_grouped = sales_details.groupby('é”€å”®å‘˜').agg({
                            'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum',
                            'é¢„è®¡é”€å”®é‡': 'sum'
                        })
                    sales_grouped['æ•°é‡å·®å¼‚'] = sales_grouped['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] - sales_grouped['é¢„è®¡é”€å”®é‡']
                    sales_grouped['æ•°é‡å·®å¼‚ç‡'] = sales_grouped.apply(
                        lambda x: (x['æ•°é‡å·®å¼‚'] / x['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] * 100) if x['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] > 0 else 0,
                        axis=1
                    )
                    sales_grouped = sales_grouped.sort_values(by='æ•°é‡å·®å¼‚ç‡', key=abs, ascending=False)

                    # æ„å»ºæ‚¬åœä¿¡æ¯
                    sales_info = []
                    for salesperson, detail in sales_grouped.iterrows():
                        sales_info.append(
                            f"é”€å”®å‘˜ {salesperson}: å·®å¼‚ {detail['æ•°é‡å·®å¼‚ç‡']:.1f}%, "
                            f"å®é™… {detail['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰']:.0f}ç®±, é¢„æµ‹ {detail['é¢„è®¡é”€å”®é‡']:.0f}ç®±"
                        )

                    # å¤‡è´§å»ºè®®
                    recommendation = "<b>å¤‡è´§å»ºè®®:</b><br>"
                    overestimated = sales_grouped[sales_grouped['æ•°é‡å·®å¼‚ç‡'] < -10]
                    underestimated = sales_grouped[sales_grouped['æ•°é‡å·®å¼‚ç‡'] > 10]

                    if len(sales_grouped) > 0:
                        if
                    len(overestimated) > len(underestimated) * 1.5:
                    recommendation += f"æ•´ä½“é¢„æµ‹åé«˜ï¼Œå»ºè®®ä¸‹è°ƒ{min(30, round(abs(sales_grouped['æ•°é‡å·®å¼‚ç‡'].mean())))}%"
                    elif len(underestimated) > len(overestimated) * 1.5:
                    recommendation += f"æ•´ä½“é¢„æµ‹åä½ï¼Œå»ºè®®ä¸Šè°ƒ{min(30, round(abs(sales_grouped['æ•°é‡å·®å¼‚ç‡'].mean())))}%"
                    else:
                    recommendation += "éœ€é’ˆå¯¹å…·ä½“é”€å”®å‘˜è°ƒæ•´"
                    else:
                    recommendation += "æ•°æ®ä¸è¶³ï¼Œæ— æ³•æä¾›å»ºè®®"

                    # æ·»åŠ åº“å­˜é£é™©ä¿¡æ¯
                    if not batch_risk_analysis.empty:
                        product_batches = batch_risk_analysis[batch_risk_analysis['äº§å“ä»£ç '] == row['äº§å“ä»£ç ']]
                    if not product_batches.empty:
                        high_risk_batches = product_batches[product_batches['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])]
                    if not high_risk_batches.empty:
                        avg_age = high_risk_batches['åº“é¾„'].mean()
                    total_qty = high_risk_batches['æ‰¹æ¬¡åº“å­˜'].sum()
                    total_value = high_risk_batches['æ‰¹æ¬¡ä»·å€¼'].sum()

                    recommendation += f"<br><b>åº“å­˜é£é™©è­¦ç¤º:</b><br>"
                    recommendation += f"æœ‰{len(high_risk_batches)}ä¸ªé«˜é£é™©æ‰¹æ¬¡ï¼Œå…±{total_qty}ç®±ï¼Œä»·å€¼{total_value:,.2f}å…ƒï¼Œå¹³å‡åº“é¾„{avg_age:.1f}å¤©"
                    recommendation += f"<br>å»ºè®®é‡‡å–ç§¯ææ¸…åº“æªæ–½ï¼Œå‡å°‘åº“å­˜ç§¯å‹"

                    hover_info = "<br>".join(sales_info) + "<br><br>" + recommendation
                    else:
                    hover_info = "æ— è¯¦ç»†é”€å”®å‘˜æ•°æ®"

                    else:  # é”€å”®å‘˜ç»´åº¦
                    if selected_region_for_diff == 'å…¨å›½':
                    # æŸ¥æ‰¾è¯¥é”€å”®å‘˜çš„æ‰€æœ‰äº§å“å·®å¼‚
                        salesperson_products = diff_data[diff_data['é”€å”®å‘˜'] == row['é”€å”®å‘˜']]

                    # æŒ‰äº§å“åˆ†ç»„å¹¶è®¡ç®—å·®å¼‚
                    product_grouped = salesperson_products.groupby('äº§å“ä»£ç ').agg({
                        'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'sum',
                        'é¢„è®¡é”€å”®é‡': 'sum'
                    })
                    product_grouped['æ•°é‡å·®å¼‚'] = product_grouped['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] - product_grouped['é¢„è®¡é”€å”®é‡']
                    product_grouped['æ•°é‡å·®å¼‚ç‡'] = product_grouped.apply(
                        lambda x: (x['æ•°é‡å·®å¼‚'] / x['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] * 100) if x['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] > 0 else 0,
                        axis=1
                    )
                    # æŒ‰å·®å¼‚ç‡ç»å¯¹å€¼æ’åº
                    product_grouped = product_grouped.sort_values(by='æ•°é‡å·®å¼‚ç‡', key=abs, ascending=False)

                    # æ„å»ºäº§å“è¯¦æƒ…ï¼ˆæœ€å¤šæ˜¾ç¤º10ä¸ªï¼‰
                    products_info = []
                    for product_code, detail in product_grouped.head(10).iterrows():
                        product_name = format_product_code(product_code, product_info, include_name=True)
                    products_info.append(
                        f"{product_name}: å·®å¼‚ç‡ {detail['æ•°é‡å·®å¼‚ç‡']:.1f}%, "
                        f"å®é™… {detail['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰']:.0f}ç®±, é¢„æµ‹ {detail['é¢„è®¡é”€å”®é‡']:.0f}ç®±"
                    )

                    # ç”Ÿæˆå¤‡è´§å»ºè®®
                    recommendation = "<b>å¤‡è´§å»ºè®®:</b><br>"
                    overestimated = product_grouped[product_grouped['æ•°é‡å·®å¼‚ç‡'] < -10]
                    underestimated = product_grouped[product_grouped['æ•°é‡å·®å¼‚ç‡'] > 10]

                    if len(product_grouped) > 0:
                        if
                    len(overestimated) > len(underestimated) * 1.5:
                    recommendation += f"è¯¥é”€å”®å‘˜æ•´ä½“é«˜ä¼°è¶‹åŠ¿ï¼Œå»ºè®®ä¸‹è°ƒé¢„æµ‹10-15%<br>"
                    elif len(underestimated) > len(overestimated) * 1.5:
                    recommendation += f"è¯¥é”€å”®å‘˜æ•´ä½“ä½ä¼°è¶‹åŠ¿ï¼Œå»ºè®®ä¸Šè°ƒé¢„æµ‹10-15%<br>"
                    else:
                    recommendation += "éœ€é’ˆå¯¹å…·ä½“äº§å“è°ƒæ•´:<br>"

                    # æ·»åŠ æœ€éœ€è¦è°ƒæ•´çš„3ä¸ªäº§å“å»ºè®®
                    top_products = 0
                    for product_code, detail in product_grouped.head(5).iterrows():
                        if
                    abs(detail['æ•°é‡å·®å¼‚ç‡']) > 10 and top_products < 3:
                    product_name = format_product_code(product_code, product_info, include_name=True)
                    adjustment = min(50, abs(round(detail['æ•°é‡å·®å¼‚ç‡'])))

                    if detail['æ•°é‡å·®å¼‚ç‡'] > 10:
                        recommendation += f"Â· {product_name}: ä¸Šè°ƒé¢„æµ‹{adjustment}%<br>"
                    else:
                        recommendation += f"Â· {product_name}: ä¸‹è°ƒé¢„æµ‹{adjustment}%<br>"

                    top_products += 1
                    else:
                    recommendation += "æ•°æ®ä¸è¶³ï¼Œæ— æ³•æä¾›å»ºè®®"

                    # æ·»åŠ åº“å­˜é£é™©è´£ä»»ä¿¡æ¯
                    if not batch_risk_analysis.empty:
                        person_responsibility = batch_risk_analysis[batch_risk_analysis['è´£ä»»äºº'] == row['é”€å”®å‘˜']]
                    if not person_responsibility.empty:
                        high_risk_count =
                        person_responsibility[person_responsibility['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])].shape[0]
                    if high_risk_count > 0:
                        total_value =
                        person_responsibility[person_responsibility['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])][
                            'æ‰¹æ¬¡ä»·å€¼'].sum()

                    recommendation += f"<br><b>åº“å­˜è´£ä»»è­¦ç¤º:</b><br>"
                    recommendation += f"è¯¥é”€å”®å‘˜è´Ÿè´£{high_risk_count}ä¸ªé«˜é£é™©æ‰¹æ¬¡ï¼Œä»·å€¼{total_value:,.2f}å…ƒ"
                    recommendation += f"<br>å»ºè®®æé«˜é¢„æµ‹å‡†ç¡®æ€§ï¼Œå‡å°‘æœªæ¥åº“å­˜ç§¯å‹"

                    hover_info = "<br>".join(products_info) + "<br><br>" + recommendation

                    else:
                    # åŒºåŸŸå†…è¯¥é”€å”®å‘˜çš„äº§å“å·®å¼‚æƒ…å†µ
                    product_details = diff_data[diff_data['é”€å”®å‘˜'] == row['é”€å”®å‘˜']]
                    if not product_details.empty:
                    # è®¡ç®—äº§å“å·®å¼‚
                        product_details['æ•°é‡å·®å¼‚'] = product_details['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] - product_details['é¢„è®¡é”€å”®é‡']
                    product_details['æ•°é‡å·®å¼‚ç‡'] = product_details.apply(
                        lambda x: (x['æ•°é‡å·®å¼‚'] / x['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] * 100) if x['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] > 0 else 0,
                        axis=1
                    )
                    product_details = product_details.sort_values(by='æ•°é‡å·®å¼‚ç‡', key=abs, ascending=False)

                    # æ„å»ºæ‚¬åœä¿¡æ¯ï¼ˆæœ€å¤š10ä¸ªäº§å“ï¼‰
                    products_info = []
                    for _, detail in product_details.head(10).iterrows():
                        product_name = format_product_code(detail['äº§å“ä»£ç '], product_info, include_name=True)
                    products_info.append(
                        f"{product_name}: å·®å¼‚ç‡ {detail['æ•°é‡å·®å¼‚ç‡']:.1f}%, "
                        f"å®é™… {detail['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰']:.0f}ç®±, é¢„æµ‹ {detail['é¢„è®¡é”€å”®é‡']:.0f}ç®±"
                    )

                    # å¤‡è´§å»ºè®®
                    recommendation = "<b>å¤‡è´§å»ºè®®:</b><br>"
                    overestimated = product_details[product_details['æ•°é‡å·®å¼‚ç‡'] < -10]
                    underestimated = product_details[product_details['æ•°é‡å·®å¼‚ç‡'] > 10]

                    if len(overestimated) > len(underestimated) * 1.5:
                        recommendation += f"è¯¥é”€å”®å‘˜åœ¨{selected_region_for_diff}åŒºåŸŸæ•´ä½“é«˜ä¼°ï¼Œå»ºè®®ä¸‹è°ƒé¢„æµ‹{min(30, round(abs(product_details['æ•°é‡å·®å¼‚ç‡'].mean())))}%"
                    elif len(underestimated) > len(overestimated) * 1.5:
                        recommendation += f"è¯¥é”€å”®å‘˜åœ¨{selected_region_for_diff}åŒºåŸŸæ•´ä½“ä½ä¼°ï¼Œå»ºè®®ä¸Šè°ƒé¢„æµ‹{min(30, round(abs(product_details['æ•°é‡å·®å¼‚ç‡'].mean())))}%"
                    else:
                        recommendation += "éœ€é’ˆå¯¹å…·ä½“äº§å“è°ƒæ•´:<br>"
                    # æ·»åŠ å‰3ä¸ªå·®å¼‚æœ€å¤§äº§å“çš„å»ºè®®
                    for idx, detail in enumerate(product_details.head(3).itertuples()):
                        if
                    hasattr(detail, 'æ•°é‡å·®å¼‚ç‡') and abs(detail.æ•°é‡å·®å¼‚ç‡) > 10:
                    product_name = format_product_code(detail.äº§å“ä»£ç , product_info, include_name=True)
                    adjustment = min(50, abs(round(detail.æ•°é‡å·®å¼‚ç‡)))
                    if detail.æ•°é‡å·®å¼‚ç‡ > 10:
                        recommendation += f"Â· {product_name}: ä¸Šè°ƒé¢„æµ‹{adjustment}%<br>"
                    else:
                        recommendation += f"Â· {product_name}: ä¸‹è°ƒé¢„æµ‹{adjustment}%<br>"

                    # æ·»åŠ åº“å­˜é£é™©è´£ä»»ä¿¡æ¯
                    if not batch_risk_analysis.empty:
                        person_responsibility = batch_risk_analysis[
                            (batch_risk_analysis['è´£ä»»äºº'] == row['é”€å”®å‘˜']) &
                            (batch_risk_analysis['è´£ä»»åŒºåŸŸ'] == selected_region_for_diff)
                            ]
                    if not person_responsibility.empty:
                        high_risk_count =
                        person_responsibility[person_responsibility['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])].shape[0]
                    if high_risk_count > 0:
                        total_value =
                        person_responsibility[person_responsibility['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])][
                            'æ‰¹æ¬¡ä»·å€¼'].sum()

                    recommendation += f"<br><b>åº“å­˜è´£ä»»è­¦ç¤º:</b><br>"
                    recommendation += f"è¯¥é”€å”®å‘˜åœ¨æ­¤åŒºåŸŸè´Ÿè´£{high_risk_count}ä¸ªé«˜é£é™©æ‰¹æ¬¡ï¼Œä»·å€¼{total_value:,.2f}å…ƒ"
                    recommendation += f"<br>å»ºè®®æé«˜é¢„æµ‹å‡†ç¡®æ€§ï¼Œå‡å°‘æœªæ¥åº“å­˜ç§¯å‹"

                    hover_info = "<br>".join(products_info) + "<br><br>" + recommendation
                    else:
                    hover_info = "æ— è¯¦ç»†äº§å“æ•°æ®"

                    hover_data.append(hover_info)

                    # åˆ›å»ºæ°´å¹³å †å æŸ±çŠ¶å›¾
                    fig_diff = go.Figure()

                    # æ·»åŠ å®é™…é”€å”®é‡æŸ±
                    fig_diff.add_trace(go.Bar(
                        y=top_diff_items[dimension_column],
                        x=top_diff_items['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'],
                        name='å®é™…é”€å”®é‡',
                        marker_color='royalblue',
                        orientation='h',
                        customdata=hover_data,
                        hovertemplate='<b>%{y}</b><br>å®é™…é”€å”®é‡: %{x:,.0f}ç®±<br><br><b>è¯¦ç»†å·®å¼‚æ¥æº:</b><br>%{customdata}<extra></extra>'
                    ))

                    # æ·»åŠ é¢„æµ‹é”€å”®é‡æŸ±
                    fig_diff.add_trace(go.Bar(
                        y=top_diff_items[dimension_column],
                        x=top_diff_items['é¢„è®¡é”€å”®é‡'],
                        name='é¢„æµ‹é”€å”®é‡',
                        marker_color='lightcoral',
                        orientation='h',
                        hovertemplate='<b>%{y}</b><br>é¢„æµ‹é”€å”®é‡: %{x:,.0f}ç®±<extra></extra>'
                    ))

                    # æ·»åŠ å·®å¼‚ç‡ç‚¹
                    fig_diff.add_trace(go.Scatter(
                        y=top_diff_items[dimension_column],
                        x=[top_diff_items['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].max() * 1.05] * len(top_diff_items),  # æ”¾åœ¨å³ä¾§
                        mode='markers+text',
                        marker=dict(
                            color=top_diff_items['æ•°é‡å·®å¼‚ç‡'].apply(lambda x: 'green' if x > 0 else 'red'),
                            size=10
                        ),
                        text=[f"{x:.1f}%" for x in top_diff_items['æ•°é‡å·®å¼‚ç‡']],
                        textposition='middle right',
                        name='å·®å¼‚ç‡ (%)',
                        hovertemplate='<b>%{y}</b><br>å·®å¼‚ç‡: %{text}<extra></extra>'
                    ))

                    # æ›´æ–°å¸ƒå±€
                    title = f"{selected_region_for_diff}é¢„æµ‹ä¸å®é™…é”€å”®å¯¹æ¯” (æŒ‰{analysis_dimension}ç»´åº¦ï¼Œå·®å¼‚ç‡é™åº)"
                    fig_diff.update_layout(
                        title=title,
                        xaxis=dict(
                            title="é”€å”®é‡ (ç®±)",
                            tickformat=",",
                            showexponent="none"
                        ),
                        yaxis=dict(title=analysis_dimension),
                        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
                        barmode='group',
                        plot_bgcolor='white',
                        hoverlabel=dict(
                            bgcolor="white",
                            font_size=12
                        ),
                        height=max(600, len(top_diff_items) * 25)  # åŠ¨æ€è°ƒæ•´é«˜åº¦ä»¥é€‚åº”æ•°æ®é‡
                    )

                    st.plotly_chart(fig_diff, use_container_width=True)

                    # é¢„æµ‹åå·®ä¸åº“å­˜é£é™©å…³ç³»åˆ†æ
                    st.markdown('<div class="sub-header">ğŸ“Š é¢„æµ‹åå·®ä¸åº“å­˜é£é™©å…³ç³»åˆ†æ</div>', unsafe_allow_html=True)

                    # åˆ›å»ºé¢„æµ‹åå·®åˆ†æå›¾
                    bias_chart = create_forecast_bias_chart(batch_risk_analysis, actual_data, forecast_data)
                    if bias_chart:
                        st.plotly_chart(bias_chart, use_container_width=True)
                    else:
                        st.info("æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®æ¥ç”Ÿæˆé¢„æµ‹åå·®åˆ†æå›¾")

                    # é¢„æµ‹åå·®ä¸åº“å­˜é£é™©å…³ç³»è§£è¯»
                    bias_explanation = """
        <b>å›¾è¡¨è§£è¯»ï¼š</b> æ­¤å›¾åˆ†æäº†é¢„æµ‹å‡†ç¡®æ€§å¯¹åº“å­˜ç§¯å‹çš„å½±å“ã€‚çº¢è‰²è¡¨ç¤ºé¢„æµ‹è¿‡é«˜(å®é™…é”€é‡ä½äºé¢„æµ‹)ï¼Œå¯¼è‡´ä¸å¿…è¦çš„åº“å­˜ç§¯å‹ï¼›è“è‰²è¡¨ç¤ºé¢„æµ‹è¿‡ä½(å®é™…é”€é‡é«˜äºé¢„æµ‹)ï¼Œå¯èƒ½å¯¼è‡´ç¼ºè´§å’Œé”€å”®æœºä¼šæŸå¤±ã€‚å›¾è¡¨æŒ‰åå·®ç»å¯¹å€¼å¤§å°æ’åºï¼Œå±•ç¤ºåå·®æœ€æ˜¾è‘—çš„æ‰¹æ¬¡ã€‚
        """

                    # æ·»åŠ å…·ä½“åˆ†æ
                    if not batch_risk_analysis.empty:
                        high_risk_batches = batch_risk_analysis[
                            batch_risk_analysis['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])]
                    if not high_risk_batches.empty:
                        high_pred_count = sum(
                            1 for bias in high_risk_batches['æ—¥å‡å‡ºè´§'] / high_risk_batches['æ‰¹æ¬¡åº“å­˜'] * 100 if
                            bias < 30)
                    bias_explanation += f"<br><b>å…³é”®å‘ç°ï¼š</b> {high_pred_count}ä¸ªé«˜é£é™©æ‰¹æ¬¡çš„æ—¥å‡å‡ºè´§é‡ä¸åˆ°æ‰¹æ¬¡åº“å­˜çš„30%ï¼Œè¡¨æ˜é¢„æµ‹è¿‡é«˜å¯¼è‡´åº“å­˜ç§¯å‹ã€‚"
                    bias_explanation += f"é¢„æµ‹å‡†ç¡®æ€§ä¸åº“å­˜å¥åº·åº¦å¯†åˆ‡ç›¸å…³ï¼Œæé«˜é¢„æµ‹å‡†ç¡®æ€§æ˜¯å‡å°‘åº“å­˜ç§¯å‹çš„å…³é”®ã€‚"

                    # é‡ç‚¹äººå‘˜åˆ†æ
                    top_persons = high_risk_batches['è´£ä»»äºº'].value_counts().head(3)
                    if not top_persons.empty:
                        persons_list = [f"{person}({count}ä¸ªæ‰¹æ¬¡)" for person, count in top_persons.items()]
                    bias_explanation += f"<br><b>é‡ç‚¹å…³æ³¨äººå‘˜ï¼š</b> {', '.join(persons_list)}çš„é¢„æµ‹å‡†ç¡®æ€§é—®é¢˜æ˜¯åº“å­˜ç§¯å‹çš„ä¸»è¦æ¥æºï¼Œåº”ä¼˜å…ˆæé«˜è¿™äº›äººå‘˜çš„é¢„æµ‹èƒ½åŠ›ã€‚"

                    add_chart_explanation(bias_explanation)

                    # åŠ¨æ€è§£è¯»
                    diff_explanation = f"""
        <b>å›¾è¡¨è§£è¯»ï¼š</b> æ­¤å›¾å±•ç¤º{selected_region_for_diff}çš„{analysis_dimension}ç»´åº¦é¢„æµ‹å·®å¼‚æƒ…å†µï¼Œè“è‰²ä»£è¡¨å®é™…é”€å”®é‡ï¼Œçº¢è‰²ä»£è¡¨é¢„æµ‹é”€å”®é‡ï¼Œç‚¹çš„é¢œè‰²è¡¨ç¤ºå·®å¼‚ç‡(ç»¿è‰²ä¸ºä½ä¼°ï¼Œçº¢è‰²ä¸ºé«˜ä¼°)ã€‚
        æ‚¬åœåœ¨"å®é™…é”€å”®é‡"æ¡å½¢ä¸Šï¼Œå¯ä»¥æŸ¥çœ‹è¯¦ç»†çš„å·®å¼‚æ¥æºï¼ŒåŒ…æ‹¬åŒºåŸŸã€é”€å”®å‘˜æˆ–äº§å“çš„å…·ä½“ä¿¡æ¯ã€‚è¿™æœ‰åŠ©äºç²¾ç¡®å®šä½é¢„æµ‹ä¸å‡†ç¡®çš„å…·ä½“åŸå› ã€‚
        """

                    # æ·»åŠ æ•°æ®é’»å–åˆ†æå»ºè®®
                    diff_explanation += f"<br><b>å·®å¼‚åˆ†æå»ºè®®ï¼š</b> "

                    if analysis_dimension == 'äº§å“':
                        diff_explanation += "å¯¹äºå·®å¼‚è¾ƒå¤§çš„äº§å“ï¼Œå»ºè®®åˆ†æäº§å“åœ¨ä¸åŒåŒºåŸŸå’Œé”€å”®å‘˜é—´çš„è¡¨ç°å·®å¼‚ï¼Œè¯†åˆ«ç‰¹å®šäº§å“é¢„æµ‹å‡†ç¡®æ€§çš„å½±å“å› ç´ ï¼›"
                    if selected_region_for_diff == 'å…¨å›½':
                        diff_explanation += "å¯è¿›ä¸€æ­¥é€‰æ‹©ç‰¹å®šåŒºåŸŸï¼Œæ·±å…¥åˆ†æè¯¥åŒºåŸŸå†…äº§å“çš„é”€å”®å‘˜å±‚é¢å·®å¼‚ã€‚"
                    else:
                        diff_explanation += "å¯åˆ‡æ¢åˆ°é”€å”®å‘˜ç»´åº¦ï¼Œåˆ†ææœ¬åŒºåŸŸå†…é”€å”®å‘˜å¯¹äº§å“é¢„æµ‹çš„å‡†ç¡®ç¨‹åº¦ã€‚"
                    else:  # é”€å”®å‘˜ç»´åº¦
                    diff_explanation += "å¯¹äºå·®å¼‚è¾ƒå¤§çš„é”€å”®å‘˜ï¼Œå»ºè®®åˆ†æå…¶é”€å”®çš„äº§å“ç»„åˆå’ŒåŒºåŸŸåˆ†å¸ƒï¼Œè¯†åˆ«ç‰¹å®šé”€å”®å‘˜é¢„æµ‹å‡†ç¡®æ€§çš„å½±å“å› ç´ ï¼›"
                    if selected_region_for_diff == 'å…¨å›½':
                        diff_explanation += "å¯è¿›ä¸€æ­¥é€‰æ‹©ç‰¹å®šåŒºåŸŸï¼Œæ·±å…¥åˆ†æè¯¥åŒºåŸŸå†…é”€å”®å‘˜çš„äº§å“å±‚é¢å·®å¼‚ã€‚"
                    else:
                        diff_explanation += "å¯åˆ‡æ¢åˆ°äº§å“ç»´åº¦ï¼Œåˆ†ææœ¬åŒºåŸŸå†…äº§å“çš„é”€å”®å‘˜å±‚é¢å·®å¼‚ã€‚"

                    add_chart_explanation(diff_explanation)

                    with tabs[2]:  # äº§å“è¶‹åŠ¿æ ‡ç­¾é¡µ
                    # åœ¨æ ‡ç­¾é¡µå†…æ·»åŠ ç­›é€‰å™¨
                        st.markdown("### ğŸ“Š åˆ†æç­›é€‰")
                    with st.expander("ç­›é€‰æ¡ä»¶", expanded=True):
                        col1, col2 = st.columns(2)
                    with col1:
                        trend_selected_months = st.multiselect(
                            "é€‰æ‹©åˆ†ææœˆä»½",
                            options=all_months,
                            default=valid_last_three_months if valid_last_three_months else (
                                [all_months[-1]] if all_months else []),
                            key="trend_months"
                        )

                    with col2:
                        trend_selected_regions = st.multiselect(
                            "é€‰æ‹©åŒºåŸŸ",
                            options=all_regions,
                            default=all_regions,
                            key="trend_regions"
                        )

                    # ç­›é€‰æ•°æ®
                    trend_filtered_monthly = filter_data(processed_data['merged_monthly'], trend_selected_months,
                                                         trend_selected_regions)
                    trend_filtered_salesperson = filter_data(processed_data['merged_by_salesperson'],
                                                             trend_selected_months,
                                                             trend_selected_regions)

                    # æ£€æŸ¥ç­›é€‰æ¡ä»¶æ˜¯å¦æœ‰æ•ˆ
                    if not trend_selected_months or not trend_selected_regions:
                        st.warning("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæœˆä»½å’Œä¸€ä¸ªåŒºåŸŸè¿›è¡Œåˆ†æã€‚")
                    else:
                        st.markdown("### äº§å“é”€å”®è¶‹åŠ¿åˆ†æ")

                    # åŠ¨æ€è®¡ç®—æ‰€é€‰åŒºåŸŸçš„äº§å“å¢é•¿ç‡ - ç§»é™¤ç¼“å­˜è£…é¥°å™¨ç¡®ä¿å“åº”ç­›é€‰
                    product_growth = calculate_product_growth(actual_monthly=actual_data,
                                                              regions=trend_selected_regions,
                                                              months=trend_selected_months)

                    if 'latest_growth' in product_growth and not product_growth['latest_growth'].empty:
                    # ç®€è¦ç»Ÿè®¡
                        latest_growth = product_growth['latest_growth']
                    growth_stats = {
                        'å¼ºåŠ²å¢é•¿': len(latest_growth[latest_growth['è¶‹åŠ¿'] == 'å¼ºåŠ²å¢é•¿']),
                        'å¢é•¿': len(latest_growth[latest_growth['è¶‹åŠ¿'] == 'å¢é•¿']),
                        'è½»å¾®ä¸‹é™': len(latest_growth[latest_growth['è¶‹åŠ¿'] == 'è½»å¾®ä¸‹é™']),
                        'æ˜¾è‘—ä¸‹é™': len(latest_growth[latest_growth['è¶‹åŠ¿'] == 'æ˜¾è‘—ä¸‹é™'])
                    }

                    # ç»Ÿè®¡æŒ‡æ ‡å¡
                    col1, col2, col3, col4 = st.columns(4)

                    with col1:
                        st.markdown(f"""
                <div class="metric-card" style="border-left: 0.5rem solid #2E8B57;">
                    <p class="card-header">å¼ºåŠ²å¢é•¿äº§å“</p>
                    <p class="card-value">{growth_stats['å¼ºåŠ²å¢é•¿']}</p>
                    <p class="card-text">å¢é•¿ç‡ > 10%</p>
                </div>
                """, unsafe_allow_html=True)

                    with col2:
                        st.markdown(f"""
                <div class="metric-card" style="border-left: 0.5rem solid #4CAF50;">
                    <p class="card-header">å¢é•¿äº§å“</p>
                    <p class="card-value">{growth_stats['å¢é•¿']}</p>
                    <p class="card-text">å¢é•¿ç‡ 0% ~ 10%</p>
                </div>
                """, unsafe_allow_html=True)

                    with col3:
                        st.markdown(f"""
                <div class="metric-card" style="border-left: 0.5rem solid #FFA500;">
                    <p class="card-header">è½»å¾®ä¸‹é™äº§å“</p>
                    <p class="card-value">{growth_stats['è½»å¾®ä¸‹é™']}</p>
                    <p class="card-text">å¢é•¿ç‡ -10% ~ 0%</p>
                </div>
                """, unsafe_allow_html=True)

                    with col4:
                        st.markdown(f"""
                <div class="metric-card" style="border-left: 0.5rem solid #F44336;">
                    <p class="card-header">æ˜¾è‘—ä¸‹é™äº§å“</p>
                    <p class="card-value">{growth_stats['æ˜¾è‘—ä¸‹é™']}</p>
                    <p class="card-text">å¢é•¿ç‡ < -10%</p>
                </div>
                """, unsafe_allow_html=True)

                    # æ˜¾ç¤ºå¤‡è´§å»ºè®®è¡¨æ ¼ - ä½¿ç”¨ä¿®æ”¹åçš„å‡½æ•°é¿å…ä¹±ç 
                    display_recommendations_table(latest_growth, product_info)

                    # æ¸…åº“é¢„æµ‹åˆ†æ
                    st.markdown('<div class="sub-header">ğŸ“Š äº§å“æ¸…åº“é¢„æµ‹åˆ†æ</div>', unsafe_allow_html=True)

                    # åˆ›å»ºæ¸…åº“é¢„æµ‹å›¾
                    clearance_chart = create_clearance_forecast_chart(batch_risk_analysis)
                    if clearance_chart:
                        st.plotly_chart(clearance_chart, use_container_width=True)
                    else:
                        st.info("æ²¡æœ‰é«˜é£é™©æ‰¹æ¬¡æ•°æ®æ¥ç”Ÿæˆæ¸…åº“é¢„æµ‹å›¾")

                    # æ¸…åº“é¢„æµ‹è§£è¯»
                    clearance_explanation = """
            <b>å›¾è¡¨è§£è¯»ï¼š</b> æ­¤å›¾å¯¹æ¯”å±•ç¤ºäº†é«˜é£é™©æ‰¹æ¬¡çš„é¢„è®¡æ¸…åº“å¤©æ•°(çº¢è‰²)å’Œå½“å‰åº“é¾„(è“è‰²)ã€‚é¢„è®¡æ¸…åº“å¤©æ•°åŸºäºå½“å‰æ—¥å‡é”€é‡è®¡ç®—ï¼Œè¡¨ç¤ºåœ¨å½“å‰é”€å”®é€Ÿåº¦ä¸‹æ¶ˆåŒ–å®Œè¯¥æ‰¹æ¬¡åº“å­˜æ‰€éœ€çš„æ—¶é—´ã€‚å‚ç›´çº¢çº¿è¡¨ç¤º90å¤©é«˜é£é™©é˜ˆå€¼ã€‚
            """

                    # æ·»åŠ å…·ä½“åˆ†æ
                    if not batch_risk_analysis.empty:
                        high_risk_batches = batch_risk_analysis[
                            batch_risk_analysis['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])]
                    if not high_risk_batches.empty:
                        avg_clearance = high_risk_batches['é¢„è®¡æ¸…åº“å¤©æ•°'].replace(float('inf'), 365).mean()
                    infinite_count = sum(1 for x in high_risk_batches['é¢„è®¡æ¸…åº“å¤©æ•°'] if x == float('inf'))

                    clearance_explanation += f"<br><b>å…³é”®å‘ç°ï¼š</b> åˆ†ææ˜¾ç¤ºé«˜é£é™©æ‰¹æ¬¡å¹³å‡æ¸…åº“æ—¶é—´çº¦{avg_clearance:.1f}å¤©ï¼Œè¿œè¶…90å¤©é£é™©é˜ˆå€¼ã€‚"
                    if infinite_count > 0:
                        clearance_explanation += f"æœ‰{infinite_count}ä¸ªæ‰¹æ¬¡å› æ— é”€é‡å¯¼è‡´æ¸…åº“å¤©æ•°ä¸ºæ— ç©·å¤§ï¼Œè¿™ç±»æ‰¹æ¬¡éœ€è¦ç‰¹åˆ«å¹²é¢„æªæ–½ã€‚"

                    clearance_explanation += f"<br>åº“å­˜å¤„ç†ä¼˜å…ˆçº§åº”æ˜¯ï¼šæ— é”€é‡æ‰¹æ¬¡ > æ¸…åº“å¤©æ•°è¶…è¿‡180å¤©æ‰¹æ¬¡ > å…¶ä½™é«˜é£é™©æ‰¹æ¬¡ã€‚å»ºè®®é‡‡å–ä¿ƒé”€ã€è½¬ä»“ã€è°ƒé…æˆ–ç‰¹ä»·å¤„ç†ç­‰æªæ–½åŠ é€Ÿåº“å­˜å‘¨è½¬ã€‚"

                    add_chart_explanation(clearance_explanation)
                    else:
                    st.warning("æ²¡æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®æ¥è®¡ç®—äº§å“å¢é•¿ç‡ã€‚éœ€è¦è‡³å°‘ä¸¤å¹´çš„é”€å”®æ•°æ®æ‰èƒ½è®¡ç®—åŒæ¯”å¢é•¿ã€‚")

                    with tabs[3]:  # é‡ç‚¹SKUåˆ†ææ ‡ç­¾é¡µ
                    # æ·»åŠ ç­›é€‰å™¨ - å¢åŠ æœˆä»½ç­›é€‰
                        st.markdown("### ğŸ“Š åˆ†æç­›é€‰")
                    with st.expander("ç­›é€‰æ¡ä»¶", expanded=True):
                        col1, col2 = st.columns(2)

                    # è·å–å½“å‰ç³»ç»Ÿæœˆä»½ä½œä¸ºé»˜è®¤å€¼
                    current_month = datetime.now().strftime('%Y-%m')
                    current_month_in_data = False

                    # æ£€æŸ¥å½“å‰æœˆä»½æ˜¯å¦åœ¨æ•°æ®é›†ä¸­
                    if current_month in all_months:
                        current_month_in_data = True
                    default_month = [current_month]
                    else:
                    # å¦‚æœå½“å‰æœˆä»½ä¸åœ¨æ•°æ®ä¸­ï¼Œä½¿ç”¨æ•°æ®ä¸­çš„æœ€æ–°æœˆä»½
                    default_month = [all_months[-1]] if all_months else []

                    with col1:
                        sku_selected_months = st.multiselect(
                            "é€‰æ‹©åˆ†ææœˆä»½",
                            options=all_months,
                            default=default_month,
                            key="sku_months"
                        )
                    with col2:
                        sku_selected_regions = st.multiselect(
                            "é€‰æ‹©åŒºåŸŸ",
                            options=all_regions,
                            default=all_regions,
                            key="sku_regions"
                        )

                    # ç­›é€‰æ•°æ®
                    sku_filtered_monthly = filter_data(processed_data['merged_monthly'], sku_selected_months,
                                                       sku_selected_regions)
                    sku_filtered_salesperson = filter_data(processed_data['merged_by_salesperson'], sku_selected_months,
                                                           sku_selected_regions)

                    # é‡æ–°è®¡ç®—é‡ç‚¹SKUï¼Œè€Œéä½¿ç”¨é¢„è®¡ç®—çš„ç»“æœ
                    filtered_national_top_skus = calculate_top_skus(sku_filtered_monthly, by_region=False)
                    filtered_regional_top_skus = calculate_top_skus(sku_filtered_monthly, by_region=True)

                    # ä½¿ç”¨æ–°è®¡ç®—çš„ç»“æœ
                    national_top_skus = filtered_national_top_skus
                    regional_top_skus = filtered_regional_top_skus

                    # æ£€æŸ¥ç­›é€‰æ¡ä»¶æ˜¯å¦æœ‰æ•ˆ
                    if not sku_selected_months or not sku_selected_regions:
                        st.warning("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæœˆä»½å’Œä¸€ä¸ªåŒºåŸŸè¿›è¡Œåˆ†æã€‚")
                    else:
                        st.markdown("### é”€å”®é‡å æ¯”80%é‡ç‚¹SKUåˆ†æ")

                    # é»˜è®¤ä½¿ç”¨å…¨å›½æ•°æ®ï¼Œä¸å†æä¾›é€‰æ‹©å™¨
                    selected_scope = "å…¨å›½"

                    # æ ¹æ®ç”¨æˆ·é€‰æ‹©æ˜¾ç¤ºç›¸åº”æ•°æ®
                    if selected_scope == "å…¨å›½":
                    # æ˜¾ç¤ºå…¨å›½é‡ç‚¹SKUåˆ†æ
                        if
                    not national_top_skus.empty:
                    # æ ¼å¼åŒ–å‡†ç¡®ç‡ä¸ºç™¾åˆ†æ¯”
                    national_top_skus['æ•°é‡å‡†ç¡®ç‡'] = national_top_skus['æ•°é‡å‡†ç¡®ç‡'] * 100

                    # æ·»åŠ äº§å“åç§°
                    national_top_skus['äº§å“åç§°'] = national_top_skus['äº§å“ä»£ç '].apply(
                        lambda x: product_names_map.get(x, '') if product_names_map else ''
                    )
                    national_top_skus['äº§å“æ˜¾ç¤º'] = national_top_skus.apply(
                        lambda row: format_product_code(row['äº§å“ä»£ç '], product_info, include_name=True),
                        axis=1
                    )

                    # åˆå¹¶å¢é•¿ç‡æ•°æ®å’Œå¤‡è´§å»ºè®®
                try:
                    # ä½¿ç”¨å½“å‰é€‰æ‹©çš„åŒºåŸŸå’Œæœˆä»½è®¡ç®—å¢é•¿ç‡
                    product_growth_data = calculate_product_growth(
                        actual_monthly=actual_data,
                        regions=sku_selected_regions,
                        months=sku_selected_months
                    ).get('latest_growth', pd.DataFrame())

                    if not product_growth_data.empty:
                        national_top_skus = pd.merge(
                            national_top_skus,
                            product_growth_data[
                                ['äº§å“ä»£ç ', 'é”€é‡å¢é•¿ç‡', 'è¶‹åŠ¿', 'å¤‡è´§å»ºè®®', 'è°ƒæ•´æ¯”ä¾‹', 'å»ºè®®æ ·å¼ç±»', 'å»ºè®®å›¾æ ‡']],
                            on='äº§å“ä»£ç ',
                            how='left'
                        )
                except Exception as e:
                    print(f"åˆå¹¶å¤‡è´§å»ºè®®æ•°æ®æ—¶å‡ºé”™: {str(e)}")

                # åˆ›å»ºæ°´å¹³æ¡å½¢å›¾
                fig_top_skus = go.Figure()

                # æ·»åŠ é”€å”®é‡æ¡
                fig_top_skus.add_trace(go.Bar(
                    y=national_top_skus['äº§å“æ˜¾ç¤º'],
                    x=national_top_skus['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'],
                    name='é”€å”®é‡',
                    marker=dict(
                        color=national_top_skus['æ•°é‡å‡†ç¡®ç‡'],
                        colorscale='RdYlGn',
                        cmin=0,
                        cmax=100,
                        colorbar=dict(
                            title='å‡†ç¡®ç‡ (%)',
                            x=1.05
                        )
                    ),
                    orientation='h'
                ))

                # æ·»åŠ å‡†ç¡®ç‡å’Œå¤‡è´§å»ºè®®æ ‡è®°
                for i, row in national_top_skus.iterrows():
                    accuracy_text = f"{row['æ•°é‡å‡†ç¡®ç‡']:.0f}%"

                    # å¦‚æœæœ‰å¤‡è´§å»ºè®®ï¼Œæ·»åŠ åˆ°æ–‡æœ¬
                    if 'backup_suggestion' in row and pd.notna(row['å¤‡è´§å»ºè®®']):
                        accuracy_text += f" {row['å»ºè®®å›¾æ ‡']}"

                    fig_top_skus.add_annotation(
                        y=row['äº§å“æ˜¾ç¤º'],
                        x=row['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] * 1.05,
                        text=accuracy_text,
                        showarrow=False,
                        font=dict(
                            color="black" if row['æ•°é‡å‡†ç¡®ç‡'] > 70 else "red",
                            size=10
                        )
                    )

                # æ›´æ–°å¸ƒå±€
                fig_top_skus.update_layout(
                    title=f"é‡ç‚¹SKUåŠå…¶å‡†ç¡®ç‡",
                    xaxis=dict(
                        title="é”€å”®é‡ (ç®±)",
                        tickformat=",",
                        showexponent="none"
                    ),
                    yaxis=dict(title="äº§å“"),
                    showlegend=False,
                    plot_bgcolor='white',
                    height=max(700, len(national_top_skus) * 40),  # å¢åŠ é«˜åº¦
                    margin=dict(l=20, r=40, t=60, b=30)  # å¢åŠ è¾¹è·
                )

                # æ·»åŠ æ‚¬åœæç¤º
                hover_template = '<b>%{y}</b><br>é”€å”®é‡: %{x:,.0f}ç®±<br>å‡†ç¡®ç‡: %{marker.color:.1f}%<br>ç´¯è®¡å æ¯”: %{customdata[0]:.2f}%'

                # å¦‚æœæœ‰å¤‡è´§å»ºè®®æ•°æ®ï¼Œæ·»åŠ åˆ°æ‚¬åœæç¤º
                if 'å¤‡è´§å»ºè®®' in national_top_skus.columns:
                    hover_template += '<br>å»ºè®®: %{customdata[1]}'
                    customdata = national_top_skus[['ç´¯è®¡å æ¯”', 'å¤‡è´§å»ºè®®']].fillna('æœªçŸ¥').values
                else:
                    customdata = national_top_skus[['ç´¯è®¡å æ¯”']].values

                fig_top_skus.update_traces(
                    hovertemplate=hover_template + '<extra></extra>',
                    customdata=customdata,
                    selector=dict(type='bar')
                )

                # çªå‡ºæ˜¾ç¤ºå‡†ç¡®ç‡ä½çš„äº§å“
                low_accuracy_products = national_top_skus[national_top_skus['æ•°é‡å‡†ç¡®ç‡'] < 70]
                if not low_accuracy_products.empty:
                    for product in low_accuracy_products['äº§å“æ˜¾ç¤º']:
                        fig_top_skus.add_shape(
                            type="rect",
                            y0=list(national_top_skus['äº§å“æ˜¾ç¤º']).index(product) - 0.45,
                            y1=list(national_top_skus['äº§å“æ˜¾ç¤º']).index(product) + 0.45,
                            x0=0,
                            x1=national_top_skus['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].max() * 1.05,
                            line=dict(color="#F44336", width=2),
                            fillcolor="rgba(244, 67, 54, 0.1)"
                        )

                # ä¿ç•™è¿™ä¸ªst.plotly_chartè°ƒç”¨ï¼Œè¿™æ˜¯æ·»åŠ ä½å‡†ç¡®ç‡äº§å“æ ‡è®°åçš„æ˜¾ç¤º
                st.plotly_chart(fig_top_skus, use_container_width=True)

                # ç”ŸæˆåŠ¨æ€è§£è¯»
                explanation = """
                <b>å›¾è¡¨è§£è¯»ï¼š</b> æ­¤å›¾å±•ç¤ºäº†é”€å”®é‡ç´¯è®¡å æ¯”è¾¾åˆ°80%çš„é‡ç‚¹SKUåŠå…¶å‡†ç¡®ç‡ï¼Œæ¡å½¢é•¿åº¦è¡¨ç¤ºé”€å”®é‡ï¼Œé¢œè‰²æ·±æµ…è¡¨ç¤ºå‡†ç¡®ç‡(æ·±ç»¿è‰²è¡¨ç¤ºé«˜å‡†ç¡®ç‡ï¼Œçº¢è‰²è¡¨ç¤ºä½å‡†ç¡®ç‡)ã€‚
                æ¡†çº¿æ ‡è®°çš„äº§å“å‡†ç¡®ç‡ä½äº70%ï¼Œéœ€è¦ç‰¹åˆ«å…³æ³¨ã€‚
                """

                # æ·»åŠ å…·ä½“äº§å“å»ºè®®
                if not national_top_skus.empty:
                    top_product = national_top_skus.iloc[0]
                    lowest_accuracy_product = national_top_skus.loc[national_top_skus['æ•°é‡å‡†ç¡®ç‡'].idxmin()]

                    explanation += f"<br><b>äº§å“åˆ†æï¼š</b> "
                    explanation += f"{top_product['äº§å“æ˜¾ç¤º']}æ˜¯é”€å”®é‡æœ€é«˜çš„äº§å“({format_number(top_product['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'])})ï¼Œç´¯è®¡å æ¯”{top_product['ç´¯è®¡å æ¯”']:.2f}%ï¼Œå‡†ç¡®ç‡{top_product['æ•°é‡å‡†ç¡®ç‡']:.1f}%ï¼›"

                    if lowest_accuracy_product['æ•°é‡å‡†ç¡®ç‡'] < 80:
                        explanation += f"{lowest_accuracy_product['äº§å“æ˜¾ç¤º']}å‡†ç¡®ç‡æœ€ä½ï¼Œä»…ä¸º{lowest_accuracy_product['æ•°é‡å‡†ç¡®ç‡']:.1f}%ã€‚"

                    # ç”Ÿæˆé¢„æµ‹å»ºè®®
                    explanation += "<br><b>è¡ŒåŠ¨å»ºè®®ï¼š</b> "

                    low_accuracy = national_top_skus[national_top_skus['æ•°é‡å‡†ç¡®ç‡'] < 70]
                    if not low_accuracy.empty:
                        if len(low_accuracy) <= 3:
                            for _, product in low_accuracy.iterrows():
                                explanation += f"é‡ç‚¹å…³æ³¨{product['äº§å“æ˜¾ç¤º']}çš„é¢„æµ‹å‡†ç¡®æ€§ï¼Œç›®å‰å‡†ç¡®ç‡ä»…ä¸º{product['æ•°é‡å‡†ç¡®ç‡']:.1f}%ï¼›"
                        else:
                            explanation += f"å…±æœ‰{len(low_accuracy)}ä¸ªé‡ç‚¹SKUå‡†ç¡®ç‡ä½äº70%ï¼Œéœ€å®‰æ’ä¸“é¡¹é¢„æµ‹æ”¹è¿›è®¡åˆ’ï¼›"
                    else:
                        explanation += "é‡ç‚¹SKUé¢„æµ‹å‡†ç¡®ç‡è‰¯å¥½ï¼Œå»ºè®®ä¿æŒå½“å‰é¢„æµ‹æ–¹æ³•ï¼›"

                    # æ·»åŠ å¤‡è´§å»ºè®®
                    if 'å¤‡è´§å»ºè®®' in national_top_skus.columns:
                        growth_products = national_top_skus[national_top_skus['é”€é‡å¢é•¿ç‡'] > 10]
                        if not growth_products.empty:
                            top_growth = growth_products.iloc[0]
                            explanation += f"å¢åŠ {top_growth['äº§å“æ˜¾ç¤º']}çš„å¤‡è´§é‡{top_growth['è°ƒæ•´æ¯”ä¾‹']}%ï¼Œå…¶å¢é•¿ç‡è¾¾{top_growth['é”€é‡å¢é•¿ç‡']:.1f}%ã€‚"

                    # æ·»åŠ åº“å­˜é£é™©ä¿¡æ¯
                    if not batch_risk_analysis.empty:
                        high_risk_products = []
                        for _, product in national_top_skus.iterrows():
                            product_code = product['äº§å“ä»£ç ']
                            product_batches = batch_risk_analysis[batch_risk_analysis['äº§å“ä»£ç '] == product_code]
                            high_risk_count = \
                            product_batches[product_batches['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])].shape[0]
                            if high_risk_count > 0:
                                high_risk_products.append(f"{product['äº§å“æ˜¾ç¤º']}({high_risk_count}ä¸ªæ‰¹æ¬¡)")

                        if high_risk_products:
                            explanation += f"<br><b>åº“å­˜é£é™©è­¦ç¤ºï¼š</b> é‡ç‚¹SKUä¸­{', '.join(high_risk_products[:3])}ç­‰äº§å“å­˜åœ¨é«˜é£é™©åº“å­˜ï¼Œéœ€è¦ç‰¹åˆ«å…³æ³¨æ¸…åº“è¿›åº¦ã€‚"

                add_chart_explanation(explanation)
            else:
                st.warning("æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®æ¥è®¡ç®—å…¨å›½é‡ç‚¹SKUã€‚")
        else:  # æ˜¾ç¤ºç‰¹å®šåŒºåŸŸæ•°æ®
            # è·å–æ‰€é€‰åŒºåŸŸçš„é‡ç‚¹SKUæ•°æ®
            if selected_scope in regional_top_skus and not regional_top_skus[selected_scope].empty:
                region_top = regional_top_skus[selected_scope].copy()

                # æ ¼å¼åŒ–å‡†ç¡®ç‡ä¸ºç™¾åˆ†æ¯”
                region_top['æ•°é‡å‡†ç¡®ç‡'] = region_top['æ•°é‡å‡†ç¡®ç‡'] * 100

                # æ·»åŠ äº§å“åç§°
                region_top['äº§å“åç§°'] = region_top['äº§å“ä»£ç '].apply(
                    lambda x: product_names_map.get(x, '') if product_names_map else ''
                )
                region_top['äº§å“æ˜¾ç¤º'] = region_top.apply(
                    lambda row: format_product_code(row['äº§å“ä»£ç '], product_info, include_name=True),
                    axis=1
                )

                # åˆå¹¶å¢é•¿ç‡æ•°æ®å’Œå¤‡è´§å»ºè®®
                try:
                    # ä½¿ç”¨å½“å‰é€‰æ‹©çš„åŒºåŸŸå’Œæœˆä»½è®¡ç®—å¢é•¿ç‡
                    product_growth_data = calculate_product_growth(
                        actual_monthly=actual_data,
                        regions=[selected_scope],  # åªä½¿ç”¨æ‰€é€‰åŒºåŸŸ
                        months=sku_selected_months
                    ).get('latest_growth', pd.DataFrame())

                    if not product_growth_data.empty:
                        region_top = pd.merge(
                            region_top,
                            product_growth_data[
                                ['äº§å“ä»£ç ', 'é”€é‡å¢é•¿ç‡', 'è¶‹åŠ¿', 'å¤‡è´§å»ºè®®', 'è°ƒæ•´æ¯”ä¾‹', 'å»ºè®®æ ·å¼ç±»', 'å»ºè®®å›¾æ ‡']],
                            on='äº§å“ä»£ç ',
                            how='left'
                        )
                except Exception as e:
                    print(f"åˆå¹¶åŒºåŸŸå¤‡è´§å»ºè®®æ•°æ®æ—¶å‡ºé”™: {str(e)}")

                # åˆ›å»ºæ°´å¹³æ¡å½¢å›¾
                fig_top_skus = go.Figure()

                # æ·»åŠ é”€å”®é‡æ¡
                fig_top_skus.add_trace(go.Bar(
                    y=region_top['äº§å“æ˜¾ç¤º'],
                    x=region_top['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'],
                    name='é”€å”®é‡',
                    marker=dict(
                        color=region_top['æ•°é‡å‡†ç¡®ç‡'],
                        colorscale='RdYlGn',
                        cmin=0,
                        cmax=100,
                        colorbar=dict(
                            title='å‡†ç¡®ç‡ (%)',
                            x=1.05
                        )
                    ),
                    orientation='h'
                ))

                # æ·»åŠ å‡†ç¡®ç‡æ ‡è®°å’Œå¤‡è´§å»ºè®®
                for i, row in region_top.iterrows():
                    accuracy_text = f"{row['æ•°é‡å‡†ç¡®ç‡']:.0f}%"

                    # å¦‚æœæœ‰å¤‡è´§å»ºè®®ï¼Œæ·»åŠ åˆ°æ–‡æœ¬
                    if 'å¤‡è´§å»ºè®®' in row and pd.notna(row['å¤‡è´§å»ºè®®']) and pd.notna(row['å»ºè®®å›¾æ ‡']):
                        accuracy_text += f" {row['å»ºè®®å›¾æ ‡']}"

                    fig_top_skus.add_annotation(
                        y=row['äº§å“æ˜¾ç¤º'],
                        x=row['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'] * 1.05,
                        text=accuracy_text,
                        showarrow=False,
                        font=dict(
                            color="black" if row['æ•°é‡å‡†ç¡®ç‡'] > 70 else "red",
                            size=10
                        )
                    )

                # æ›´æ–°å¸ƒå±€
                fig_top_skus.update_layout(
                    title=f"{selected_scope}åŒºåŸŸé‡ç‚¹SKUåŠå…¶å‡†ç¡®ç‡",
                    xaxis=dict(
                        title="é”€å”®é‡ (ç®±)",
                        tickformat=",",
                        showexponent="none"
                    ),
                    yaxis=dict(title="äº§å“"),
                    showlegend=False,
                    plot_bgcolor='white'
                )

                # æ·»åŠ æ‚¬åœæç¤º
                hover_template = '<b>%{y}</b><br>é”€å”®é‡: %{x:,.0f}ç®±<br>å‡†ç¡®ç‡: %{marker.color:.1f}%<br>ç´¯è®¡å æ¯”: %{customdata[0]:.2f}%'

                # å¦‚æœæœ‰å¤‡è´§å»ºè®®æ•°æ®ï¼Œæ·»åŠ åˆ°æ‚¬åœæç¤º
                if 'å¤‡è´§å»ºè®®' in region_top.columns:
                    hover_template += '<br>å»ºè®®: %{customdata[1]}'
                    customdata = region_top[['ç´¯è®¡å æ¯”', 'å¤‡è´§å»ºè®®']].fillna('æœªçŸ¥').values
                else:
                    customdata = region_top[['ç´¯è®¡å æ¯”']].values

                fig_top_skus.update_traces(
                    hovertemplate=hover_template + '<extra></extra>',
                    customdata=customdata,
                    selector=dict(type='bar')
                )

                # çªå‡ºæ˜¾ç¤ºå‡†ç¡®ç‡ä½çš„äº§å“
                low_accuracy_products = region_top[region_top['æ•°é‡å‡†ç¡®ç‡'] < 70]
                if not low_accuracy_products.empty:
                    for product in low_accuracy_products['äº§å“æ˜¾ç¤º']:
                        fig_top_skus.add_shape(
                            type="rect",
                            y0=list(region_top['äº§å“æ˜¾ç¤º']).index(product) - 0.45,
                            y1=list(region_top['äº§å“æ˜¾ç¤º']).index(product) + 0.45,
                            x0=0,
                            x1=region_top['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'].max() * 1.05,
                            line=dict(color="#F44336", width=2),
                            fillcolor="rgba(244, 67, 54, 0.1)"
                        )

                st.plotly_chart(fig_top_skus, use_container_width=True)

                # ç”ŸæˆåŠ¨æ€è§£è¯»
                explanation = f"""
                <b>å›¾è¡¨è§£è¯»ï¼š</b> æ­¤å›¾å±•ç¤ºäº†{selected_scope}åŒºåŸŸé”€å”®é‡ç´¯è®¡å æ¯”è¾¾åˆ°80%çš„é‡ç‚¹SKUåŠå…¶å‡†ç¡®ç‡ï¼Œæ¡å½¢é•¿åº¦è¡¨ç¤ºé”€å”®é‡ï¼Œé¢œè‰²æ·±æµ…è¡¨ç¤ºå‡†ç¡®ç‡ã€‚æ¡†çº¿æ ‡è®°çš„äº§å“å‡†ç¡®ç‡ä½äº70%ï¼Œéœ€è¦ç‰¹åˆ«å…³æ³¨ã€‚
                """

                # æ·»åŠ å…·ä½“äº§å“å»ºè®®
                if not region_top.empty:
                    top_product = region_top.iloc[0]

                    explanation += f"<br><b>äº§å“åˆ†æï¼š</b> "
                    explanation += f"{top_product['äº§å“æ˜¾ç¤º']}æ˜¯{selected_scope}åŒºåŸŸé”€å”®é‡æœ€é«˜çš„äº§å“({format_number(top_product['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'])})ï¼Œ"

                    if len(region_top) > 1:
                        second_product = region_top.iloc[1]
                        explanation += f"å…¶æ¬¡æ˜¯{second_product['äº§å“æ˜¾ç¤º']}({format_number(second_product['æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰'])})ã€‚"

                    # æ£€æŸ¥å‡†ç¡®ç‡
                    low_accuracy = region_top[region_top['æ•°é‡å‡†ç¡®ç‡'] < 70]
                    if not low_accuracy.empty:
                        lowest = low_accuracy.iloc[0]
                        explanation += f"{lowest['äº§å“æ˜¾ç¤º']}å‡†ç¡®ç‡æœ€ä½ï¼Œä»…ä¸º{lowest['æ•°é‡å‡†ç¡®ç‡']:.1f}%ã€‚"

                    # ç”Ÿæˆé¢„æµ‹å»ºè®®
                    explanation += "<br><b>è¡ŒåŠ¨å»ºè®®ï¼š</b> "

                    if not low_accuracy.empty:
                        if len(low_accuracy) <= 2:
                            for _, product in low_accuracy.iterrows():
                                explanation += f"{selected_scope}åŒºåŸŸåº”é‡ç‚¹å…³æ³¨{product['äº§å“æ˜¾ç¤º']}çš„é¢„æµ‹å‡†ç¡®æ€§ï¼›"
                        else:
                            explanation += f"{selected_scope}åŒºåŸŸæœ‰{len(low_accuracy)}ä¸ªé‡ç‚¹SKUå‡†ç¡®ç‡ä½äº70%ï¼Œéœ€å®‰æ’åŒºåŸŸé¢„æµ‹åŸ¹è®­ï¼›"
                    else:
                        explanation += f"{selected_scope}åŒºåŸŸé‡ç‚¹SKUé¢„æµ‹å‡†ç¡®ç‡è‰¯å¥½ï¼›"

                    # æ·»åŠ å¤‡è´§å»ºè®®
                    if 'å¤‡è´§å»ºè®®' in region_top.columns:
                        growth_products = region_top[region_top['é”€é‡å¢é•¿ç‡'] > 0]
                        decline_products = region_top[region_top['é”€é‡å¢é•¿ç‡'] < -10]

                        if not growth_products.empty:
                            top_growth = growth_products.iloc[0]
                            explanation += f"å»ºè®®å¢åŠ {top_growth['äº§å“æ˜¾ç¤º']}çš„å¤‡è´§é‡{top_growth['è°ƒæ•´æ¯”ä¾‹']}%ï¼›"

                        if not decline_products.empty:
                            top_decline = decline_products.iloc[0]
                            adjust = top_decline['è°ƒæ•´æ¯”ä¾‹']
                            explanation += f"å»ºè®®å‡å°‘{top_decline['äº§å“æ˜¾ç¤º']}çš„å¤‡è´§é‡{adjust}%ä»¥é¿å…åº“å­˜ç§¯å‹ã€‚"

                    # æ·»åŠ åº“å­˜é£é™©ä¿¡æ¯
                    if not batch_risk_analysis.empty:
                        high_risk_products = []
                        for _, product in region_top.iterrows():
                            product_code = product['äº§å“ä»£ç ']
                            product_batches = batch_risk_analysis[
                                (batch_risk_analysis['äº§å“ä»£ç '] == product_code) &
                                (batch_risk_analysis['è´£ä»»åŒºåŸŸ'] == selected_scope)
                                ]
                            high_risk_count = \
                            product_batches[product_batches['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])].shape[0]
                            if high_risk_count > 0:
                                high_risk_products.append(f"{product['äº§å“æ˜¾ç¤º']}({high_risk_count}ä¸ªæ‰¹æ¬¡)")

                        if high_risk_products:
                            explanation += f"<br><b>åº“å­˜é£é™©è­¦ç¤ºï¼š</b> åŒºåŸŸé‡ç‚¹SKUä¸­{', '.join(high_risk_products[:3])}ç­‰äº§å“å­˜åœ¨é«˜é£é™©åº“å­˜ï¼Œéœ€è¦ç‰¹åˆ«å…³æ³¨æ¸…åº“è¿›åº¦ã€‚"

                add_chart_explanation(explanation)
            else:
                st.warning(f"æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®æ¥è®¡ç®—{selected_scope}åŒºåŸŸçš„é‡ç‚¹SKUã€‚")

        # åŒºåŸŸä¸å…¨å›½é‡ç‚¹SKUå¯¹æ¯”ï¼ˆä¿ç•™è¿™éƒ¨åˆ†ï¼Œå› ä¸ºå®ƒæä¾›äº†ä¸åŒçš„åˆ†æç»´åº¦ï¼‰
        if selected_scope != "å…¨å›½":  # åªæœ‰åœ¨é€‰æ‹©ç‰¹å®šåŒºåŸŸæ—¶æ‰æ˜¾ç¤ºå¯¹æ¯”åˆ†æ
            st.markdown("### åŒºåŸŸä¸å…¨å›½é‡ç‚¹SKUå¯¹æ¯”")

            # è·å–åŒºåŸŸå’Œå…¨å›½çš„SKUåˆ—è¡¨
            region_top = regional_top_skus[selected_scope] if selected_scope in regional_top_skus else pd.DataFrame()
            if not region_top.empty and not national_top_skus.empty:
                region_skus = set(region_top['äº§å“ä»£ç '])
                national_skus = set(national_top_skus['äº§å“ä»£ç '])

                # è®¡ç®—å…±æœ‰å’Œç‰¹æœ‰SKU
                common_skus = region_skus.intersection(national_skus)
                region_unique_skus = region_skus - national_skus
                national_unique_skus = national_skus - region_skus

                # åˆ›å»ºåŒºåŸŸå’Œå…¨å›½é‡ç‚¹SKUçš„åç§°æ˜ å°„
                common_sku_names = [format_product_code(code, product_info, include_name=True) for code in common_skus]
                region_unique_sku_names = [format_product_code(code, product_info, include_name=True) for code in
                                           region_unique_skus]
                national_unique_sku_names = [format_product_code(code, product_info, include_name=True) for code in
                                             national_unique_skus]

                # å®Œæ•´æ˜¾ç¤ºæ‰€æœ‰SKUï¼Œä¸é™åˆ¶æ•°é‡
                hover_texts = [
                    f"å…±æœ‰SKU ({len(common_skus)}ä¸ª):<br>" +
                    '<br>- '.join(
                        [''] + [format_product_code(code, product_info, include_name=True) for code in common_skus]),

                    f"åŒºåŸŸç‰¹æœ‰SKU ({len(region_unique_skus)}ä¸ª):<br>" +
                    '<br>- '.join([''] + [format_product_code(code, product_info, include_name=True) for code in
                                          region_unique_skus]),

                    f"å…¨å›½é‡ç‚¹éåŒºåŸŸSKU ({len(national_unique_skus)}ä¸ª):<br>" +
                    '<br>- '.join([''] + [format_product_code(code, product_info, include_name=True) for code in
                                          national_unique_skus])
                ]

                # åˆ›å»ºé¥¼å›¾
                fig_sku_comparison = go.Figure()

                # æ·»åŠ åŒºåŸŸç‰¹æœ‰SKUå æ¯”
                fig_sku_comparison.add_trace(go.Pie(
                    labels=['åŒºåŸŸä¸å…¨å›½å…±æœ‰SKU', 'åŒºåŸŸç‰¹æœ‰SKU', 'å…¨å›½é‡ç‚¹ä½†åŒºåŸŸéé‡ç‚¹SKU'],
                    values=[len(common_skus), len(region_unique_skus), len(national_unique_skus)],
                    hole=.3,
                    marker_colors=['#4CAF50', '#2196F3', '#F44336'],
                    textinfo='label+percent',
                    hoverinfo='text',
                    hovertext=hover_texts,
                    customdata=[common_sku_names, region_unique_sku_names, national_unique_sku_names]
                ))

                fig_sku_comparison.update_layout(
                    title=f"{selected_scope}åŒºåŸŸä¸å…¨å›½é‡ç‚¹SKUå¯¹æ¯”",
                    plot_bgcolor='white',
                    hoverlabel=dict(
                        bgcolor="white",
                        font_size=12,
                        font_family="Arial"
                    )
                )

                st.plotly_chart(fig_sku_comparison, use_container_width=True)

                # ä¿®æ”¹å›¾è¡¨è§£è¯»ï¼Œåˆ é™¤SKUè¯¦æƒ…éƒ¨åˆ†
                sku_comparison_explanation = f"""
                <b>å›¾è¡¨è§£è¯»ï¼š</b> æ­¤é¥¼å›¾å±•ç¤ºäº†{selected_scope}åŒºåŸŸé‡ç‚¹SKUä¸å…¨å›½é‡ç‚¹SKUçš„å¯¹æ¯”æƒ…å†µã€‚å…±æœ‰SKU(ç»¿è‰²)è¡¨ç¤ºåŒæ—¶æ˜¯åŒºåŸŸå’Œå…¨å›½é‡ç‚¹çš„äº§å“ï¼›åŒºåŸŸç‰¹æœ‰SKU(è“è‰²)è¡¨ç¤ºåªåœ¨è¯¥åŒºåŸŸæ˜¯é‡ç‚¹çš„äº§å“ï¼›å…¨å›½é‡ç‚¹ä½†åŒºåŸŸéé‡ç‚¹SKU(çº¢è‰²)è¡¨ç¤ºåœ¨å…¨å›½èŒƒå›´å†…æ˜¯é‡ç‚¹ä½†åœ¨è¯¥åŒºåŸŸä¸æ˜¯é‡ç‚¹çš„äº§å“ã€‚
                <br><b>å»ºè®®ï¼š</b> å…³æ³¨åŒºåŸŸç‰¹æœ‰SKUè¡¨æ˜åŒºåŸŸå¸‚åœºç‰¹æ€§ï¼›æ³¨æ„å…¨å›½é‡ç‚¹ä½†åŒºåŸŸéé‡ç‚¹çš„SKUå¯èƒ½æœ‰å¼€å‘ç©ºé—´ã€‚
                """

                add_chart_explanation(sku_comparison_explanation)
            else:
                st.warning("ç¼ºå°‘å¯¹æ¯”æ‰€éœ€çš„æ•°æ®ã€‚")

with tabs[4]:  # åº“å­˜é£é™©ç®¡ç†æ ‡ç­¾é¡µ
    # åœ¨æ ‡ç­¾é¡µå†…æ·»åŠ ç­›é€‰å™¨
    st.markdown("### ğŸ“Š åº“å­˜é£é™©åˆ†æç­›é€‰")
    with st.expander("ç­›é€‰æ¡ä»¶", expanded=True):
        col1, col2, col3 = st.columns(3)

        with col1:
            risk_filter = st.multiselect(
                "æŒ‰é£é™©ç¨‹åº¦ç­›é€‰",
                options=['æé«˜é£é™©', 'é«˜é£é™©', 'ä¸­é£é™©', 'ä½é£é™©', 'æä½é£é™©'],
                default=['æé«˜é£é™©', 'é«˜é£é™©'],
                key="risk_filter"
            )

        with col2:
            responsibility_regions = sorted(batch_risk_analysis['è´£ä»»åŒºåŸŸ'].unique())
            region_filter = st.multiselect(
                "æŒ‰è´£ä»»åŒºåŸŸç­›é€‰",
                options=responsibility_regions,
                default=responsibility_regions,
                key="region_filter"
            )

        with col3:
            all_persons = sorted(batch_risk_analysis['è´£ä»»äºº'].unique())
            person_filter = st.multiselect(
                "æŒ‰è´£ä»»äººç­›é€‰",
                options=all_persons,
                default=[],
                key="person_filter"
            )

    # åº”ç”¨ç­›é€‰æ¡ä»¶
    filtered_risk_data = batch_risk_analysis

    if risk_filter:
        filtered_risk_data = filtered_risk_data[filtered_risk_data['é£é™©ç¨‹åº¦'].isin(risk_filter)]

    if region_filter:
        filtered_risk_data = filtered_risk_data[filtered_risk_data['è´£ä»»åŒºåŸŸ'].isin(region_filter)]

    if person_filter:
        filtered_risk_data = filtered_risk_data[filtered_risk_data['è´£ä»»äºº'].isin(person_filter)]

    # æ£€æŸ¥ç­›é€‰åçš„æ•°æ®æ˜¯å¦ä¸ºç©º
    if filtered_risk_data.empty:
        st.warning("ç­›é€‰æ¡ä»¶ä¸‹æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ‰¹æ¬¡æ•°æ®ã€‚")
    else:
        # åº“å­˜é£é™©æ¦‚è§ˆ
        st.markdown("### åº“å­˜é£é™©æ€»è§ˆ")

        # é£é™©æ‰¹æ¬¡ç»Ÿè®¡å’Œæ±‡æ€»ä¿¡æ¯
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            total_batches = len(filtered_risk_data)
            high_risk_batches = filtered_risk_data[filtered_risk_data['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])].shape[0]
            high_risk_pct = (high_risk_batches / total_batches * 100) if total_batches > 0 else 0

            st.markdown(f"""
            <div class="metric-card">
                <p class="card-header">é£é™©æ‰¹æ¬¡æ•°é‡</p>
                <p class="card-value">{total_batches}</p>
                <p class="card-text">å…¶ä¸­é«˜é£é™©{high_risk_batches}ä¸ª({high_risk_pct:.1f}%)</p>
            </div>
            """, unsafe_allow_html=True)

        with col2:
            total_value = filtered_risk_data['æ‰¹æ¬¡ä»·å€¼'].sum()
            high_risk_value = filtered_risk_data[filtered_risk_data['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])][
                'æ‰¹æ¬¡ä»·å€¼'].sum()
            value_pct = (high_risk_value / total_value * 100) if total_value > 0 else 0

            st.markdown(f"""
            <div class="metric-card">
                <p class="card-header">åº“å­˜ä»·å€¼æ€»é¢</p>
                <p class="card-value">Â¥{total_value:,.2f}</p>
                <p class="card-text">é«˜é£é™©ä»·å€¼å æ¯”{value_pct:.1f}%</p>
            </div>
            """, unsafe_allow_html=True)

        with col3:
            avg_age = filtered_risk_data['åº“é¾„'].mean()
            max_age = filtered_risk_data['åº“é¾„'].max()

            st.markdown(f"""
            <div class="metric-card">
                <p class="card-header">å¹³å‡åº“é¾„</p>
                <p class="card-value">{avg_age:.1f}å¤©</p>
                <p class="card-text">æœ€é•¿åº“é¾„{max_age}å¤©</p>
            </div>
            """, unsafe_allow_html=True)

        with col4:
            # è®¡ç®—æ— æ¸…åº“å¤©æ•°çš„æ‰¹æ¬¡æ•°é‡
            inf_clearance = sum(1 for x in filtered_risk_data['é¢„è®¡æ¸…åº“å¤©æ•°'] if x == float('inf'))
            clearance_pct = (inf_clearance / total_batches * 100) if total_batches > 0 else 0

            st.markdown(f"""
            <div class="metric-card">
                <p class="card-header">æ— æ³•æ¸…åº“æ‰¹æ¬¡</p>
                <p class="card-value">{inf_clearance}ä¸ª</p>
                <p class="card-text">å æ€»æ‰¹æ¬¡{clearance_pct:.1f}%</p>
            </div>
            """, unsafe_allow_html=True)

        # åº“å­˜é£é™©åˆ†å¸ƒå¯è§†åŒ–
        st.markdown('<div class="sub-header">ğŸš¨ é£é™©åˆ†å¸ƒä¸è´£ä»»åˆ†æ</div>', unsafe_allow_html=True)

        col1, col2 = st.columns(2)

        with col1:
            # åˆ›å»ºé£é™©åˆ†å¸ƒé¥¼å›¾
            risk_chart = create_risk_distribution_chart(filtered_risk_data)
            if risk_chart:
                st.plotly_chart(risk_chart, use_container_width=True)

        with col2:
            # è´£ä»»åŒºåŸŸåˆ†å¸ƒ
            region_chart = create_responsibility_region_chart(filtered_risk_data)
            if region_chart:
                st.plotly_chart(region_chart, use_container_width=True)

        # è´£ä»»äººåˆ†æ
        st.markdown('<div class="sub-header">ğŸ‘¤ è´£ä»»äººåº“å­˜é£é™©åˆ†æ</div>', unsafe_allow_html=True)

        # è´£ä»»äººåˆ†å¸ƒå›¾
        person_chart = create_responsibility_person_chart(filtered_risk_data)
        if person_chart:
            st.plotly_chart(person_chart, use_container_width=True)

        # è´£ä»»åˆ†æè§£è¯»
        responsibility_explanation = """
        <b>å›¾è¡¨è§£è¯»ï¼š</b> ä¸Šæ–¹å›¾è¡¨å±•ç¤ºäº†é«˜é£é™©æ‰¹æ¬¡çš„è´£ä»»åŒºåŸŸå’Œè´£ä»»äººåˆ†å¸ƒæƒ…å†µã€‚è“è‰²æŸ±è¡¨ç¤ºæ‰¹æ¬¡æ•°é‡ï¼Œçº¢è‰²çº¿è¡¨ç¤ºæ‰¹æ¬¡ä»·å€¼ã€‚è´Ÿè´£æ‰¹æ¬¡æ•°é‡æœ€å¤šæˆ–æ‰¹æ¬¡ä»·å€¼æœ€é«˜çš„åŒºåŸŸå’Œäººå‘˜åº”ä¼˜å…ˆå…³æ³¨ã€‚
        """

        # æ·»åŠ å…·ä½“åˆ†æ
        if not filtered_risk_data.empty:
            # åŒºåŸŸåˆ†æ
            top_regions = filtered_risk_data['è´£ä»»åŒºåŸŸ'].value_counts().head(3)
            if not top_regions.empty:
                regions_str = ', '.join([f"{region}({count}ä¸ªæ‰¹æ¬¡)" for region, count in top_regions.items()])
                responsibility_explanation += f"<br><b>é‡ç‚¹è´£ä»»åŒºåŸŸï¼š</b> {regions_str}éœ€è¦ä¼˜å…ˆå¤„ç†é«˜é£é™©åº“å­˜ã€‚"

            # è´£ä»»äººåˆ†æ
            top_persons = filtered_risk_data['è´£ä»»äºº'].value_counts().head(3)
            if not top_persons.empty:
                persons_str = ', '.join([f"{person}({count}ä¸ªæ‰¹æ¬¡)" for person, count in top_persons.items()])
                responsibility_explanation += f"<br><b>é‡ç‚¹è´£ä»»äººå‘˜ï¼š</b> {persons_str}è´Ÿè´£çš„æ‰¹æ¬¡é£é™©è¾ƒé«˜ï¼Œéœ€è¦é‡ç‚¹å…³æ³¨å…¶é¢„æµ‹å‡†ç¡®æ€§ã€‚"

            # é£é™©æ‰¹æ¬¡æˆå› åˆ†æ
            if 'ç§¯å‹åŸå› ' in filtered_risk_data.columns:
                reason_counts = filtered_risk_data['ç§¯å‹åŸå› '].value_counts()
                top_reasons = reason_counts.head(3)
                if not top_reasons.empty:
                    reasons_str = ', '.join([f"{reason}({count}ä¸ªæ‰¹æ¬¡)" for reason, count in top_reasons.items()])
                    responsibility_explanation += f"<br><b>ä¸»è¦ç§¯å‹åŸå› ï¼š</b> {reasons_str}ï¼Œåº”é’ˆå¯¹ä¸åŒåŸå› é‡‡å–å·®å¼‚åŒ–æªæ–½ã€‚"

            # æ·»åŠ æ¸…åº“å»ºè®®
            responsibility_explanation += f"<br><b>è¡ŒåŠ¨å»ºè®®ï¼š</b> é’ˆå¯¹é«˜é£é™©æ‰¹æ¬¡ï¼Œåº”ä¼˜å…ˆè€ƒè™‘æŠ˜ä»·ä¿ƒé”€æˆ–è½¬ä»“è°ƒé…ï¼›"
            responsibility_explanation += f"åŠ å¼ºé”€å”®é¢„æµ‹åŸ¹è®­ï¼Œå°¤å…¶æ˜¯å¯¹è´£ä»»äººæ•°é‡è¾ƒå¤šçš„äººå‘˜ï¼›å®šæœŸè¿›è¡Œåº“å­˜å¥åº·åº¦åˆ†æï¼Œå‡å°‘åº“å­˜ç§¯å‹é£é™©ã€‚"

        add_chart_explanation(responsibility_explanation)

        # æ˜¾ç¤ºæ‰¹æ¬¡è¯¦æƒ…è¡¨æ ¼
        st.markdown('<div class="sub-header">ğŸ“‹ æ‰¹æ¬¡é£é™©è¯¦æƒ…è¡¨</div>', unsafe_allow_html=True)

        # æ˜¾ç¤ºç­›é€‰åçš„æ‰¹æ¬¡é£é™©æ•°æ®
        if not filtered_risk_data.empty:
            # é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—
            display_columns = [
                'äº§å“ä»£ç ', 'æ‰¹æ¬¡æ—¥æœŸ', 'æ‰¹æ¬¡åº“å­˜', 'åº“é¾„', 'æ‰¹æ¬¡ä»·å€¼', 'æ—¥å‡å‡ºè´§',
                'é¢„è®¡æ¸…åº“å¤©æ•°', 'é£é™©ç¨‹åº¦', 'è´£ä»»åŒºåŸŸ', 'è´£ä»»äºº', 'å»ºè®®æªæ–½'
            ]

            # ç¡®ä¿æ‰€æœ‰è¦æ˜¾ç¤ºçš„åˆ—éƒ½å­˜åœ¨äºæ•°æ®ä¸­
            display_columns = [col for col in display_columns if col in filtered_risk_data.columns]

            # æ ¼å¼åŒ–é¢„è®¡æ¸…åº“å¤©æ•°åˆ—
            filtered_risk_data_display = filtered_risk_data.copy()
            filtered_risk_data_display['é¢„è®¡æ¸…åº“å¤©æ•°'] = filtered_risk_data_display['é¢„è®¡æ¸…åº“å¤©æ•°'].apply(
                lambda x: "æ— æ³•æ¸…åº“" if x == float('inf') else f"{int(x)}å¤©"
            )


            # åˆ›å»ºå¸¦æœ‰é¢œè‰²æ ‡è®°çš„é£é™©ç­‰çº§åˆ—
            def highlight_risk(risk_level):
                if risk_level == 'æé«˜é£é™©':
                    return f'<span class="risk-extreme-high">{risk_level}</span>'
                elif risk_level == 'é«˜é£é™©':
                    return f'<span class="risk-high">{risk_level}</span>'
                elif risk_level == 'ä¸­é£é™©':
                    return f'<span class="risk-medium">{risk_level}</span>'
                elif risk_level == 'ä½é£é™©':
                    return f'<span class="risk-low">{risk_level}</span>'
                else:
                    return f'<span class="risk-extreme-low">{risk_level}</span>'


            filtered_risk_data_display['é£é™©ç¨‹åº¦'] = filtered_risk_data_display['é£é™©ç¨‹åº¦'].apply(highlight_risk)

            # æ˜¾ç¤ºè¡¨æ ¼
            st.markdown(filtered_risk_data_display[display_columns].to_html(
                escape=False, index=False, formatters={
                    'æ‰¹æ¬¡ä»·å€¼': lambda x: f"Â¥{x:,.2f}",
                    'æ—¥å‡å‡ºè´§': lambda x: f"{x:.2f}ç®±/å¤©"
                }
            ), unsafe_allow_html=True)

            # æä¾›CSVä¸‹è½½åŠŸèƒ½
            csv_download = filtered_risk_data[display_columns].to_csv(index=False).encode('utf-8')
            st.download_button(
                label="ä¸‹è½½é£é™©æ‰¹æ¬¡æ•°æ®CSV",
                data=csv_download,
                file_name="åº“å­˜é£é™©æ‰¹æ¬¡æ•°æ®.csv",
                mime="text/csv",
                key="download-risk-csv"
            )

            # æ·»åŠ æ‰¹æ¬¡æ•°æ®è§£è¯»
            batch_explanation = f"""
            <b>è¡¨æ ¼è¯´æ˜ï¼š</b> æ­¤è¡¨æ ¼å±•ç¤ºäº†æ‰€æœ‰ç¬¦åˆç­›é€‰æ¡ä»¶çš„{len(filtered_risk_data)}ä¸ªæ‰¹æ¬¡çš„è¯¦ç»†é£é™©ä¿¡æ¯ï¼Œ
            åŒ…æ‹¬äº§å“ä»£ç ã€æ‰¹æ¬¡æ—¥æœŸã€åº“å­˜é‡ã€åº“é¾„ã€æ‰¹æ¬¡ä»·å€¼ã€æ—¥å‡å‡ºè´§é‡ã€é¢„è®¡æ¸…åº“å¤©æ•°ã€é£é™©ç¨‹åº¦ã€è´£ä»»åŒºåŸŸã€è´£ä»»äººå’Œå»ºè®®æªæ–½ã€‚
            å¯ä»¥é€šè¿‡ç‚¹å‡»è¡¨å¤´å¯¹ä»»æ„åˆ—è¿›è¡Œæ’åºï¼Œä»¥ä¾¿æ›´å¥½åœ°åˆ†æå’Œå¤„ç†åº“å­˜é£é™©ã€‚
            """

            add_chart_explanation(batch_explanation)
        else:
            st.info("æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ‰¹æ¬¡æ•°æ®")

# é¡µé¢è¿è¡Œ
if __name__ == "__main__":
    # é¡µé¢å·²æˆåŠŸåŠ è½½ï¼Œä¸éœ€è¦é¢å¤–çš„å¤„ç†
    pass